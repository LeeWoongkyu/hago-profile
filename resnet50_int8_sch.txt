Compile...
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, float32, [], []),
             placeholder: Buffer(placeholder_2: handle, int32, [], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  T_cast_2[0] = cast(float32, (int32*)placeholder_2[0])
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op divide
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide_6", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: handle, float32, [64, 3, 7, 7], []),
             placeholder: Buffer(placeholder_4: handle, float32, [64, 3, 7, 7], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  for (ax0.ax1.fused: int32, 0, 192) "parallel" {
    for (ax2: int32, 0, 7) {
      T_divide_2[ramp(((ax0.ax1.fused*49) + (ax2*7)), 1, 7)] = ((float32x7*)placeholder_4[ramp(((ax0.ax1.fused*49) + (ax2*7)), 1, 7)] / broadcast((float32*)placeholder_5[0], 7))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op add
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add_26", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: handle, float32, [64, 3, 7, 7], []),
             placeholder: Buffer(placeholder_4: handle, float32, [64, 3, 7, 7], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  for (ax0.ax1.fused: int32, 0, 192) "parallel" {
    for (ax2: int32, 0, 7) {
      T_add_2[ramp(((ax0.ax1.fused*49) + (ax2*7)), 1, 7)] = ((float32x7*)placeholder_4[ramp(((ax0.ax1.fused*49) + (ax2*7)), 1, 7)] + broadcast((float32*)placeholder_5[0], 7))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op round
primfn(placeholder_1: handle, T_round_1: handle) -> ()
  attr = {"global_symbol": "fused_round", "tir.noalias": True}
  buffers = {T_round: Buffer(T_round_2: handle, float32, [64, 3, 7, 7], []),
             placeholder: Buffer(placeholder_2: handle, float32, [64, 3, 7, 7], [])}
  buffer_map = {placeholder_1: placeholder, T_round_1: T_round} {
  for (ax0.ax1.fused: int32, 0, 192) "parallel" {
    for (ax2: int32, 0, 7) {
      T_round_2[ramp(((ax0.ax1.fused*49) + (ax2*7)), 1, 7)] = @tir.round((float32x7*)placeholder_2[ramp(((ax0.ax1.fused*49) + (ax2*7)), 1, 7)], dtype=float32x7)
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_1", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [64, 3, 7, 7], []),
             placeholder: Buffer(placeholder_2: handle, float32, [64, 3, 7, 7], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 192) "parallel" {
    for (ax2: int32, 0, 7) {
      T_cast_2[ramp(((ax0.ax1.fused*49) + (ax2*7)), 1, 7)] = cast(int32x7, (float32x7*)placeholder_2[ramp(((ax0.ax1.fused*49) + (ax2*7)), 1, 7)])
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op clip
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_clip", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [64, 3, 7, 7], []),
             placeholder: Buffer(placeholder_2: handle, int32, [64, 3, 7, 7], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0.i1.fused: int32, 0, 192) "parallel" {
    for (i2: int32, 0, 7) {
      compute_2[ramp(((i0.i1.fused*49) + (i2*7)), 1, 7)] = max(min((int32x7*)placeholder_2[ramp(((i0.i1.fused*49) + (i2*7)), 1, 7)], broadcast(127, 7)), broadcast(-128, 7))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_2", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [64, 3, 7, 7], []),
             placeholder: Buffer(placeholder_2: handle, int32, [64, 3, 7, 7], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 192) "parallel" {
    for (ax2: int32, 0, 7) {
      T_cast_2[ramp(((ax0.ax1.fused*49) + (ax2*7)), 1, 7)] = cast(int8x7, (int32x7*)placeholder_2[ramp(((ax0.ax1.fused*49) + (ax2*7)), 1, 7)])
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op nn.pad
primfn(placeholder_1: handle, T_pad_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_pad", "tir.noalias": True}
  buffers = {T_pad: Buffer(T_pad_2: handle, int8, [64, 4, 7, 7], []),
             placeholder: Buffer(placeholder_2: handle, int8, [64, 3, 7, 7], [])}
  buffer_map = {placeholder_1: placeholder, T_pad_1: T_pad} {
  for (ax0.ax1.fused: int32, 0, 256) "parallel" {
    for (ax2: int32, 0, 7) {
      T_pad_2[ramp(((ax0.ax1.fused*49) + (ax2*7)), 1, 7)] = @tir.if_then_else((floormod(ax0.ax1.fused, 4) < 3), (int8x7*)placeholder_2[ramp((((floordiv(ax0.ax1.fused, 4)*147) + (floormod(ax0.ax1.fused, 4)*49)) + (ax2*7)), 1, 7)], broadcast(0i8, 7), dtype=int8x7)
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op divide
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide_7", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: handle, float32, [64, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [64, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  for (ax0.ax1.fused: int32, 0, 64) "parallel" {
    T_divide_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] / (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op add
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add_27", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_4: handle, float32, [64, 1, 1], []),
             T_add: Buffer(T_add_2: handle, float32, [64, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  for (ax0.ax1.fused: int32, 0, 64) "parallel" {
    T_add_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] + (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op round
primfn(placeholder_1: handle, T_round_1: handle) -> ()
  attr = {"global_symbol": "fused_round_1", "tir.noalias": True}
  buffers = {T_round: Buffer(T_round_2: handle, float32, [64, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [64, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_round_1: T_round} {
  for (ax0.ax1.fused: int32, 0, 64) "parallel" {
    T_round_2[ax0.ax1.fused] = @tir.round((float32*)placeholder_2[ax0.ax1.fused], dtype=float32)
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_3", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [64, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [64, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 64) "parallel" {
    T_cast_2[ax0.ax1.fused] = cast(int32, (float32*)placeholder_2[ax0.ax1.fused])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op clip
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_clip_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [64, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [64, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0.i1.fused: int32, 0, 64) "parallel" {
    compute_2[i0.i1.fused] = (int32*)placeholder_2[i0.i1.fused]
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_4", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [64, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [64, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 64) "parallel" {
    T_cast_2[ax0.ax1.fused] = (int32*)placeholder_2[ax0.ax1.fused]
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op divide
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide_8", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_4: handle, float32, [64, 64, 1, 1], []),
             T_divide: Buffer(T_divide_2: handle, float32, [64, 64, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  for (ax0.ax1.fused: int32, 0, 4096) "parallel" {
    T_divide_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] / (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op add
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add_28", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: handle, float32, [64, 64, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [64, 64, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  for (ax0.ax1.fused: int32, 0, 4096) "parallel" {
    T_add_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] + (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op round
primfn(placeholder_1: handle, T_round_1: handle) -> ()
  attr = {"global_symbol": "fused_round_2", "tir.noalias": True}
  buffers = {T_round: Buffer(T_round_2: handle, float32, [64, 64, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [64, 64, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_round_1: T_round} {
  for (ax0.ax1.fused: int32, 0, 4096) "parallel" {
    T_round_2[ax0.ax1.fused] = @tir.round((float32*)placeholder_2[ax0.ax1.fused], dtype=float32)
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_5", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [64, 64, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [64, 64, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 4096) "parallel" {
    T_cast_2[ax0.ax1.fused] = cast(int32, (float32*)placeholder_2[ax0.ax1.fused])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op clip
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_clip_2", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [64, 64, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [64, 64, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0.i1.fused: int32, 0, 4096) "parallel" {
    compute_2[i0.i1.fused] = max(min((int32*)placeholder_2[i0.i1.fused], 127), -128)
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_6", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [64, 64, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [64, 64, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 4096) "parallel" {
    T_cast_2[ax0.ax1.fused] = cast(int8, (int32*)placeholder_2[ax0.ax1.fused])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op divide
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide_9", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: handle, float32, [64, 64, 3, 3], []),
             placeholder: Buffer(placeholder_4: handle, float32, [64, 64, 3, 3], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  for (ax0.ax1.fused: int32, 0, 4096) "parallel" {
    for (ax2: int32, 0, 3) {
      T_divide_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = ((float32x3*)placeholder_4[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] / broadcast((float32*)placeholder_5[0], 3))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op add
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add_29", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: handle, float32, [64, 64, 3, 3], []),
             placeholder: Buffer(placeholder_4: handle, float32, [64, 64, 3, 3], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  for (ax0.ax1.fused: int32, 0, 4096) "parallel" {
    for (ax2: int32, 0, 3) {
      T_add_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = ((float32x3*)placeholder_4[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] + broadcast((float32*)placeholder_5[0], 3))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op round
primfn(placeholder_1: handle, T_round_1: handle) -> ()
  attr = {"global_symbol": "fused_round_3", "tir.noalias": True}
  buffers = {T_round: Buffer(T_round_2: handle, float32, [64, 64, 3, 3], []),
             placeholder: Buffer(placeholder_2: handle, float32, [64, 64, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, T_round_1: T_round} {
  for (ax0.ax1.fused: int32, 0, 4096) "parallel" {
    for (ax2: int32, 0, 3) {
      T_round_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = @tir.round((float32x3*)placeholder_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)], dtype=float32x3)
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_7", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [64, 64, 3, 3], []),
             placeholder: Buffer(placeholder_2: handle, float32, [64, 64, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 4096) "parallel" {
    for (ax2: int32, 0, 3) {
      T_cast_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = cast(int32x3, (float32x3*)placeholder_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)])
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op clip
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_clip_3", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [64, 64, 3, 3], []),
             placeholder: Buffer(placeholder_2: handle, int32, [64, 64, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0.i1.fused: int32, 0, 4096) "parallel" {
    for (i2: int32, 0, 3) {
      compute_2[ramp(((i0.i1.fused*9) + (i2*3)), 1, 3)] = max(min((int32x3*)placeholder_2[ramp(((i0.i1.fused*9) + (i2*3)), 1, 3)], broadcast(127, 3)), broadcast(-128, 3))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_8", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [64, 64, 3, 3], []),
             placeholder: Buffer(placeholder_2: handle, int32, [64, 64, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 4096) "parallel" {
    for (ax2: int32, 0, 3) {
      T_cast_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = cast(int8x3, (int32x3*)placeholder_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)])
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op divide
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide_10", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: handle, float32, [256, 64, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [256, 64, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  for (ax0.ax1.fused: int32, 0, 16384) "parallel" {
    T_divide_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] / (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op add
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add_30", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: handle, float32, [256, 64, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [256, 64, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  for (ax0.ax1.fused: int32, 0, 16384) "parallel" {
    T_add_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] + (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op round
primfn(placeholder_1: handle, T_round_1: handle) -> ()
  attr = {"global_symbol": "fused_round_4", "tir.noalias": True}
  buffers = {T_round: Buffer(T_round_2: handle, float32, [256, 64, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [256, 64, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_round_1: T_round} {
  for (ax0.ax1.fused: int32, 0, 16384) "parallel" {
    T_round_2[ax0.ax1.fused] = @tir.round((float32*)placeholder_2[ax0.ax1.fused], dtype=float32)
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_9", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [256, 64, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [256, 64, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 16384) "parallel" {
    T_cast_2[ax0.ax1.fused] = cast(int32, (float32*)placeholder_2[ax0.ax1.fused])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op clip
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_clip_4", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [256, 64, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [256, 64, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0.i1.fused: int32, 0, 16384) "parallel" {
    compute_2[i0.i1.fused] = max(min((int32*)placeholder_2[i0.i1.fused], 127), -128)
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_10", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [256, 64, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [256, 64, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 16384) "parallel" {
    T_cast_2[ax0.ax1.fused] = cast(int8, (int32*)placeholder_2[ax0.ax1.fused])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op divide
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide_11", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: handle, float32, [256, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [256, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  for (ax0.ax1.fused: int32, 0, 256) "parallel" {
    T_divide_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] / (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op add
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add_31", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: handle, float32, [256, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [256, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  for (ax0.ax1.fused: int32, 0, 256) "parallel" {
    T_add_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] + (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op round
primfn(placeholder_1: handle, T_round_1: handle) -> ()
  attr = {"global_symbol": "fused_round_5", "tir.noalias": True}
  buffers = {T_round: Buffer(T_round_2: handle, float32, [256, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [256, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_round_1: T_round} {
  for (ax0.ax1.fused: int32, 0, 256) "parallel" {
    T_round_2[ax0.ax1.fused] = @tir.round((float32*)placeholder_2[ax0.ax1.fused], dtype=float32)
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_11", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [256, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [256, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 256) "parallel" {
    T_cast_2[ax0.ax1.fused] = cast(int32, (float32*)placeholder_2[ax0.ax1.fused])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op clip
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_clip_5", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [256, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [256, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0.i1.fused: int32, 0, 256) "parallel" {
    compute_2[i0.i1.fused] = (int32*)placeholder_2[i0.i1.fused]
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_12", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [256, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [256, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 256) "parallel" {
    T_cast_2[ax0.ax1.fused] = (int32*)placeholder_2[ax0.ax1.fused]
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op divide
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide_12", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: handle, float32, [64, 256, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [64, 256, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  for (ax0.ax1.fused: int32, 0, 16384) "parallel" {
    T_divide_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] / (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op add
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add_32", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: handle, float32, [64, 256, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [64, 256, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  for (ax0.ax1.fused: int32, 0, 16384) "parallel" {
    T_add_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] + (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op round
primfn(placeholder_1: handle, T_round_1: handle) -> ()
  attr = {"global_symbol": "fused_round_6", "tir.noalias": True}
  buffers = {T_round: Buffer(T_round_2: handle, float32, [64, 256, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [64, 256, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_round_1: T_round} {
  for (ax0.ax1.fused: int32, 0, 16384) "parallel" {
    T_round_2[ax0.ax1.fused] = @tir.round((float32*)placeholder_2[ax0.ax1.fused], dtype=float32)
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_13", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [64, 256, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [64, 256, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 16384) "parallel" {
    T_cast_2[ax0.ax1.fused] = cast(int32, (float32*)placeholder_2[ax0.ax1.fused])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op clip
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_clip_6", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [64, 256, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [64, 256, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0.i1.fused: int32, 0, 16384) "parallel" {
    compute_2[i0.i1.fused] = max(min((int32*)placeholder_2[i0.i1.fused], 127), -128)
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_14", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [64, 256, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [64, 256, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 16384) "parallel" {
    T_cast_2[ax0.ax1.fused] = cast(int8, (int32*)placeholder_2[ax0.ax1.fused])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op divide
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide_13", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: handle, float32, [128, 256, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [128, 256, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  for (ax0.ax1.fused: int32, 0, 32768) "parallel" {
    T_divide_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] / (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op add
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add_33", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: handle, float32, [128, 256, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [128, 256, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  for (ax0.ax1.fused: int32, 0, 32768) "parallel" {
    T_add_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] + (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op round
primfn(placeholder_1: handle, T_round_1: handle) -> ()
  attr = {"global_symbol": "fused_round_7", "tir.noalias": True}
  buffers = {T_round: Buffer(T_round_2: handle, float32, [128, 256, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [128, 256, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_round_1: T_round} {
  for (ax0.ax1.fused: int32, 0, 32768) "parallel" {
    T_round_2[ax0.ax1.fused] = @tir.round((float32*)placeholder_2[ax0.ax1.fused], dtype=float32)
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_15", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [128, 256, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [128, 256, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 32768) "parallel" {
    T_cast_2[ax0.ax1.fused] = cast(int32, (float32*)placeholder_2[ax0.ax1.fused])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op clip
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_clip_7", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [128, 256, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [128, 256, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0.i1.fused: int32, 0, 32768) "parallel" {
    compute_2[i0.i1.fused] = max(min((int32*)placeholder_2[i0.i1.fused], 127), -128)
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_16", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [128, 256, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [128, 256, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 32768) "parallel" {
    T_cast_2[ax0.ax1.fused] = cast(int8, (int32*)placeholder_2[ax0.ax1.fused])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op divide
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide_14", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: handle, float32, [128, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [128, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  for (ax0.ax1.fused: int32, 0, 128) "parallel" {
    T_divide_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] / (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op add
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add_34", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: handle, float32, [128, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [128, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  for (ax0.ax1.fused: int32, 0, 128) "parallel" {
    T_add_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] + (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op round
primfn(placeholder_1: handle, T_round_1: handle) -> ()
  attr = {"global_symbol": "fused_round_8", "tir.noalias": True}
  buffers = {T_round: Buffer(T_round_2: handle, float32, [128, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [128, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_round_1: T_round} {
  for (ax0.ax1.fused: int32, 0, 128) "parallel" {
    T_round_2[ax0.ax1.fused] = @tir.round((float32*)placeholder_2[ax0.ax1.fused], dtype=float32)
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_17", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [128, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [128, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 128) "parallel" {
    T_cast_2[ax0.ax1.fused] = cast(int32, (float32*)placeholder_2[ax0.ax1.fused])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op clip
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_clip_8", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [128, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [128, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0.i1.fused: int32, 0, 128) "parallel" {
    compute_2[i0.i1.fused] = (int32*)placeholder_2[i0.i1.fused]
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_18", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [128, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [128, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 128) "parallel" {
    T_cast_2[ax0.ax1.fused] = (int32*)placeholder_2[ax0.ax1.fused]
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op divide
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide_15", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: handle, float32, [128, 128, 3, 3], []),
             placeholder: Buffer(placeholder_4: handle, float32, [128, 128, 3, 3], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  for (ax0.ax1.fused: int32, 0, 16384) "parallel" {
    for (ax2: int32, 0, 3) {
      T_divide_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = ((float32x3*)placeholder_4[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] / broadcast((float32*)placeholder_5[0], 3))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op add
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add_35", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: handle, float32, [128, 128, 3, 3], []),
             placeholder: Buffer(placeholder_4: handle, float32, [128, 128, 3, 3], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  for (ax0.ax1.fused: int32, 0, 16384) "parallel" {
    for (ax2: int32, 0, 3) {
      T_add_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = ((float32x3*)placeholder_4[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] + broadcast((float32*)placeholder_5[0], 3))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op round
primfn(placeholder_1: handle, T_round_1: handle) -> ()
  attr = {"global_symbol": "fused_round_9", "tir.noalias": True}
  buffers = {T_round: Buffer(T_round_2: handle, float32, [128, 128, 3, 3], []),
             placeholder: Buffer(placeholder_2: handle, float32, [128, 128, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, T_round_1: T_round} {
  for (ax0.ax1.fused: int32, 0, 16384) "parallel" {
    for (ax2: int32, 0, 3) {
      T_round_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = @tir.round((float32x3*)placeholder_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)], dtype=float32x3)
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_19", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [128, 128, 3, 3], []),
             placeholder: Buffer(placeholder_2: handle, float32, [128, 128, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 16384) "parallel" {
    for (ax2: int32, 0, 3) {
      T_cast_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = cast(int32x3, (float32x3*)placeholder_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)])
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op clip
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_clip_9", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [128, 128, 3, 3], []),
             placeholder: Buffer(placeholder_2: handle, int32, [128, 128, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0.i1.fused: int32, 0, 16384) "parallel" {
    for (i2: int32, 0, 3) {
      compute_2[ramp(((i0.i1.fused*9) + (i2*3)), 1, 3)] = max(min((int32x3*)placeholder_2[ramp(((i0.i1.fused*9) + (i2*3)), 1, 3)], broadcast(127, 3)), broadcast(-128, 3))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_20", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [128, 128, 3, 3], []),
             placeholder: Buffer(placeholder_2: handle, int32, [128, 128, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 16384) "parallel" {
    for (ax2: int32, 0, 3) {
      T_cast_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = cast(int8x3, (int32x3*)placeholder_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)])
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op divide
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide_16", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: handle, float32, [512, 128, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [512, 128, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  for (ax0.ax1.fused: int32, 0, 65536) "parallel" {
    T_divide_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] / (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op add
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add_36", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: handle, float32, [512, 128, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [512, 128, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  for (ax0.ax1.fused: int32, 0, 65536) "parallel" {
    T_add_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] + (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op round
primfn(placeholder_1: handle, T_round_1: handle) -> ()
  attr = {"global_symbol": "fused_round_10", "tir.noalias": True}
  buffers = {T_round: Buffer(T_round_2: handle, float32, [512, 128, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [512, 128, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_round_1: T_round} {
  for (ax0.ax1.fused: int32, 0, 65536) "parallel" {
    T_round_2[ax0.ax1.fused] = @tir.round((float32*)placeholder_2[ax0.ax1.fused], dtype=float32)
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_21", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [512, 128, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [512, 128, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 65536) "parallel" {
    T_cast_2[ax0.ax1.fused] = cast(int32, (float32*)placeholder_2[ax0.ax1.fused])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op clip
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_clip_10", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [512, 128, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [512, 128, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0.i1.fused: int32, 0, 65536) "parallel" {
    compute_2[i0.i1.fused] = max(min((int32*)placeholder_2[i0.i1.fused], 127), -128)
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_22", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [512, 128, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [512, 128, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 65536) "parallel" {
    T_cast_2[ax0.ax1.fused] = cast(int8, (int32*)placeholder_2[ax0.ax1.fused])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op divide
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide_17", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: handle, float32, [512, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [512, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  for (ax0.ax1.fused: int32, 0, 512) "parallel" {
    T_divide_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] / (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op add
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add_37", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: handle, float32, [512, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [512, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  for (ax0.ax1.fused: int32, 0, 512) "parallel" {
    T_add_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] + (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op round
primfn(placeholder_1: handle, T_round_1: handle) -> ()
  attr = {"global_symbol": "fused_round_11", "tir.noalias": True}
  buffers = {T_round: Buffer(T_round_2: handle, float32, [512, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [512, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_round_1: T_round} {
  for (ax0.ax1.fused: int32, 0, 512) "parallel" {
    T_round_2[ax0.ax1.fused] = @tir.round((float32*)placeholder_2[ax0.ax1.fused], dtype=float32)
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_23", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [512, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [512, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 512) "parallel" {
    T_cast_2[ax0.ax1.fused] = cast(int32, (float32*)placeholder_2[ax0.ax1.fused])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op clip
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_clip_11", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [512, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [512, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0.i1.fused: int32, 0, 512) "parallel" {
    compute_2[i0.i1.fused] = (int32*)placeholder_2[i0.i1.fused]
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_24", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [512, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [512, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 512) "parallel" {
    T_cast_2[ax0.ax1.fused] = (int32*)placeholder_2[ax0.ax1.fused]
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op divide
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide_18", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: handle, float32, [512, 256, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [512, 256, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  for (ax0.ax1.fused: int32, 0, 131072) "parallel" {
    T_divide_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] / (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op add
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add_38", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: handle, float32, [512, 256, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [512, 256, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  for (ax0.ax1.fused: int32, 0, 131072) "parallel" {
    T_add_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] + (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op round
primfn(placeholder_1: handle, T_round_1: handle) -> ()
  attr = {"global_symbol": "fused_round_12", "tir.noalias": True}
  buffers = {T_round: Buffer(T_round_2: handle, float32, [512, 256, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [512, 256, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_round_1: T_round} {
  for (ax0.ax1.fused: int32, 0, 131072) "parallel" {
    T_round_2[ax0.ax1.fused] = @tir.round((float32*)placeholder_2[ax0.ax1.fused], dtype=float32)
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_25", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [512, 256, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [512, 256, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 131072) "parallel" {
    T_cast_2[ax0.ax1.fused] = cast(int32, (float32*)placeholder_2[ax0.ax1.fused])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op clip
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_clip_12", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [512, 256, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [512, 256, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0.i1.fused: int32, 0, 131072) "parallel" {
    compute_2[i0.i1.fused] = max(min((int32*)placeholder_2[i0.i1.fused], 127), -128)
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_26", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [512, 256, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [512, 256, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 131072) "parallel" {
    T_cast_2[ax0.ax1.fused] = cast(int8, (int32*)placeholder_2[ax0.ax1.fused])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op divide
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide_19", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: handle, float32, [128, 512, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [128, 512, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  for (ax0.ax1.fused: int32, 0, 65536) "parallel" {
    T_divide_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] / (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op add
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add_39", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: handle, float32, [128, 512, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [128, 512, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  for (ax0.ax1.fused: int32, 0, 65536) "parallel" {
    T_add_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] + (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op round
primfn(placeholder_1: handle, T_round_1: handle) -> ()
  attr = {"global_symbol": "fused_round_13", "tir.noalias": True}
  buffers = {T_round: Buffer(T_round_2: handle, float32, [128, 512, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [128, 512, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_round_1: T_round} {
  for (ax0.ax1.fused: int32, 0, 65536) "parallel" {
    T_round_2[ax0.ax1.fused] = @tir.round((float32*)placeholder_2[ax0.ax1.fused], dtype=float32)
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_27", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [128, 512, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [128, 512, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 65536) "parallel" {
    T_cast_2[ax0.ax1.fused] = cast(int32, (float32*)placeholder_2[ax0.ax1.fused])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op clip
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_clip_13", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [128, 512, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [128, 512, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0.i1.fused: int32, 0, 65536) "parallel" {
    compute_2[i0.i1.fused] = max(min((int32*)placeholder_2[i0.i1.fused], 127), -128)
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_28", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [128, 512, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [128, 512, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 65536) "parallel" {
    T_cast_2[ax0.ax1.fused] = cast(int8, (int32*)placeholder_2[ax0.ax1.fused])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op divide
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide_20", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: handle, float32, [256, 512, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [256, 512, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  for (ax0.ax1.fused: int32, 0, 131072) "parallel" {
    T_divide_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] / (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op add
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add_40", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: handle, float32, [256, 512, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [256, 512, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  for (ax0.ax1.fused: int32, 0, 131072) "parallel" {
    T_add_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] + (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op round
primfn(placeholder_1: handle, T_round_1: handle) -> ()
  attr = {"global_symbol": "fused_round_14", "tir.noalias": True}
  buffers = {T_round: Buffer(T_round_2: handle, float32, [256, 512, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [256, 512, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_round_1: T_round} {
  for (ax0.ax1.fused: int32, 0, 131072) "parallel" {
    T_round_2[ax0.ax1.fused] = @tir.round((float32*)placeholder_2[ax0.ax1.fused], dtype=float32)
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_29", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [256, 512, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [256, 512, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 131072) "parallel" {
    T_cast_2[ax0.ax1.fused] = cast(int32, (float32*)placeholder_2[ax0.ax1.fused])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op clip
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_clip_14", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [256, 512, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [256, 512, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0.i1.fused: int32, 0, 131072) "parallel" {
    compute_2[i0.i1.fused] = max(min((int32*)placeholder_2[i0.i1.fused], 127), -128)
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_30", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [256, 512, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [256, 512, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 131072) "parallel" {
    T_cast_2[ax0.ax1.fused] = cast(int8, (int32*)placeholder_2[ax0.ax1.fused])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op divide
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide_21", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: handle, float32, [256, 256, 3, 3], []),
             placeholder: Buffer(placeholder_4: handle, float32, [256, 256, 3, 3], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  for (ax0.ax1.fused: int32, 0, 65536) "parallel" {
    for (ax2: int32, 0, 3) {
      T_divide_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = ((float32x3*)placeholder_4[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] / broadcast((float32*)placeholder_5[0], 3))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op add
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add_41", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: handle, float32, [256, 256, 3, 3], []),
             placeholder: Buffer(placeholder_4: handle, float32, [256, 256, 3, 3], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  for (ax0.ax1.fused: int32, 0, 65536) "parallel" {
    for (ax2: int32, 0, 3) {
      T_add_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = ((float32x3*)placeholder_4[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] + broadcast((float32*)placeholder_5[0], 3))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op round
primfn(placeholder_1: handle, T_round_1: handle) -> ()
  attr = {"global_symbol": "fused_round_15", "tir.noalias": True}
  buffers = {T_round: Buffer(T_round_2: handle, float32, [256, 256, 3, 3], []),
             placeholder: Buffer(placeholder_2: handle, float32, [256, 256, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, T_round_1: T_round} {
  for (ax0.ax1.fused: int32, 0, 65536) "parallel" {
    for (ax2: int32, 0, 3) {
      T_round_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = @tir.round((float32x3*)placeholder_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)], dtype=float32x3)
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_31", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [256, 256, 3, 3], []),
             placeholder: Buffer(placeholder_2: handle, float32, [256, 256, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 65536) "parallel" {
    for (ax2: int32, 0, 3) {
      T_cast_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = cast(int32x3, (float32x3*)placeholder_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)])
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op clip
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_clip_15", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [256, 256, 3, 3], []),
             placeholder: Buffer(placeholder_2: handle, int32, [256, 256, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0.i1.fused: int32, 0, 65536) "parallel" {
    for (i2: int32, 0, 3) {
      compute_2[ramp(((i0.i1.fused*9) + (i2*3)), 1, 3)] = max(min((int32x3*)placeholder_2[ramp(((i0.i1.fused*9) + (i2*3)), 1, 3)], broadcast(127, 3)), broadcast(-128, 3))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_32", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [256, 256, 3, 3], []),
             placeholder: Buffer(placeholder_2: handle, int32, [256, 256, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 65536) "parallel" {
    for (ax2: int32, 0, 3) {
      T_cast_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = cast(int8x3, (int32x3*)placeholder_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)])
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op divide
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide_22", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: handle, float32, [1024, 256, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [1024, 256, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  for (ax0.ax1.fused: int32, 0, 262144) "parallel" {
    T_divide_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] / (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op add
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add_42", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: handle, float32, [1024, 256, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [1024, 256, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  for (ax0.ax1.fused: int32, 0, 262144) "parallel" {
    T_add_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] + (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op round
primfn(placeholder_1: handle, T_round_1: handle) -> ()
  attr = {"global_symbol": "fused_round_16", "tir.noalias": True}
  buffers = {T_round: Buffer(T_round_2: handle, float32, [1024, 256, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [1024, 256, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_round_1: T_round} {
  for (ax0.ax1.fused: int32, 0, 262144) "parallel" {
    T_round_2[ax0.ax1.fused] = @tir.round((float32*)placeholder_2[ax0.ax1.fused], dtype=float32)
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_33", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [1024, 256, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [1024, 256, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 262144) "parallel" {
    T_cast_2[ax0.ax1.fused] = cast(int32, (float32*)placeholder_2[ax0.ax1.fused])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op clip
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_clip_16", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [1024, 256, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [1024, 256, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0.i1.fused: int32, 0, 262144) "parallel" {
    compute_2[i0.i1.fused] = max(min((int32*)placeholder_2[i0.i1.fused], 127), -128)
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_34", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [1024, 256, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [1024, 256, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 262144) "parallel" {
    T_cast_2[ax0.ax1.fused] = cast(int8, (int32*)placeholder_2[ax0.ax1.fused])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op divide
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide_23", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: handle, float32, [1024, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [1024, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  for (ax0.ax1.fused: int32, 0, 1024) "parallel" {
    T_divide_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] / (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op add
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add_43", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: handle, float32, [1024, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [1024, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  for (ax0.ax1.fused: int32, 0, 1024) "parallel" {
    T_add_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] + (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op round
primfn(placeholder_1: handle, T_round_1: handle) -> ()
  attr = {"global_symbol": "fused_round_17", "tir.noalias": True}
  buffers = {T_round: Buffer(T_round_2: handle, float32, [1024, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [1024, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_round_1: T_round} {
  for (ax0.ax1.fused: int32, 0, 1024) "parallel" {
    T_round_2[ax0.ax1.fused] = @tir.round((float32*)placeholder_2[ax0.ax1.fused], dtype=float32)
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_35", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [1024, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [1024, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 1024) "parallel" {
    T_cast_2[ax0.ax1.fused] = cast(int32, (float32*)placeholder_2[ax0.ax1.fused])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op clip
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_clip_17", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [1024, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [1024, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0.i1.fused: int32, 0, 1024) "parallel" {
    compute_2[i0.i1.fused] = (int32*)placeholder_2[i0.i1.fused]
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_36", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [1024, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [1024, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 1024) "parallel" {
    T_cast_2[ax0.ax1.fused] = (int32*)placeholder_2[ax0.ax1.fused]
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op divide
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide_24", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: handle, float32, [1024, 512, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [1024, 512, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  for (ax0.ax1.fused: int32, 0, 524288) "parallel" {
    T_divide_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] / (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op add
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add_44", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: handle, float32, [1024, 512, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [1024, 512, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  for (ax0.ax1.fused: int32, 0, 524288) "parallel" {
    T_add_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] + (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op round
primfn(placeholder_1: handle, T_round_1: handle) -> ()
  attr = {"global_symbol": "fused_round_18", "tir.noalias": True}
  buffers = {T_round: Buffer(T_round_2: handle, float32, [1024, 512, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [1024, 512, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_round_1: T_round} {
  for (ax0.ax1.fused: int32, 0, 524288) "parallel" {
    T_round_2[ax0.ax1.fused] = @tir.round((float32*)placeholder_2[ax0.ax1.fused], dtype=float32)
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_37", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [1024, 512, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [1024, 512, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 524288) "parallel" {
    T_cast_2[ax0.ax1.fused] = cast(int32, (float32*)placeholder_2[ax0.ax1.fused])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op clip
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_clip_18", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [1024, 512, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [1024, 512, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0.i1.fused: int32, 0, 524288) "parallel" {
    compute_2[i0.i1.fused] = max(min((int32*)placeholder_2[i0.i1.fused], 127), -128)
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_38", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [1024, 512, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [1024, 512, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 524288) "parallel" {
    T_cast_2[ax0.ax1.fused] = cast(int8, (int32*)placeholder_2[ax0.ax1.fused])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op divide
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide_25", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_4: handle, float32, [256, 1024, 1, 1], []),
             T_divide: Buffer(T_divide_2: handle, float32, [256, 1024, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  for (ax0.ax1.fused: int32, 0, 262144) "parallel" {
    T_divide_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] / (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op add
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add_45", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: handle, float32, [256, 1024, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [256, 1024, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  for (ax0.ax1.fused: int32, 0, 262144) "parallel" {
    T_add_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] + (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op round
primfn(placeholder_1: handle, T_round_1: handle) -> ()
  attr = {"global_symbol": "fused_round_19", "tir.noalias": True}
  buffers = {T_round: Buffer(T_round_2: handle, float32, [256, 1024, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [256, 1024, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_round_1: T_round} {
  for (ax0.ax1.fused: int32, 0, 262144) "parallel" {
    T_round_2[ax0.ax1.fused] = @tir.round((float32*)placeholder_2[ax0.ax1.fused], dtype=float32)
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_39", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [256, 1024, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [256, 1024, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 262144) "parallel" {
    T_cast_2[ax0.ax1.fused] = cast(int32, (float32*)placeholder_2[ax0.ax1.fused])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op clip
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_clip_19", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [256, 1024, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [256, 1024, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0.i1.fused: int32, 0, 262144) "parallel" {
    compute_2[i0.i1.fused] = max(min((int32*)placeholder_2[i0.i1.fused], 127), -128)
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_40", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [256, 1024, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [256, 1024, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 262144) "parallel" {
    T_cast_2[ax0.ax1.fused] = cast(int8, (int32*)placeholder_2[ax0.ax1.fused])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op divide
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide_26", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_4: handle, float32, [512, 1024, 1, 1], []),
             T_divide: Buffer(T_divide_2: handle, float32, [512, 1024, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  for (ax0.ax1.fused: int32, 0, 524288) "parallel" {
    T_divide_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] / (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op add
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add_46", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: handle, float32, [512, 1024, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [512, 1024, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  for (ax0.ax1.fused: int32, 0, 524288) "parallel" {
    T_add_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] + (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op round
primfn(placeholder_1: handle, T_round_1: handle) -> ()
  attr = {"global_symbol": "fused_round_20", "tir.noalias": True}
  buffers = {T_round: Buffer(T_round_2: handle, float32, [512, 1024, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [512, 1024, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_round_1: T_round} {
  for (ax0.ax1.fused: int32, 0, 524288) "parallel" {
    T_round_2[ax0.ax1.fused] = @tir.round((float32*)placeholder_2[ax0.ax1.fused], dtype=float32)
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_41", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [512, 1024, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [512, 1024, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 524288) "parallel" {
    T_cast_2[ax0.ax1.fused] = cast(int32, (float32*)placeholder_2[ax0.ax1.fused])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op clip
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_clip_20", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [512, 1024, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [512, 1024, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0.i1.fused: int32, 0, 524288) "parallel" {
    compute_2[i0.i1.fused] = max(min((int32*)placeholder_2[i0.i1.fused], 127), -128)
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_42", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [512, 1024, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [512, 1024, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 524288) "parallel" {
    T_cast_2[ax0.ax1.fused] = cast(int8, (int32*)placeholder_2[ax0.ax1.fused])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op divide
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide_27", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: handle, float32, [512, 512, 3, 3], []),
             placeholder: Buffer(placeholder_4: handle, float32, [512, 512, 3, 3], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  for (ax0.ax1.fused: int32, 0, 262144) "parallel" {
    for (ax2: int32, 0, 3) {
      T_divide_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = ((float32x3*)placeholder_4[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] / broadcast((float32*)placeholder_5[0], 3))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op add
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add_47", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: handle, float32, [512, 512, 3, 3], []),
             placeholder: Buffer(placeholder_4: handle, float32, [512, 512, 3, 3], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  for (ax0.ax1.fused: int32, 0, 262144) "parallel" {
    for (ax2: int32, 0, 3) {
      T_add_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = ((float32x3*)placeholder_4[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] + broadcast((float32*)placeholder_5[0], 3))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op round
primfn(placeholder_1: handle, T_round_1: handle) -> ()
  attr = {"global_symbol": "fused_round_21", "tir.noalias": True}
  buffers = {T_round: Buffer(T_round_2: handle, float32, [512, 512, 3, 3], []),
             placeholder: Buffer(placeholder_2: handle, float32, [512, 512, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, T_round_1: T_round} {
  for (ax0.ax1.fused: int32, 0, 262144) "parallel" {
    for (ax2: int32, 0, 3) {
      T_round_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = @tir.round((float32x3*)placeholder_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)], dtype=float32x3)
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_43", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [512, 512, 3, 3], []),
             placeholder: Buffer(placeholder_2: handle, float32, [512, 512, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 262144) "parallel" {
    for (ax2: int32, 0, 3) {
      T_cast_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = cast(int32x3, (float32x3*)placeholder_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)])
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op clip
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_clip_21", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [512, 512, 3, 3], []),
             placeholder: Buffer(placeholder_2: handle, int32, [512, 512, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0.i1.fused: int32, 0, 262144) "parallel" {
    for (i2: int32, 0, 3) {
      compute_2[ramp(((i0.i1.fused*9) + (i2*3)), 1, 3)] = max(min((int32x3*)placeholder_2[ramp(((i0.i1.fused*9) + (i2*3)), 1, 3)], broadcast(127, 3)), broadcast(-128, 3))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_44", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [512, 512, 3, 3], []),
             placeholder: Buffer(placeholder_2: handle, int32, [512, 512, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 262144) "parallel" {
    for (ax2: int32, 0, 3) {
      T_cast_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = cast(int8x3, (int32x3*)placeholder_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)])
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op divide
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide_28", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: handle, float32, [2048, 512, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [2048, 512, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  for (ax0.ax1.fused: int32, 0, 1048576) "parallel" {
    T_divide_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] / (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op add
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add_48", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: handle, float32, [2048, 512, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [2048, 512, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  for (ax0.ax1.fused: int32, 0, 1048576) "parallel" {
    T_add_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] + (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op round
primfn(placeholder_1: handle, T_round_1: handle) -> ()
  attr = {"global_symbol": "fused_round_22", "tir.noalias": True}
  buffers = {T_round: Buffer(T_round_2: handle, float32, [2048, 512, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [2048, 512, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_round_1: T_round} {
  for (ax0.ax1.fused: int32, 0, 1048576) "parallel" {
    T_round_2[ax0.ax1.fused] = @tir.round((float32*)placeholder_2[ax0.ax1.fused], dtype=float32)
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_45", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [2048, 512, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [2048, 512, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 1048576) "parallel" {
    T_cast_2[ax0.ax1.fused] = cast(int32, (float32*)placeholder_2[ax0.ax1.fused])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op clip
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_clip_22", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [2048, 512, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [2048, 512, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0.i1.fused: int32, 0, 1048576) "parallel" {
    compute_2[i0.i1.fused] = max(min((int32*)placeholder_2[i0.i1.fused], 127), -128)
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_46", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [2048, 512, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [2048, 512, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 1048576) "parallel" {
    T_cast_2[ax0.ax1.fused] = cast(int8, (int32*)placeholder_2[ax0.ax1.fused])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op divide
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide_29", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: handle, float32, [2048, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [2048, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  for (ax0.ax1.fused: int32, 0, 2048) "parallel" {
    T_divide_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] / (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op add
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add_49", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: handle, float32, [2048, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [2048, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  for (ax0.ax1.fused: int32, 0, 2048) "parallel" {
    T_add_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] + (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op round
primfn(placeholder_1: handle, T_round_1: handle) -> ()
  attr = {"global_symbol": "fused_round_23", "tir.noalias": True}
  buffers = {T_round: Buffer(T_round_2: handle, float32, [2048, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [2048, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_round_1: T_round} {
  for (ax0.ax1.fused: int32, 0, 2048) "parallel" {
    T_round_2[ax0.ax1.fused] = @tir.round((float32*)placeholder_2[ax0.ax1.fused], dtype=float32)
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_47", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [2048, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [2048, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 2048) "parallel" {
    T_cast_2[ax0.ax1.fused] = cast(int32, (float32*)placeholder_2[ax0.ax1.fused])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op clip
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_clip_23", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [2048, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [2048, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0.i1.fused: int32, 0, 2048) "parallel" {
    compute_2[i0.i1.fused] = (int32*)placeholder_2[i0.i1.fused]
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_48", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [2048, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [2048, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 2048) "parallel" {
    T_cast_2[ax0.ax1.fused] = (int32*)placeholder_2[ax0.ax1.fused]
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op divide
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide_30", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: handle, float32, [2048, 1024, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [2048, 1024, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  for (ax0.ax1.fused: int32, 0, 2097152) "parallel" {
    T_divide_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] / (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op add
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add_50", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: handle, float32, [2048, 1024, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [2048, 1024, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  for (ax0.ax1.fused: int32, 0, 2097152) "parallel" {
    T_add_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] + (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op round
primfn(placeholder_1: handle, T_round_1: handle) -> ()
  attr = {"global_symbol": "fused_round_24", "tir.noalias": True}
  buffers = {T_round: Buffer(T_round_2: handle, float32, [2048, 1024, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [2048, 1024, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_round_1: T_round} {
  for (ax0.ax1.fused: int32, 0, 2097152) "parallel" {
    T_round_2[ax0.ax1.fused] = @tir.round((float32*)placeholder_2[ax0.ax1.fused], dtype=float32)
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_49", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [2048, 1024, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [2048, 1024, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 2097152) "parallel" {
    T_cast_2[ax0.ax1.fused] = cast(int32, (float32*)placeholder_2[ax0.ax1.fused])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op clip
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_clip_24", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [2048, 1024, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [2048, 1024, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0.i1.fused: int32, 0, 2097152) "parallel" {
    compute_2[i0.i1.fused] = max(min((int32*)placeholder_2[i0.i1.fused], 127), -128)
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_50", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [2048, 1024, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [2048, 1024, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 2097152) "parallel" {
    T_cast_2[ax0.ax1.fused] = cast(int8, (int32*)placeholder_2[ax0.ax1.fused])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op divide
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide_31", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: handle, float32, [512, 2048, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [512, 2048, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  for (ax0.ax1.fused: int32, 0, 1048576) "parallel" {
    T_divide_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] / (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op add
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add_51", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: handle, float32, [512, 2048, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [512, 2048, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  for (ax0.ax1.fused: int32, 0, 1048576) "parallel" {
    T_add_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] + (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op round
primfn(placeholder_1: handle, T_round_1: handle) -> ()
  attr = {"global_symbol": "fused_round_25", "tir.noalias": True}
  buffers = {T_round: Buffer(T_round_2: handle, float32, [512, 2048, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [512, 2048, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_round_1: T_round} {
  for (ax0.ax1.fused: int32, 0, 1048576) "parallel" {
    T_round_2[ax0.ax1.fused] = @tir.round((float32*)placeholder_2[ax0.ax1.fused], dtype=float32)
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_51", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [512, 2048, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [512, 2048, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 1048576) "parallel" {
    T_cast_2[ax0.ax1.fused] = cast(int32, (float32*)placeholder_2[ax0.ax1.fused])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op clip
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_clip_25", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [512, 2048, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [512, 2048, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0.i1.fused: int32, 0, 1048576) "parallel" {
    compute_2[i0.i1.fused] = max(min((int32*)placeholder_2[i0.i1.fused], 127), -128)
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_52", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [512, 2048, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [512, 2048, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 1048576) "parallel" {
    T_cast_2[ax0.ax1.fused] = cast(int8, (int32*)placeholder_2[ax0.ax1.fused])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op layout_transform
primfn(placeholder_1: handle, T_layout_trans_1: handle) -> ()
  attr = {"global_symbol": "fused_layout_transform", "tir.noalias": True}
  buffers = {T_layout_trans: Buffer(T_layout_trans_2: handle, int8, [16, 1, 7, 7, 4, 4], []),
             placeholder: Buffer(placeholder_2: handle, int8, [64, 4, 7, 7], [])}
  buffer_map = {placeholder_1: placeholder, T_layout_trans_1: T_layout_trans} {
  for (ax0.ax1.fused.ax2.fused: int32, 0, 112) "parallel" {
    for (ax3: int32, 0, 7) {
      for (ax4: int32, 0, 4) {
        T_layout_trans_2[ramp((((ax0.ax1.fused.ax2.fused*112) + (ax3*16)) + (ax4*4)), 1, 4)] = (int8x4*)placeholder_2[ramp(((((floordiv(ax0.ax1.fused.ax2.fused, 7)*784) + (ax4*196)) + (floormod(ax0.ax1.fused.ax2.fused, 7)*7)) + ax3), 49, 4)]
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op expand_dims
primfn(placeholder_1: handle, T_expand_dims_1: handle) -> ()
  attr = {"global_symbol": "fused_expand_dims_12", "tir.noalias": True}
  buffers = {T_expand_dims: Buffer(T_expand_dims_2: handle, int32, [1, 64, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [64, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_expand_dims_1: T_expand_dims} {
  for (ax0.ax1.fused: int32, 0, 64) "parallel" {
    T_expand_dims_2[ax0.ax1.fused] = (int32*)placeholder_2[ax0.ax1.fused]
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op layout_transform
primfn(placeholder_1: handle, T_layout_trans_1: handle) -> ()
  attr = {"global_symbol": "fused_layout_transform_1", "tir.noalias": True}
  buffers = {T_layout_trans: Buffer(T_layout_trans_2: handle, int32, [1, 16, 1, 1, 4], []),
             placeholder: Buffer(placeholder_2: handle, int32, [1, 64, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_layout_trans_1: T_layout_trans} {
  for (ax0.ax1.fused.ax2.fused: int32, 0, 16) "parallel" {
    T_layout_trans_2[ramp((ax0.ax1.fused.ax2.fused*4), 1, 4)] = (int32x4*)placeholder_2[ramp((ax0.ax1.fused.ax2.fused*4), 1, 4)]
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op layout_transform
primfn(placeholder_1: handle, T_layout_trans_1: handle) -> ()
  attr = {"global_symbol": "fused_layout_transform_2", "tir.noalias": True}
  buffers = {T_layout_trans: Buffer(T_layout_trans_2: handle, int8, [16, 16, 1, 1, 4, 4], []),
             placeholder: Buffer(placeholder_2: handle, int8, [64, 64, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_layout_trans_1: T_layout_trans} {
  for (ax0.ax1.fused.ax2.fused: int32, 0, 256) "parallel" {
    for (ax4: int32, 0, 4) {
      T_layout_trans_2[ramp(((ax0.ax1.fused.ax2.fused*16) + (ax4*4)), 1, 4)] = (int8x4*)placeholder_2[ramp((((floordiv(ax0.ax1.fused.ax2.fused, 16)*256) + (ax4*64)) + (floormod(ax0.ax1.fused.ax2.fused, 16)*4)), 1, 4)]
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op layout_transform
primfn(placeholder_1: handle, T_layout_trans_1: handle) -> ()
  attr = {"global_symbol": "fused_layout_transform_3", "tir.noalias": True}
  buffers = {T_layout_trans: Buffer(T_layout_trans_2: handle, int8, [16, 16, 3, 3, 4, 4], []),
             placeholder: Buffer(placeholder_2: handle, int8, [64, 64, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, T_layout_trans_1: T_layout_trans} {
  for (ax0.ax1.fused.ax2.fused: int32, 0, 768) "parallel" {
    for (ax3: int32, 0, 3) {
      for (ax4: int32, 0, 4) {
        T_layout_trans_2[ramp((((ax0.ax1.fused.ax2.fused*48) + (ax3*16)) + (ax4*4)), 1, 4)] = (int8x4*)placeholder_2[ramp((((((floordiv(ax0.ax1.fused.ax2.fused, 48)*2304) + (ax4*576)) + (floordiv(floormod(ax0.ax1.fused.ax2.fused, 48), 3)*36)) + (floormod(ax0.ax1.fused.ax2.fused, 3)*3)) + ax3), 9, 4)]
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op layout_transform
primfn(placeholder_1: handle, T_layout_trans_1: handle) -> ()
  attr = {"global_symbol": "fused_layout_transform_4", "tir.noalias": True}
  buffers = {T_layout_trans: Buffer(T_layout_trans_2: handle, int8, [64, 16, 1, 1, 4, 4], []),
             placeholder: Buffer(placeholder_2: handle, int8, [256, 64, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_layout_trans_1: T_layout_trans} {
  for (ax0.ax1.fused.ax2.fused: int32, 0, 1024) "parallel" {
    for (ax4: int32, 0, 4) {
      T_layout_trans_2[ramp(((ax0.ax1.fused.ax2.fused*16) + (ax4*4)), 1, 4)] = (int8x4*)placeholder_2[ramp((((floordiv(ax0.ax1.fused.ax2.fused, 16)*256) + (ax4*64)) + (floormod(ax0.ax1.fused.ax2.fused, 16)*4)), 1, 4)]
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op expand_dims
primfn(placeholder_1: handle, T_expand_dims_1: handle) -> ()
  attr = {"global_symbol": "fused_expand_dims_13", "tir.noalias": True}
  buffers = {T_expand_dims: Buffer(T_expand_dims_2: handle, int32, [1, 256, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [256, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_expand_dims_1: T_expand_dims} {
  for (ax0.ax1.fused: int32, 0, 256) "parallel" {
    T_expand_dims_2[ax0.ax1.fused] = (int32*)placeholder_2[ax0.ax1.fused]
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op layout_transform
primfn(placeholder_1: handle, T_layout_trans_1: handle) -> ()
  attr = {"global_symbol": "fused_layout_transform_5", "tir.noalias": True}
  buffers = {T_layout_trans: Buffer(T_layout_trans_2: handle, int32, [1, 64, 1, 1, 4], []),
             placeholder: Buffer(placeholder_2: handle, int32, [1, 256, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_layout_trans_1: T_layout_trans} {
  for (ax0.ax1.fused.ax2.fused: int32, 0, 64) "parallel" {
    T_layout_trans_2[ramp((ax0.ax1.fused.ax2.fused*4), 1, 4)] = (int32x4*)placeholder_2[ramp((ax0.ax1.fused.ax2.fused*4), 1, 4)]
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op layout_transform
primfn(placeholder_1: handle, T_layout_trans_1: handle) -> ()
  attr = {"global_symbol": "fused_layout_transform_6", "tir.noalias": True}
  buffers = {T_layout_trans: Buffer(T_layout_trans_2: handle, int8, [16, 64, 1, 1, 4, 4], []),
             placeholder: Buffer(placeholder_2: handle, int8, [64, 256, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_layout_trans_1: T_layout_trans} {
  for (ax0.ax1.fused.ax2.fused: int32, 0, 1024) "parallel" {
    for (ax4: int32, 0, 4) {
      T_layout_trans_2[ramp(((ax0.ax1.fused.ax2.fused*16) + (ax4*4)), 1, 4)] = (int8x4*)placeholder_2[ramp((((floordiv(ax0.ax1.fused.ax2.fused, 64)*1024) + (ax4*256)) + (floormod(ax0.ax1.fused.ax2.fused, 64)*4)), 1, 4)]
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op layout_transform
primfn(placeholder_1: handle, T_layout_trans_1: handle) -> ()
  attr = {"global_symbol": "fused_layout_transform_7", "tir.noalias": True}
  buffers = {T_layout_trans: Buffer(T_layout_trans_2: handle, int8, [32, 64, 1, 1, 4, 4], []),
             placeholder: Buffer(placeholder_2: handle, int8, [128, 256, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_layout_trans_1: T_layout_trans} {
  for (ax0.ax1.fused.ax2.fused: int32, 0, 2048) "parallel" {
    for (ax4: int32, 0, 4) {
      T_layout_trans_2[ramp(((ax0.ax1.fused.ax2.fused*16) + (ax4*4)), 1, 4)] = (int8x4*)placeholder_2[ramp((((floordiv(ax0.ax1.fused.ax2.fused, 64)*1024) + (ax4*256)) + (floormod(ax0.ax1.fused.ax2.fused, 64)*4)), 1, 4)]
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op expand_dims
primfn(placeholder_1: handle, T_expand_dims_1: handle) -> ()
  attr = {"global_symbol": "fused_expand_dims_14", "tir.noalias": True}
  buffers = {T_expand_dims: Buffer(T_expand_dims_2: handle, int32, [1, 128, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [128, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_expand_dims_1: T_expand_dims} {
  for (ax0.ax1.fused: int32, 0, 128) "parallel" {
    T_expand_dims_2[ax0.ax1.fused] = (int32*)placeholder_2[ax0.ax1.fused]
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op layout_transform
primfn(placeholder_1: handle, T_layout_trans_1: handle) -> ()
  attr = {"global_symbol": "fused_layout_transform_8", "tir.noalias": True}
  buffers = {T_layout_trans: Buffer(T_layout_trans_2: handle, int32, [1, 32, 1, 1, 4], []),
             placeholder: Buffer(placeholder_2: handle, int32, [1, 128, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_layout_trans_1: T_layout_trans} {
  for (ax0.ax1.fused.ax2.fused: int32, 0, 32) "parallel" {
    T_layout_trans_2[ramp((ax0.ax1.fused.ax2.fused*4), 1, 4)] = (int32x4*)placeholder_2[ramp((ax0.ax1.fused.ax2.fused*4), 1, 4)]
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op layout_transform
primfn(placeholder_1: handle, T_layout_trans_1: handle) -> ()
  attr = {"global_symbol": "fused_layout_transform_9", "tir.noalias": True}
  buffers = {T_layout_trans: Buffer(T_layout_trans_2: handle, int8, [32, 32, 3, 3, 4, 4], []),
             placeholder: Buffer(placeholder_2: handle, int8, [128, 128, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, T_layout_trans_1: T_layout_trans} {
  for (ax0.ax1.fused.ax2.fused: int32, 0, 3072) "parallel" {
    for (ax3: int32, 0, 3) {
      for (ax4: int32, 0, 4) {
        T_layout_trans_2[ramp((((ax0.ax1.fused.ax2.fused*48) + (ax3*16)) + (ax4*4)), 1, 4)] = (int8x4*)placeholder_2[ramp((((((floordiv(ax0.ax1.fused.ax2.fused, 96)*4608) + (ax4*1152)) + (floordiv(floormod(ax0.ax1.fused.ax2.fused, 96), 3)*36)) + (floormod(ax0.ax1.fused.ax2.fused, 3)*3)) + ax3), 9, 4)]
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op layout_transform
primfn(placeholder_1: handle, T_layout_trans_1: handle) -> ()
  attr = {"global_symbol": "fused_layout_transform_10", "tir.noalias": True}
  buffers = {T_layout_trans: Buffer(T_layout_trans_2: handle, int8, [128, 32, 1, 1, 4, 4], []),
             placeholder: Buffer(placeholder_2: handle, int8, [512, 128, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_layout_trans_1: T_layout_trans} {
  for (ax0.ax1.fused.ax2.fused: int32, 0, 4096) "parallel" {
    for (ax4: int32, 0, 4) {
      T_layout_trans_2[ramp(((ax0.ax1.fused.ax2.fused*16) + (ax4*4)), 1, 4)] = (int8x4*)placeholder_2[ramp((((floordiv(ax0.ax1.fused.ax2.fused, 32)*512) + (ax4*128)) + (floormod(ax0.ax1.fused.ax2.fused, 32)*4)), 1, 4)]
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op expand_dims
primfn(placeholder_1: handle, T_expand_dims_1: handle) -> ()
  attr = {"global_symbol": "fused_expand_dims_15", "tir.noalias": True}
  buffers = {T_expand_dims: Buffer(T_expand_dims_2: handle, int32, [1, 512, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [512, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_expand_dims_1: T_expand_dims} {
  for (ax0.ax1.fused: int32, 0, 512) "parallel" {
    T_expand_dims_2[ax0.ax1.fused] = (int32*)placeholder_2[ax0.ax1.fused]
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op layout_transform
primfn(placeholder_1: handle, T_layout_trans_1: handle) -> ()
  attr = {"global_symbol": "fused_layout_transform_11", "tir.noalias": True}
  buffers = {T_layout_trans: Buffer(T_layout_trans_2: handle, int32, [1, 128, 1, 1, 4], []),
             placeholder: Buffer(placeholder_2: handle, int32, [1, 512, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_layout_trans_1: T_layout_trans} {
  for (ax0.ax1.fused.ax2.fused: int32, 0, 128) "parallel" {
    T_layout_trans_2[ramp((ax0.ax1.fused.ax2.fused*4), 1, 4)] = (int32x4*)placeholder_2[ramp((ax0.ax1.fused.ax2.fused*4), 1, 4)]
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op layout_transform
primfn(placeholder_1: handle, T_layout_trans_1: handle) -> ()
  attr = {"global_symbol": "fused_layout_transform_12", "tir.noalias": True}
  buffers = {T_layout_trans: Buffer(T_layout_trans_2: handle, int8, [128, 64, 1, 1, 4, 4], []),
             placeholder: Buffer(placeholder_2: handle, int8, [512, 256, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_layout_trans_1: T_layout_trans} {
  for (ax0.ax1.fused.ax2.fused: int32, 0, 8192) "parallel" {
    for (ax4: int32, 0, 4) {
      T_layout_trans_2[ramp(((ax0.ax1.fused.ax2.fused*16) + (ax4*4)), 1, 4)] = (int8x4*)placeholder_2[ramp((((floordiv(ax0.ax1.fused.ax2.fused, 64)*1024) + (ax4*256)) + (floormod(ax0.ax1.fused.ax2.fused, 64)*4)), 1, 4)]
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op layout_transform
primfn(placeholder_1: handle, T_layout_trans_1: handle) -> ()
  attr = {"global_symbol": "fused_layout_transform_13", "tir.noalias": True}
  buffers = {T_layout_trans: Buffer(T_layout_trans_2: handle, int8, [32, 128, 1, 1, 4, 4], []),
             placeholder: Buffer(placeholder_2: handle, int8, [128, 512, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_layout_trans_1: T_layout_trans} {
  for (ax0.ax1.fused.ax2.fused: int32, 0, 4096) "parallel" {
    for (ax4: int32, 0, 4) {
      T_layout_trans_2[ramp(((ax0.ax1.fused.ax2.fused*16) + (ax4*4)), 1, 4)] = (int8x4*)placeholder_2[ramp((((floordiv(ax0.ax1.fused.ax2.fused, 128)*2048) + (ax4*512)) + (floormod(ax0.ax1.fused.ax2.fused, 128)*4)), 1, 4)]
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op layout_transform
primfn(placeholder_1: handle, T_layout_trans_1: handle) -> ()
  attr = {"global_symbol": "fused_layout_transform_14", "tir.noalias": True}
  buffers = {T_layout_trans: Buffer(T_layout_trans_2: handle, int8, [64, 128, 1, 1, 4, 4], []),
             placeholder: Buffer(placeholder_2: handle, int8, [256, 512, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_layout_trans_1: T_layout_trans} {
  for (ax0.ax1.fused.ax2.fused: int32, 0, 8192) "parallel" {
    for (ax4: int32, 0, 4) {
      T_layout_trans_2[ramp(((ax0.ax1.fused.ax2.fused*16) + (ax4*4)), 1, 4)] = (int8x4*)placeholder_2[ramp((((floordiv(ax0.ax1.fused.ax2.fused, 128)*2048) + (ax4*512)) + (floormod(ax0.ax1.fused.ax2.fused, 128)*4)), 1, 4)]
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op layout_transform
primfn(placeholder_1: handle, T_layout_trans_1: handle) -> ()
  attr = {"global_symbol": "fused_layout_transform_15", "tir.noalias": True}
  buffers = {T_layout_trans: Buffer(T_layout_trans_2: handle, int8, [64, 64, 3, 3, 4, 4], []),
             placeholder: Buffer(placeholder_2: handle, int8, [256, 256, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, T_layout_trans_1: T_layout_trans} {
  for (ax0.ax1.fused.ax2.fused: int32, 0, 12288) "parallel" {
    for (ax3: int32, 0, 3) {
      for (ax4: int32, 0, 4) {
        T_layout_trans_2[ramp((((ax0.ax1.fused.ax2.fused*48) + (ax3*16)) + (ax4*4)), 1, 4)] = (int8x4*)placeholder_2[ramp((((((floordiv(ax0.ax1.fused.ax2.fused, 192)*9216) + (ax4*2304)) + (floordiv(floormod(ax0.ax1.fused.ax2.fused, 192), 3)*36)) + (floormod(ax0.ax1.fused.ax2.fused, 3)*3)) + ax3), 9, 4)]
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op layout_transform
primfn(placeholder_1: handle, T_layout_trans_1: handle) -> ()
  attr = {"global_symbol": "fused_layout_transform_16", "tir.noalias": True}
  buffers = {T_layout_trans: Buffer(T_layout_trans_2: handle, int8, [256, 64, 1, 1, 4, 4], []),
             placeholder: Buffer(placeholder_2: handle, int8, [1024, 256, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_layout_trans_1: T_layout_trans} {
  for (ax0.ax1.fused.ax2.fused: int32, 0, 16384) "parallel" {
    for (ax4: int32, 0, 4) {
      T_layout_trans_2[ramp(((ax0.ax1.fused.ax2.fused*16) + (ax4*4)), 1, 4)] = (int8x4*)placeholder_2[ramp((((floordiv(ax0.ax1.fused.ax2.fused, 64)*1024) + (ax4*256)) + (floormod(ax0.ax1.fused.ax2.fused, 64)*4)), 1, 4)]
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op expand_dims
primfn(placeholder_1: handle, T_expand_dims_1: handle) -> ()
  attr = {"global_symbol": "fused_expand_dims_16", "tir.noalias": True}
  buffers = {T_expand_dims: Buffer(T_expand_dims_2: handle, int32, [1, 1024, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [1024, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_expand_dims_1: T_expand_dims} {
  for (ax0.ax1.fused: int32, 0, 1024) "parallel" {
    T_expand_dims_2[ax0.ax1.fused] = (int32*)placeholder_2[ax0.ax1.fused]
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op layout_transform
primfn(placeholder_1: handle, T_layout_trans_1: handle) -> ()
  attr = {"global_symbol": "fused_layout_transform_17", "tir.noalias": True}
  buffers = {T_layout_trans: Buffer(T_layout_trans_2: handle, int32, [1, 256, 1, 1, 4], []),
             placeholder: Buffer(placeholder_2: handle, int32, [1, 1024, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_layout_trans_1: T_layout_trans} {
  for (ax0.ax1.fused.ax2.fused: int32, 0, 256) "parallel" {
    T_layout_trans_2[ramp((ax0.ax1.fused.ax2.fused*4), 1, 4)] = (int32x4*)placeholder_2[ramp((ax0.ax1.fused.ax2.fused*4), 1, 4)]
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op layout_transform
primfn(placeholder_1: handle, T_layout_trans_1: handle) -> ()
  attr = {"global_symbol": "fused_layout_transform_18", "tir.noalias": True}
  buffers = {T_layout_trans: Buffer(T_layout_trans_2: handle, int8, [256, 128, 1, 1, 4, 4], []),
             placeholder: Buffer(placeholder_2: handle, int8, [1024, 512, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_layout_trans_1: T_layout_trans} {
  for (ax0.ax1.fused.ax2.fused: int32, 0, 32768) "parallel" {
    for (ax4: int32, 0, 4) {
      T_layout_trans_2[ramp(((ax0.ax1.fused.ax2.fused*16) + (ax4*4)), 1, 4)] = (int8x4*)placeholder_2[ramp((((floordiv(ax0.ax1.fused.ax2.fused, 128)*2048) + (ax4*512)) + (floormod(ax0.ax1.fused.ax2.fused, 128)*4)), 1, 4)]
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op layout_transform
primfn(placeholder_1: handle, T_layout_trans_1: handle) -> ()
  attr = {"global_symbol": "fused_layout_transform_19", "tir.noalias": True}
  buffers = {T_layout_trans: Buffer(T_layout_trans_2: handle, int8, [64, 256, 1, 1, 4, 4], []),
             placeholder: Buffer(placeholder_2: handle, int8, [256, 1024, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_layout_trans_1: T_layout_trans} {
  for (ax0.ax1.fused.ax2.fused: int32, 0, 16384) "parallel" {
    for (ax4: int32, 0, 4) {
      T_layout_trans_2[ramp(((ax0.ax1.fused.ax2.fused*16) + (ax4*4)), 1, 4)] = (int8x4*)placeholder_2[ramp((((floordiv(ax0.ax1.fused.ax2.fused, 256)*4096) + (ax4*1024)) + (floormod(ax0.ax1.fused.ax2.fused, 256)*4)), 1, 4)]
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op layout_transform
primfn(placeholder_1: handle, T_layout_trans_1: handle) -> ()
  attr = {"global_symbol": "fused_layout_transform_20", "tir.noalias": True}
  buffers = {T_layout_trans: Buffer(T_layout_trans_2: handle, int8, [128, 256, 1, 1, 4, 4], []),
             placeholder: Buffer(placeholder_2: handle, int8, [512, 1024, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_layout_trans_1: T_layout_trans} {
  for (ax0.ax1.fused.ax2.fused: int32, 0, 32768) "parallel" {
    for (ax4: int32, 0, 4) {
      T_layout_trans_2[ramp(((ax0.ax1.fused.ax2.fused*16) + (ax4*4)), 1, 4)] = (int8x4*)placeholder_2[ramp((((floordiv(ax0.ax1.fused.ax2.fused, 256)*4096) + (ax4*1024)) + (floormod(ax0.ax1.fused.ax2.fused, 256)*4)), 1, 4)]
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op layout_transform
primfn(placeholder_1: handle, T_layout_trans_1: handle) -> ()
  attr = {"global_symbol": "fused_layout_transform_21", "tir.noalias": True}
  buffers = {T_layout_trans: Buffer(T_layout_trans_2: handle, int8, [128, 128, 3, 3, 4, 4], []),
             placeholder: Buffer(placeholder_2: handle, int8, [512, 512, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, T_layout_trans_1: T_layout_trans} {
  for (ax0.ax1.fused.ax2.fused: int32, 0, 49152) "parallel" {
    for (ax3: int32, 0, 3) {
      for (ax4: int32, 0, 4) {
        T_layout_trans_2[ramp((((ax0.ax1.fused.ax2.fused*48) + (ax3*16)) + (ax4*4)), 1, 4)] = (int8x4*)placeholder_2[ramp((((((floordiv(ax0.ax1.fused.ax2.fused, 384)*18432) + (ax4*4608)) + (floordiv(floormod(ax0.ax1.fused.ax2.fused, 384), 3)*36)) + (floormod(ax0.ax1.fused.ax2.fused, 3)*3)) + ax3), 9, 4)]
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op layout_transform
primfn(placeholder_1: handle, T_layout_trans_1: handle) -> ()
  attr = {"global_symbol": "fused_layout_transform_22", "tir.noalias": True}
  buffers = {T_layout_trans: Buffer(T_layout_trans_2: handle, int8, [512, 128, 1, 1, 4, 4], []),
             placeholder: Buffer(placeholder_2: handle, int8, [2048, 512, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_layout_trans_1: T_layout_trans} {
  for (ax0.ax1.fused.ax2.fused: int32, 0, 65536) "parallel" {
    for (ax4: int32, 0, 4) {
      T_layout_trans_2[ramp(((ax0.ax1.fused.ax2.fused*16) + (ax4*4)), 1, 4)] = (int8x4*)placeholder_2[ramp((((floordiv(ax0.ax1.fused.ax2.fused, 128)*2048) + (ax4*512)) + (floormod(ax0.ax1.fused.ax2.fused, 128)*4)), 1, 4)]
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op expand_dims
primfn(placeholder_1: handle, T_expand_dims_1: handle) -> ()
  attr = {"global_symbol": "fused_expand_dims_17", "tir.noalias": True}
  buffers = {T_expand_dims: Buffer(T_expand_dims_2: handle, int32, [1, 2048, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [2048, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_expand_dims_1: T_expand_dims} {
  for (ax0.ax1.fused: int32, 0, 2048) "parallel" {
    T_expand_dims_2[ax0.ax1.fused] = (int32*)placeholder_2[ax0.ax1.fused]
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op layout_transform
primfn(placeholder_1: handle, T_layout_trans_1: handle) -> ()
  attr = {"global_symbol": "fused_layout_transform_23", "tir.noalias": True}
  buffers = {T_layout_trans: Buffer(T_layout_trans_2: handle, int32, [1, 512, 1, 1, 4], []),
             placeholder: Buffer(placeholder_2: handle, int32, [1, 2048, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_layout_trans_1: T_layout_trans} {
  for (ax0.ax1.fused.ax2.fused: int32, 0, 512) "parallel" {
    T_layout_trans_2[ramp((ax0.ax1.fused.ax2.fused*4), 1, 4)] = (int32x4*)placeholder_2[ramp((ax0.ax1.fused.ax2.fused*4), 1, 4)]
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op layout_transform
primfn(placeholder_1: handle, T_layout_trans_1: handle) -> ()
  attr = {"global_symbol": "fused_layout_transform_24", "tir.noalias": True}
  buffers = {T_layout_trans: Buffer(T_layout_trans_2: handle, int8, [512, 256, 1, 1, 4, 4], []),
             placeholder: Buffer(placeholder_2: handle, int8, [2048, 1024, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_layout_trans_1: T_layout_trans} {
  for (ax0.ax1.fused.ax2.fused: int32, 0, 131072) "parallel" {
    for (ax4: int32, 0, 4) {
      T_layout_trans_2[ramp(((ax0.ax1.fused.ax2.fused*16) + (ax4*4)), 1, 4)] = (int8x4*)placeholder_2[ramp((((floordiv(ax0.ax1.fused.ax2.fused, 256)*4096) + (ax4*1024)) + (floormod(ax0.ax1.fused.ax2.fused, 256)*4)), 1, 4)]
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op layout_transform
primfn(placeholder_1: handle, T_layout_trans_1: handle) -> ()
  attr = {"global_symbol": "fused_layout_transform_25", "tir.noalias": True}
  buffers = {T_layout_trans: Buffer(T_layout_trans_2: handle, int8, [128, 512, 1, 1, 4, 4], []),
             placeholder: Buffer(placeholder_2: handle, int8, [512, 2048, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_layout_trans_1: T_layout_trans} {
  for (ax0.ax1.fused.ax2.fused: int32, 0, 65536) "parallel" {
    for (ax4: int32, 0, 4) {
      T_layout_trans_2[ramp(((ax0.ax1.fused.ax2.fused*16) + (ax4*4)), 1, 4)] = (int8x4*)placeholder_2[ramp((((floordiv(ax0.ax1.fused.ax2.fused, 512)*8192) + (ax4*2048)) + (floormod(ax0.ax1.fused.ax2.fused, 512)*4)), 1, 4)]
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cuda for op layout_transform
INFO:compile_engine:Use implementation injective.cuda for op nn.batch_flatten
primfn(placeholder_1: handle, tensor_1: handle) -> ()
  attr = {"global_symbol": "fused_layout_transform_nn_batch_flatten", "tir.noalias": True}
  buffers = {tensor: Buffer(tensor_2: handle, float32, [32, 2048], []),
             placeholder: Buffer(placeholder_2: handle, float32, [32, 512, 1, 1, 4], [])}
  buffer_map = {placeholder_1: placeholder, tensor_1: tensor} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 64;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  tensor_2[((blockIdx.x*1024) + threadIdx.x)] = (float32*)placeholder_2[((blockIdx.x*1024) + threadIdx.x)]
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation adaptive_pool.cuda for op nn.global_avg_pool2d
primfn(placeholder_1: handle, tensor_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_global_avg_pool2d_1", "tir.noalias": True}
  buffers = {tensor: Buffer(tensor_2: handle, float32, [32, 512, 1, 1, 4], []),
             placeholder: Buffer(placeholder_2: handle, float32, [32, 512, 7, 7, 4], [])}
  buffer_map = {placeholder_1: placeholder, tensor_1: tensor} {
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 4;
  attr [tensor_3: handle] "storage_scope" = "local";
  allocate(tensor_3, float32, [4]);
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 64;
  attr [IterVar(threadIdx.y: int32, [0:8], "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
  attr [IterVar(threadIdx.x: int32, [0:8], "ThreadIndex", "threadIdx.x")] "thread_extent" = 8 {
    for (ax4: int32, 0, 4) {
      tensor_3[ax4] = 0f32
      for (rv0: int32, 0, 7) {
        for (rv1: int32, 0, 7) {
          tensor_3[ax4] = ((float32*)tensor_3[ax4] + (float32*)placeholder_2[(((((((blockIdx.y*802816) + (threadIdx.y*100352)) + (blockIdx.x*1568)) + (threadIdx.x*196)) + (rv0*28)) + (rv1*4)) + ax4)])
        }
      }
    }
    for (ax4_1: int32, 0, 4) {
      tensor_2[(((((blockIdx.y*16384) + (threadIdx.y*2048)) + (blockIdx.x*32)) + (threadIdx.x*4)) + ax4_1)] = ((float32*)tensor_3[ax4_1]*0.0204082f32)
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op subtract
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op multiply
primfn(placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, placeholder_8: handle, placeholder_9: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_fixed_point_multiply_add_cast_9206029716410883813_", "tir.noalias": True}
  buffers = {placeholder_4: Buffer(placeholder_10: handle, int8, [32, 128, 7, 7, 4], []),
             placeholder_1: Buffer(placeholder_11: handle, int8, [512, 128, 1, 1, 4, 4], []),
             placeholder: Buffer(placeholder_12: handle, int32, [32, 512, 7, 7, 4], []),
             placeholder_3: Buffer(placeholder_13: handle, int32, [1, 512, 1, 1, 4], []),
             T_multiply: Buffer(T_multiply_2: handle, float32, [32, 512, 7, 7, 4], []),
             placeholder_2: Buffer(placeholder_14: handle, int32, [1, 512, 1, 1, 4], [])}
  buffer_map = {placeholder_9: placeholder, placeholder_6: placeholder_1, placeholder_8: placeholder_2, placeholder_7: placeholder_3, T_multiply_1: T_multiply, placeholder_5: placeholder_4} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 32;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [28]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [1568]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [2048]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 32;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7 {
    for (oh.init: int32, 0, 7) "unroll" {
      for (oc_block.init: int32, 0, 4) "unroll" {
        compute[((oh.init*4) + oc_block.init)] = 0
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 7) "unroll" {
      attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
      pad_data.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*448) + (threadIdx.y_1*28)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_10[ramp(((((blockIdx.z*25088) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*448)) + (threadIdx.y_1*28)) + (threadIdx.x_1*4)), 1, 4)]
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 10) "unroll" {
      attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
      attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*112) + (threadIdx.y_2*7)) + threadIdx.x_2) < 1024) {
        if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*16) + threadIdx.y_2) < 147) {
          placeholder.shared[ramp((((floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 64)*256) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*28) + floordiv(((threadIdx.y_2*7) + threadIdx.x_2), 4)), 16)*16)) + (floormod(((threadIdx.y_2*7) + threadIdx.x_2), 4)*4)), 1, 4)] = (int8x4*)placeholder_11[ramp(((((blockIdx.y*32768) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 64)*2048)) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*28) + floordiv(((threadIdx.y_2*7) + threadIdx.x_2), 4)), 16)*16)) + (floormod(((threadIdx.y_2*7) + threadIdx.x_2), 4)*4)), 1, 4)]
        }
      }
    }
    for (ic_chunk.outer.outer: int32, 0, 7) {
      attr [pad_data.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1: int32, 0, 7) "unroll" {
        attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
        attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
        pad_data.shared[ramp(((((floormod((ic_chunk.outer.outer + 1), 2)*3136) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*448)) + (threadIdx.y_1*28)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_10[ramp(((((((blockIdx.z*25088) + (ic_chunk.outer.outer*3136)) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*448)) + (threadIdx.y_1*28)) + (threadIdx.x_1*4)) + 3136), 1, 4)]
      }
      attr [placeholder.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 10) "unroll" {
        attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
        attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*112) + (threadIdx.y_2*7)) + threadIdx.x_2) < 1024) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*16) + threadIdx.y_2) < 147) {
            placeholder.shared[ramp(((((floormod((ic_chunk.outer.outer + 1), 2)*4096) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 64)*256)) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*28) + floordiv(((threadIdx.y_2*7) + threadIdx.x_2), 4)), 16)*16)) + (floormod(((threadIdx.y_2*7) + threadIdx.x_2), 4)*4)), 1, 4)] = (int8x4*)placeholder_11[ramp(((((((blockIdx.y*32768) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 64)*2048)) + (ic_chunk.outer.outer*256)) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*28) + floordiv(((threadIdx.y_2*7) + threadIdx.x_2), 4)), 16)*16)) + (floormod(((threadIdx.y_2*7) + threadIdx.x_2), 4)*4)) + 256), 1, 4)]
          }
        }
      }
      for (ic_chunk.inner: int32, 0, 16) "unroll" {
        for (oh: int32, 0, 7) "unroll" {
          for (oc_block: int32, 0, 4) "unroll" {
            compute[((oh*4) + oc_block)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*3136) + (ic_chunk.inner*196)) + (oh*28)) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*4096) + (threadIdx.y*256)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[((oh*4) + oc_block)], dtype=int32)
          }
        }
      }
    }
    for (ic_chunk.inner_1: int32, 0, 16) "unroll" {
      for (oh_1: int32, 0, 7) "unroll" {
        for (oc_block_1: int32, 0, 4) "unroll" {
          compute[((oh_1*4) + oc_block_1)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((ic_chunk.inner_1*196) + (oh_1*28)) + (threadIdx.x*4)) + 3136), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*256) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 4096), 1, 4)], (int32*)compute[((oh_1*4) + oc_block_1)], dtype=int32)
        }
      }
    }
    for (ax2.inner.inner.inner: int32, 0, 7) "unroll" {
      for (ax4: int32, 0, 4) "unroll" {
        T_multiply_2[((((((blockIdx.z*100352) + (blockIdx.y*3136)) + (threadIdx.y*196)) + (ax2.inner.inner.inner*28)) + (threadIdx.x*4)) + ax4)] = (cast(float32, max((@tir.q_multiply_shift((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[((ax2.inner.inner.inner*4) + ax4)], 1156257710, 31, 19, dtype=int32) + (int32*)placeholder_13[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 2147483386, 31, 0, dtype=int32) + (int32*)placeholder_14[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 2136531316, 31, 0, dtype=int32) + @tir.q_multiply_shift((int32*)placeholder_12[((((((blockIdx.z*100352) + (blockIdx.y*3136)) + (threadIdx.y*196)) + (ax2.inner.inner.inner*28)) + (threadIdx.x*4)) + ax4)], 2140100076, 31, -4, dtype=int32)), 0))*1.46121e-08f32)
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_nn_relu_cast_fixed_point_mult_18399029763786111876_", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [32, 128, 7, 7, 4], []),
             placeholder_2: Buffer(placeholder_6: handle, int32, [1, 128, 1, 1, 4], []),
             placeholder: Buffer(placeholder_7: handle, int8, [32, 128, 7, 7, 4], []),
             placeholder_1: Buffer(placeholder_8: handle, int8, [128, 128, 3, 3, 4, 4], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 4;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [16]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [864]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [1152]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 16;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 7;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7 {
    for (n.init: int32, 0, 4) "unroll" {
      for (oc_block.init: int32, 0, 4) "unroll" {
        compute[((n.init*4) + oc_block.init)] = 0
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 4) "unroll" {
      attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
      attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
      if (((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1) < 432) {
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*16) + (threadIdx.z_1*8)) + threadIdx.y_1) < 62) {
          pad_data.shared[ramp(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*448) + (threadIdx.z_1*224)) + (threadIdx.y_1*28)) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((1 <= (floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1), 27), 9) + blockIdx.x)) && ((floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1), 27), 9) + blockIdx.x) < 8)) && (1 <= floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1), 9))) && (floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1), 9) < 8)), (int8x4*)placeholder_7[ramp((((((((blockIdx.z*200704) + (floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1), 54)*25088)) + (floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1), 54), 27)*196)) + (floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1), 27), 9)*28)) + (blockIdx.x*28)) + (floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1), 9)*4)) - 32), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
        }
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 6) "unroll" {
      attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
      attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
      attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
      if (((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*112) + (threadIdx.z_2*56)) + (threadIdx.y_2*7)) + threadIdx.x_2) < 576) {
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*16) + (threadIdx.z_2*8)) + threadIdx.y_2) < 83) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*2) + threadIdx.z_2) < 11) {
            placeholder.shared[ramp((((floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*112) + (threadIdx.z_2*56)) + (threadIdx.y_2*7)) + threadIdx.x_2), 12)*48) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*28) + (threadIdx.z_2*14)) + floordiv(((threadIdx.y_2*7) + threadIdx.x_2), 4)), 3)*16)) + (floormod(((threadIdx.y_2*7) + threadIdx.x_2), 4)*4)), 1, 4)] = (int8x4*)placeholder_8[ramp((((((blockIdx.y*147456) + (floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*112) + (threadIdx.z_2*56)) + (threadIdx.y_2*7)) + threadIdx.x_2), 72)*18432)) + (floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*112) + (threadIdx.z_2*56)) + (threadIdx.y_2*7)) + threadIdx.x_2), 72), 12)*48)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*28) + (threadIdx.z_2*14)) + floordiv(((threadIdx.y_2*7) + threadIdx.x_2), 4)), 3)*16)) + (floormod(((threadIdx.y_2*7) + threadIdx.x_2), 4)*4)), 1, 4)]
          }
        }
      }
    }
    for (ic_chunk.outer.outer: int32, 0, 63) {
      attr [pad_data.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1: int32, 0, 4) "unroll" {
        attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
        attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
        attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
        if (((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1) < 432) {
          if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*16) + (threadIdx.z_1*8)) + threadIdx.y_1) < 62) {
            pad_data.shared[ramp((((((floormod((ic_chunk.outer.outer + 1), 2)*1728) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*448)) + (threadIdx.z_1*224)) + (threadIdx.y_1*28)) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((1 <= (floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1), 27), 9) + blockIdx.x)) && ((floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1), 27), 9) + blockIdx.x) < 8)) && (1 <= floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1), 9))) && (floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1), 9) < 8)), (int8x4*)placeholder_7[ramp(((((((((blockIdx.z*200704) + (floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1), 54)*25088)) + (ic_chunk.outer.outer*392)) + (floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1), 54), 27)*196)) + (floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1), 27), 9)*28)) + (blockIdx.x*28)) + (floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1), 9)*4)) + 360), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
          }
        }
      }
      attr [placeholder.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 6) "unroll" {
        attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
        attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
        attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
        if (((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*112) + (threadIdx.z_2*56)) + (threadIdx.y_2*7)) + threadIdx.x_2) < 576) {
          if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*16) + (threadIdx.z_2*8)) + threadIdx.y_2) < 83) {
            if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*2) + threadIdx.z_2) < 11) {
              placeholder.shared[ramp(((((floormod((ic_chunk.outer.outer + 1), 2)*2304) + (floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*112) + (threadIdx.z_2*56)) + (threadIdx.y_2*7)) + threadIdx.x_2), 12)*48)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*28) + (threadIdx.z_2*14)) + floordiv(((threadIdx.y_2*7) + threadIdx.x_2), 4)), 3)*16)) + (floormod(((threadIdx.y_2*7) + threadIdx.x_2), 4)*4)), 1, 4)] = (int8x4*)placeholder_8[ramp((((((((blockIdx.y*147456) + (floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*112) + (threadIdx.z_2*56)) + (threadIdx.y_2*7)) + threadIdx.x_2), 72)*18432)) + (ic_chunk.outer.outer*288)) + (floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*112) + (threadIdx.z_2*56)) + (threadIdx.y_2*7)) + threadIdx.x_2), 72), 12)*48)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*28) + (threadIdx.z_2*14)) + floordiv(((threadIdx.y_2*7) + threadIdx.x_2), 4)), 3)*16)) + (floormod(((threadIdx.y_2*7) + threadIdx.x_2), 4)*4)) + 288), 1, 4)]
            }
          }
        }
      }
      for (kh.inner: int32, 0, 3) "unroll" {
        for (ic_chunk.inner: int32, 0, 2) "unroll" {
          for (kw.inner: int32, 0, 3) "unroll" {
            for (n: int32, 0, 4) "unroll" {
              for (oc_block: int32, 0, 4) "unroll" {
                compute[((n*4) + oc_block)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((((floormod(ic_chunk.outer.outer, 2)*1728) + (threadIdx.z*864)) + (n*216)) + (ic_chunk.inner*108)) + (kh.inner*36)) + (threadIdx.x*4)) + (kw.inner*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((((floormod(ic_chunk.outer.outer, 2)*2304) + (threadIdx.y*288)) + (ic_chunk.inner*144)) + (kh.inner*48)) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[((n*4) + oc_block)], dtype=int32)
              }
            }
          }
        }
      }
    }
    for (kh.inner_1: int32, 0, 3) "unroll" {
      for (ic_chunk.inner_1: int32, 0, 2) "unroll" {
        for (kw.inner_1: int32, 0, 3) "unroll" {
          for (n_1: int32, 0, 4) "unroll" {
            for (oc_block_1: int32, 0, 4) "unroll" {
              compute[((n_1*4) + oc_block_1)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((((threadIdx.z*864) + (n_1*216)) + (ic_chunk.inner_1*108)) + (kh.inner_1*36)) + (threadIdx.x*4)) + (kw.inner_1*4)) + 1728), 1, 4)], (int8x4*)placeholder.shared[ramp(((((((threadIdx.y*288) + (ic_chunk.inner_1*144)) + (kh.inner_1*48)) + (kw.inner_1*16)) + (oc_block_1*4)) + 2304), 1, 4)], (int32*)compute[((n_1*4) + oc_block_1)], dtype=int32)
            }
          }
        }
      }
    }
    for (ax0.inner.inner.inner.inner: int32, 0, 4) "unroll" {
      for (ax4: int32, 0, 4) "unroll" {
        T_cast_2[((((((((blockIdx.z*200704) + (threadIdx.z*100352)) + (ax0.inner.inner.inner.inner*25088)) + (blockIdx.y*1568)) + (threadIdx.y*196)) + (blockIdx.x*28)) + (threadIdx.x*4)) + ax4)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((int32*)compute[((ax0.inner.inner.inner.inner*4) + ax4)], 1529959532, 31, 16, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*32) + (threadIdx.y*4)) + ax4)]), 0), 2094848558, 31, -24, dtype=int32), 127), -128))
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_add_cast_nn_relu_cast_fixed_p_13766817817639592840_", "tir.noalias": True}
  buffers = {placeholder_3: Buffer(placeholder_8: handle, int8, [128, 512, 1, 1, 4, 4], []),
             placeholder_2: Buffer(placeholder_9: handle, int32, [1, 128, 1, 1, 4], []),
             placeholder_1: Buffer(placeholder_10: handle, int8, [32, 512, 7, 7, 4], []),
             placeholder: Buffer(placeholder_11: handle, int32, [1, 128, 1, 1, 4], []),
             T_cast: Buffer(T_cast_2: handle, int8, [32, 128, 7, 7, 4], [])}
  buffer_map = {placeholder_6: placeholder, T_cast_1: T_cast, placeholder_4: placeholder_1, placeholder_7: placeholder_2, placeholder_5: placeholder_3} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 8;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [32]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [224]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [1024]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 4;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 7;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7 {
    for (oc_block.init: int32, 0, 4) "unroll" {
      compute[oc_block.init] = 0
      compute[(oc_block.init + 8)] = 0
      compute[(oc_block.init + 16)] = 0
      compute[(oc_block.init + 24)] = 0
      compute[(oc_block.init + 4)] = 0
      compute[(oc_block.init + 12)] = 0
      compute[(oc_block.init + 20)] = 0
      compute[(oc_block.init + 28)] = 0
    }
    for (ic_chunk.outer: int32, 0, 64) {
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 2) "unroll" {
        attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
        attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
        pad_data.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*448) + (threadIdx.y_1*28)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_10[ramp((((((((blockIdx.z*401408) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*200704)) + (floordiv(threadIdx.y_1, 8)*100352)) + (ic_chunk.outer*1568)) + (floormod(threadIdx.y_1, 8)*196)) + (blockIdx.x*28)) + (threadIdx.x_1*4)), 1, 4)]
      }
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 10) "unroll" {
        attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*112) + (threadIdx.y_2*7)) + threadIdx.x_2) < 1024) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*16) + threadIdx.y_2) < 147) {
            placeholder.shared[ramp((((floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 32)*128) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*28) + floordiv(((threadIdx.y_2*7) + threadIdx.x_2), 4)), 8)*16)) + (floormod(((threadIdx.y_2*7) + threadIdx.x_2), 4)*4)), 1, 4)] = (int8x4*)placeholder_8[ramp((((((blockIdx.y*262144) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 32)*8192)) + (ic_chunk.outer*128)) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*28) + floordiv(((threadIdx.y_2*7) + threadIdx.x_2), 4)), 8)*16)) + (floormod(((threadIdx.y_2*7) + threadIdx.x_2), 4)*4)), 1, 4)]
          }
        }
      }
      for (ic_chunk.inner: int32, 0, 8) "unroll" {
        for (oc_block: int32, 0, 4) "unroll" {
          compute[oc_block] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((ic_chunk.inner*28) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.y*128) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[oc_block], dtype=int32)
          compute[(oc_block + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*28) + (threadIdx.x*4)) + 224), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.y*128) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 8)], dtype=int32)
          compute[(oc_block + 16)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*28) + (threadIdx.x*4)) + 448), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.y*128) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 16)], dtype=int32)
          compute[(oc_block + 24)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*28) + (threadIdx.x*4)) + 672), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.y*128) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 24)], dtype=int32)
          compute[(oc_block + 4)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((ic_chunk.inner*28) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*128) + (ic_chunk.inner*16)) + (oc_block*4)) + 2048), 1, 4)], (int32*)compute[(oc_block + 4)], dtype=int32)
          compute[(oc_block + 12)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*28) + (threadIdx.x*4)) + 224), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*128) + (ic_chunk.inner*16)) + (oc_block*4)) + 2048), 1, 4)], (int32*)compute[(oc_block + 12)], dtype=int32)
          compute[(oc_block + 20)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*28) + (threadIdx.x*4)) + 448), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*128) + (ic_chunk.inner*16)) + (oc_block*4)) + 2048), 1, 4)], (int32*)compute[(oc_block + 20)], dtype=int32)
          compute[(oc_block + 28)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*28) + (threadIdx.x*4)) + 672), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*128) + (ic_chunk.inner*16)) + (oc_block*4)) + 2048), 1, 4)], (int32*)compute[(oc_block + 28)], dtype=int32)
        }
      }
    }
    for (ax4: int32, 0, 4) "unroll" {
      T_cast_2[((((((blockIdx.z*100352) + (blockIdx.y*6272)) + (threadIdx.y*196)) + (blockIdx.x*28)) + (threadIdx.x*4)) + ax4)] = cast(int8, max(min(@tir.q_multiply_shift(max(((@tir.q_multiply_shift((int32*)compute[ax4], 1292030419, 31, 17, dtype=int32) + (int32*)placeholder_11[(((blockIdx.y*128) + (threadIdx.y*4)) + ax4)]) + (int32*)placeholder_9[(((blockIdx.y*128) + (threadIdx.y*4)) + ax4)]), 0), 1145587898, 31, -23, dtype=int32), 127), -128))
      T_cast_2[(((((((blockIdx.z*100352) + (blockIdx.y*6272)) + (threadIdx.y*196)) + (blockIdx.x*28)) + (threadIdx.x*4)) + ax4) + 25088)] = cast(int8, max(min(@tir.q_multiply_shift(max(((@tir.q_multiply_shift((int32*)compute[(ax4 + 8)], 1292030419, 31, 17, dtype=int32) + (int32*)placeholder_11[(((blockIdx.y*128) + (threadIdx.y*4)) + ax4)]) + (int32*)placeholder_9[(((blockIdx.y*128) + (threadIdx.y*4)) + ax4)]), 0), 1145587898, 31, -23, dtype=int32), 127), -128))
      T_cast_2[(((((((blockIdx.z*100352) + (blockIdx.y*6272)) + (threadIdx.y*196)) + (blockIdx.x*28)) + (threadIdx.x*4)) + ax4) + 50176)] = cast(int8, max(min(@tir.q_multiply_shift(max(((@tir.q_multiply_shift((int32*)compute[(ax4 + 16)], 1292030419, 31, 17, dtype=int32) + (int32*)placeholder_11[(((blockIdx.y*128) + (threadIdx.y*4)) + ax4)]) + (int32*)placeholder_9[(((blockIdx.y*128) + (threadIdx.y*4)) + ax4)]), 0), 1145587898, 31, -23, dtype=int32), 127), -128))
      T_cast_2[(((((((blockIdx.z*100352) + (blockIdx.y*6272)) + (threadIdx.y*196)) + (blockIdx.x*28)) + (threadIdx.x*4)) + ax4) + 75264)] = cast(int8, max(min(@tir.q_multiply_shift(max(((@tir.q_multiply_shift((int32*)compute[(ax4 + 24)], 1292030419, 31, 17, dtype=int32) + (int32*)placeholder_11[(((blockIdx.y*128) + (threadIdx.y*4)) + ax4)]) + (int32*)placeholder_9[(((blockIdx.y*128) + (threadIdx.y*4)) + ax4)]), 0), 1145587898, 31, -23, dtype=int32), 127), -128))
      T_cast_2[(((((((blockIdx.z*100352) + (blockIdx.y*6272)) + (threadIdx.y*196)) + (blockIdx.x*28)) + (threadIdx.x*4)) + ax4) + 3136)] = cast(int8, max(min(@tir.q_multiply_shift(max(((@tir.q_multiply_shift((int32*)compute[(ax4 + 4)], 1292030419, 31, 17, dtype=int32) + (int32*)placeholder_11[((((blockIdx.y*128) + (threadIdx.y*4)) + ax4) + 64)]) + (int32*)placeholder_9[((((blockIdx.y*128) + (threadIdx.y*4)) + ax4) + 64)]), 0), 1145587898, 31, -23, dtype=int32), 127), -128))
      T_cast_2[(((((((blockIdx.z*100352) + (blockIdx.y*6272)) + (threadIdx.y*196)) + (blockIdx.x*28)) + (threadIdx.x*4)) + ax4) + 28224)] = cast(int8, max(min(@tir.q_multiply_shift(max(((@tir.q_multiply_shift((int32*)compute[(ax4 + 12)], 1292030419, 31, 17, dtype=int32) + (int32*)placeholder_11[((((blockIdx.y*128) + (threadIdx.y*4)) + ax4) + 64)]) + (int32*)placeholder_9[((((blockIdx.y*128) + (threadIdx.y*4)) + ax4) + 64)]), 0), 1145587898, 31, -23, dtype=int32), 127), -128))
      T_cast_2[(((((((blockIdx.z*100352) + (blockIdx.y*6272)) + (threadIdx.y*196)) + (blockIdx.x*28)) + (threadIdx.x*4)) + ax4) + 53312)] = cast(int8, max(min(@tir.q_multiply_shift(max(((@tir.q_multiply_shift((int32*)compute[(ax4 + 20)], 1292030419, 31, 17, dtype=int32) + (int32*)placeholder_11[((((blockIdx.y*128) + (threadIdx.y*4)) + ax4) + 64)]) + (int32*)placeholder_9[((((blockIdx.y*128) + (threadIdx.y*4)) + ax4) + 64)]), 0), 1145587898, 31, -23, dtype=int32), 127), -128))
      T_cast_2[(((((((blockIdx.z*100352) + (blockIdx.y*6272)) + (threadIdx.y*196)) + (blockIdx.x*28)) + (threadIdx.x*4)) + ax4) + 78400)] = cast(int8, max(min(@tir.q_multiply_shift(max(((@tir.q_multiply_shift((int32*)compute[(ax4 + 28)], 1292030419, 31, 17, dtype=int32) + (int32*)placeholder_11[((((blockIdx.y*128) + (threadIdx.y*4)) + ax4) + 64)]) + (int32*)placeholder_9[((((blockIdx.y*128) + (threadIdx.y*4)) + ax4) + 64)]), 0), 1145587898, 31, -23, dtype=int32), 127), -128))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_fixed_point_multiply_clip_cast", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [32, 512, 7, 7, 4], []),
             placeholder: Buffer(placeholder_2: handle, int32, [32, 512, 7, 7, 4], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer: int32, 0, 13) {
    if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*65536) + (blockIdx.x*256)) + floordiv(threadIdx.x, 4)) < 802816) {
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x) < 3211264) {
        T_cast_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = cast(int8, max(min(@tir.q_multiply_shift((int32*)placeholder_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)], 1576722265, 31, -24, dtype=int32), 127), -128))
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
primfn(placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, placeholder_8: handle, placeholder_9: handle, T_relu_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_fixed_point_multiply_add_cast_15119380522063600768_", "tir.noalias": True}
  buffers = {placeholder_4: Buffer(placeholder_10: handle, int8, [32, 128, 7, 7, 4], []),
             placeholder_1: Buffer(placeholder_11: handle, int32, [1, 512, 1, 1, 4], []),
             placeholder: Buffer(placeholder_12: handle, int32, [1, 512, 1, 1, 4], []),
             placeholder_2: Buffer(placeholder_13: handle, int8, [512, 128, 1, 1, 4, 4], []),
             placeholder_3: Buffer(placeholder_14: handle, int32, [32, 512, 7, 7, 4], []),
             T_relu: Buffer(T_relu_2: handle, int32, [32, 512, 7, 7, 4], [])}
  buffer_map = {placeholder_7: placeholder, placeholder_8: placeholder_1, placeholder_6: placeholder_2, placeholder_9: placeholder_3, T_relu_1: T_relu, placeholder_5: placeholder_4} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 32;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [28]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [1568]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [2048]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 32;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7 {
    for (oh.init: int32, 0, 7) "unroll" {
      for (oc_block.init: int32, 0, 4) "unroll" {
        compute[((oh.init*4) + oc_block.init)] = 0
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 7) "unroll" {
      attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
      pad_data.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*448) + (threadIdx.y_1*28)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_10[ramp(((((blockIdx.z*25088) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*448)) + (threadIdx.y_1*28)) + (threadIdx.x_1*4)), 1, 4)]
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 10) "unroll" {
      attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
      attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*112) + (threadIdx.y_2*7)) + threadIdx.x_2) < 1024) {
        if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*16) + threadIdx.y_2) < 147) {
          placeholder.shared[ramp((((floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 64)*256) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*28) + floordiv(((threadIdx.y_2*7) + threadIdx.x_2), 4)), 16)*16)) + (floormod(((threadIdx.y_2*7) + threadIdx.x_2), 4)*4)), 1, 4)] = (int8x4*)placeholder_13[ramp(((((blockIdx.y*32768) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 64)*2048)) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*28) + floordiv(((threadIdx.y_2*7) + threadIdx.x_2), 4)), 16)*16)) + (floormod(((threadIdx.y_2*7) + threadIdx.x_2), 4)*4)), 1, 4)]
        }
      }
    }
    for (ic_chunk.outer.outer: int32, 0, 7) {
      attr [pad_data.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1: int32, 0, 7) "unroll" {
        attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
        attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
        pad_data.shared[ramp(((((floormod((ic_chunk.outer.outer + 1), 2)*3136) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*448)) + (threadIdx.y_1*28)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_10[ramp(((((((blockIdx.z*25088) + (ic_chunk.outer.outer*3136)) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*448)) + (threadIdx.y_1*28)) + (threadIdx.x_1*4)) + 3136), 1, 4)]
      }
      attr [placeholder.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 10) "unroll" {
        attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
        attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*112) + (threadIdx.y_2*7)) + threadIdx.x_2) < 1024) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*16) + threadIdx.y_2) < 147) {
            placeholder.shared[ramp(((((floormod((ic_chunk.outer.outer + 1), 2)*4096) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 64)*256)) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*28) + floordiv(((threadIdx.y_2*7) + threadIdx.x_2), 4)), 16)*16)) + (floormod(((threadIdx.y_2*7) + threadIdx.x_2), 4)*4)), 1, 4)] = (int8x4*)placeholder_13[ramp(((((((blockIdx.y*32768) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 64)*2048)) + (ic_chunk.outer.outer*256)) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*28) + floordiv(((threadIdx.y_2*7) + threadIdx.x_2), 4)), 16)*16)) + (floormod(((threadIdx.y_2*7) + threadIdx.x_2), 4)*4)) + 256), 1, 4)]
          }
        }
      }
      for (ic_chunk.inner: int32, 0, 16) "unroll" {
        for (oh: int32, 0, 7) "unroll" {
          for (oc_block: int32, 0, 4) "unroll" {
            compute[((oh*4) + oc_block)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*3136) + (ic_chunk.inner*196)) + (oh*28)) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*4096) + (threadIdx.y*256)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[((oh*4) + oc_block)], dtype=int32)
          }
        }
      }
    }
    for (ic_chunk.inner_1: int32, 0, 16) "unroll" {
      for (oh_1: int32, 0, 7) "unroll" {
        for (oc_block_1: int32, 0, 4) "unroll" {
          compute[((oh_1*4) + oc_block_1)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((ic_chunk.inner_1*196) + (oh_1*28)) + (threadIdx.x*4)) + 3136), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*256) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 4096), 1, 4)], (int32*)compute[((oh_1*4) + oc_block_1)], dtype=int32)
        }
      }
    }
    for (ax2.inner.inner.inner: int32, 0, 7) "unroll" {
      for (ax4: int32, 0, 4) "unroll" {
        T_relu_2[((((((blockIdx.z*100352) + (blockIdx.y*3136)) + (threadIdx.y*196)) + (ax2.inner.inner.inner*28)) + (threadIdx.x*4)) + ax4)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[((ax2.inner.inner.inner*4) + ax4)], 1353888287, 31, 18, dtype=int32) + (int32*)placeholder_12[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 2147483342, 31, 0, dtype=int32) + (int32*)placeholder_11[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 1840126696, 31, 0, dtype=int32) + @tir.q_multiply_shift((int32*)placeholder_14[((((((blockIdx.z*100352) + (blockIdx.y*3136)) + (threadIdx.y*196)) + (ax2.inner.inner.inner*28)) + (threadIdx.x*4)) + ax4)], 2056266911, 31, 0, dtype=int32)), 0)
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_nn_relu_cast_fixed_point_mult_18399029763786111876__1", "tir.noalias": True}
  buffers = {placeholder_2: Buffer(placeholder_6: handle, int32, [1, 128, 1, 1, 4], []),
             placeholder: Buffer(placeholder_7: handle, int8, [32, 128, 7, 7, 4], []),
             T_cast: Buffer(T_cast_2: handle, int8, [32, 128, 7, 7, 4], []),
             placeholder_1: Buffer(placeholder_8: handle, int8, [128, 128, 3, 3, 4, 4], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 4;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [16]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [864]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [1152]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 16;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 7;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7 {
    for (n.init: int32, 0, 4) "unroll" {
      for (oc_block.init: int32, 0, 4) "unroll" {
        compute[((n.init*4) + oc_block.init)] = 0
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 4) "unroll" {
      attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
      attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
      if (((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1) < 432) {
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*16) + (threadIdx.z_1*8)) + threadIdx.y_1) < 62) {
          pad_data.shared[ramp(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*448) + (threadIdx.z_1*224)) + (threadIdx.y_1*28)) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((1 <= (floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1), 27), 9) + blockIdx.x)) && ((floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1), 27), 9) + blockIdx.x) < 8)) && (1 <= floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1), 9))) && (floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1), 9) < 8)), (int8x4*)placeholder_7[ramp((((((((blockIdx.z*200704) + (floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1), 54)*25088)) + (floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1), 54), 27)*196)) + (floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1), 27), 9)*28)) + (blockIdx.x*28)) + (floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1), 9)*4)) - 32), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
        }
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 6) "unroll" {
      attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
      attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
      attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
      if (((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*112) + (threadIdx.z_2*56)) + (threadIdx.y_2*7)) + threadIdx.x_2) < 576) {
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*16) + (threadIdx.z_2*8)) + threadIdx.y_2) < 83) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*2) + threadIdx.z_2) < 11) {
            placeholder.shared[ramp((((floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*112) + (threadIdx.z_2*56)) + (threadIdx.y_2*7)) + threadIdx.x_2), 12)*48) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*28) + (threadIdx.z_2*14)) + floordiv(((threadIdx.y_2*7) + threadIdx.x_2), 4)), 3)*16)) + (floormod(((threadIdx.y_2*7) + threadIdx.x_2), 4)*4)), 1, 4)] = (int8x4*)placeholder_8[ramp((((((blockIdx.y*147456) + (floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*112) + (threadIdx.z_2*56)) + (threadIdx.y_2*7)) + threadIdx.x_2), 72)*18432)) + (floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*112) + (threadIdx.z_2*56)) + (threadIdx.y_2*7)) + threadIdx.x_2), 72), 12)*48)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*28) + (threadIdx.z_2*14)) + floordiv(((threadIdx.y_2*7) + threadIdx.x_2), 4)), 3)*16)) + (floormod(((threadIdx.y_2*7) + threadIdx.x_2), 4)*4)), 1, 4)]
          }
        }
      }
    }
    for (ic_chunk.outer.outer: int32, 0, 63) {
      attr [pad_data.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1: int32, 0, 4) "unroll" {
        attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
        attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
        attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
        if (((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1) < 432) {
          if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*16) + (threadIdx.z_1*8)) + threadIdx.y_1) < 62) {
            pad_data.shared[ramp((((((floormod((ic_chunk.outer.outer + 1), 2)*1728) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*448)) + (threadIdx.z_1*224)) + (threadIdx.y_1*28)) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((1 <= (floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1), 27), 9) + blockIdx.x)) && ((floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1), 27), 9) + blockIdx.x) < 8)) && (1 <= floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1), 9))) && (floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1), 9) < 8)), (int8x4*)placeholder_7[ramp(((((((((blockIdx.z*200704) + (floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1), 54)*25088)) + (ic_chunk.outer.outer*392)) + (floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1), 54), 27)*196)) + (floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1), 27), 9)*28)) + (blockIdx.x*28)) + (floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1), 9)*4)) + 360), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
          }
        }
      }
      attr [placeholder.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 6) "unroll" {
        attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
        attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
        attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
        if (((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*112) + (threadIdx.z_2*56)) + (threadIdx.y_2*7)) + threadIdx.x_2) < 576) {
          if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*16) + (threadIdx.z_2*8)) + threadIdx.y_2) < 83) {
            if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*2) + threadIdx.z_2) < 11) {
              placeholder.shared[ramp(((((floormod((ic_chunk.outer.outer + 1), 2)*2304) + (floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*112) + (threadIdx.z_2*56)) + (threadIdx.y_2*7)) + threadIdx.x_2), 12)*48)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*28) + (threadIdx.z_2*14)) + floordiv(((threadIdx.y_2*7) + threadIdx.x_2), 4)), 3)*16)) + (floormod(((threadIdx.y_2*7) + threadIdx.x_2), 4)*4)), 1, 4)] = (int8x4*)placeholder_8[ramp((((((((blockIdx.y*147456) + (floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*112) + (threadIdx.z_2*56)) + (threadIdx.y_2*7)) + threadIdx.x_2), 72)*18432)) + (ic_chunk.outer.outer*288)) + (floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*112) + (threadIdx.z_2*56)) + (threadIdx.y_2*7)) + threadIdx.x_2), 72), 12)*48)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*28) + (threadIdx.z_2*14)) + floordiv(((threadIdx.y_2*7) + threadIdx.x_2), 4)), 3)*16)) + (floormod(((threadIdx.y_2*7) + threadIdx.x_2), 4)*4)) + 288), 1, 4)]
            }
          }
        }
      }
      for (kh.inner: int32, 0, 3) "unroll" {
        for (ic_chunk.inner: int32, 0, 2) "unroll" {
          for (kw.inner: int32, 0, 3) "unroll" {
            for (n: int32, 0, 4) "unroll" {
              for (oc_block: int32, 0, 4) "unroll" {
                compute[((n*4) + oc_block)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((((floormod(ic_chunk.outer.outer, 2)*1728) + (threadIdx.z*864)) + (n*216)) + (ic_chunk.inner*108)) + (kh.inner*36)) + (threadIdx.x*4)) + (kw.inner*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((((floormod(ic_chunk.outer.outer, 2)*2304) + (threadIdx.y*288)) + (ic_chunk.inner*144)) + (kh.inner*48)) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[((n*4) + oc_block)], dtype=int32)
              }
            }
          }
        }
      }
    }
    for (kh.inner_1: int32, 0, 3) "unroll" {
      for (ic_chunk.inner_1: int32, 0, 2) "unroll" {
        for (kw.inner_1: int32, 0, 3) "unroll" {
          for (n_1: int32, 0, 4) "unroll" {
            for (oc_block_1: int32, 0, 4) "unroll" {
              compute[((n_1*4) + oc_block_1)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((((threadIdx.z*864) + (n_1*216)) + (ic_chunk.inner_1*108)) + (kh.inner_1*36)) + (threadIdx.x*4)) + (kw.inner_1*4)) + 1728), 1, 4)], (int8x4*)placeholder.shared[ramp(((((((threadIdx.y*288) + (ic_chunk.inner_1*144)) + (kh.inner_1*48)) + (kw.inner_1*16)) + (oc_block_1*4)) + 2304), 1, 4)], (int32*)compute[((n_1*4) + oc_block_1)], dtype=int32)
            }
          }
        }
      }
    }
    for (ax0.inner.inner.inner.inner: int32, 0, 4) "unroll" {
      for (ax4: int32, 0, 4) "unroll" {
        T_cast_2[((((((((blockIdx.z*200704) + (threadIdx.z*100352)) + (ax0.inner.inner.inner.inner*25088)) + (blockIdx.y*1568)) + (threadIdx.y*196)) + (blockIdx.x*28)) + (threadIdx.x*4)) + ax4)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((int32*)compute[((ax0.inner.inner.inner.inner*4) + ax4)], 1506044321, 31, 16, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*32) + (threadIdx.y*4)) + ax4)]), 0), 1082269554, 31, -23, dtype=int32), 127), -128))
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_fixed_point_multiply_add_cast_16086763325481941859_", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [32, 128, 7, 7, 4], []),
             placeholder_2: Buffer(placeholder_8: handle, int32, [1, 128, 1, 1, 4], []),
             placeholder: Buffer(placeholder_9: handle, int8, [32, 512, 7, 7, 4], []),
             placeholder_3: Buffer(placeholder_10: handle, int32, [1, 128, 1, 1, 4], []),
             placeholder_1: Buffer(placeholder_11: handle, int8, [128, 512, 1, 1, 4, 4], [])}
  buffer_map = {placeholder_4: placeholder, placeholder_5: placeholder_1, placeholder_7: placeholder_2, placeholder_6: placeholder_3, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 8;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [32]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [224]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [1024]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 4;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 7;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7 {
    for (oc_block.init: int32, 0, 4) "unroll" {
      compute[oc_block.init] = 0
      compute[(oc_block.init + 8)] = 0
      compute[(oc_block.init + 16)] = 0
      compute[(oc_block.init + 24)] = 0
      compute[(oc_block.init + 4)] = 0
      compute[(oc_block.init + 12)] = 0
      compute[(oc_block.init + 20)] = 0
      compute[(oc_block.init + 28)] = 0
    }
    for (ic_chunk.outer: int32, 0, 64) {
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 2) "unroll" {
        attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
        attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
        pad_data.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*448) + (threadIdx.y_1*28)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_9[ramp((((((((blockIdx.z*401408) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*200704)) + (floordiv(threadIdx.y_1, 8)*100352)) + (ic_chunk.outer*1568)) + (floormod(threadIdx.y_1, 8)*196)) + (blockIdx.x*28)) + (threadIdx.x_1*4)), 1, 4)]
      }
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 10) "unroll" {
        attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*112) + (threadIdx.y_2*7)) + threadIdx.x_2) < 1024) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*16) + threadIdx.y_2) < 147) {
            placeholder.shared[ramp((((floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 32)*128) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*28) + floordiv(((threadIdx.y_2*7) + threadIdx.x_2), 4)), 8)*16)) + (floormod(((threadIdx.y_2*7) + threadIdx.x_2), 4)*4)), 1, 4)] = (int8x4*)placeholder_11[ramp((((((blockIdx.y*262144) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 32)*8192)) + (ic_chunk.outer*128)) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*28) + floordiv(((threadIdx.y_2*7) + threadIdx.x_2), 4)), 8)*16)) + (floormod(((threadIdx.y_2*7) + threadIdx.x_2), 4)*4)), 1, 4)]
          }
        }
      }
      for (ic_chunk.inner: int32, 0, 8) "unroll" {
        for (oc_block: int32, 0, 4) "unroll" {
          compute[oc_block] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((ic_chunk.inner*28) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.y*128) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[oc_block], dtype=int32)
          compute[(oc_block + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*28) + (threadIdx.x*4)) + 224), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.y*128) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 8)], dtype=int32)
          compute[(oc_block + 16)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*28) + (threadIdx.x*4)) + 448), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.y*128) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 16)], dtype=int32)
          compute[(oc_block + 24)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*28) + (threadIdx.x*4)) + 672), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.y*128) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 24)], dtype=int32)
          compute[(oc_block + 4)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((ic_chunk.inner*28) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*128) + (ic_chunk.inner*16)) + (oc_block*4)) + 2048), 1, 4)], (int32*)compute[(oc_block + 4)], dtype=int32)
          compute[(oc_block + 12)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*28) + (threadIdx.x*4)) + 224), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*128) + (ic_chunk.inner*16)) + (oc_block*4)) + 2048), 1, 4)], (int32*)compute[(oc_block + 12)], dtype=int32)
          compute[(oc_block + 20)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*28) + (threadIdx.x*4)) + 448), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*128) + (ic_chunk.inner*16)) + (oc_block*4)) + 2048), 1, 4)], (int32*)compute[(oc_block + 20)], dtype=int32)
          compute[(oc_block + 28)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*28) + (threadIdx.x*4)) + 672), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*128) + (ic_chunk.inner*16)) + (oc_block*4)) + 2048), 1, 4)], (int32*)compute[(oc_block + 28)], dtype=int32)
        }
      }
    }
    for (ax4: int32, 0, 4) "unroll" {
      T_cast_2[((((((blockIdx.z*100352) + (blockIdx.y*6272)) + (threadIdx.y*196)) + (blockIdx.x*28)) + (threadIdx.x*4)) + ax4)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[ax4], 2054051438, 31, 16, dtype=int32) + (int32*)placeholder_10[(((blockIdx.y*128) + (threadIdx.y*4)) + ax4)]), 1073741938, 31, 1, dtype=int32) + (int32*)placeholder_8[(((blockIdx.y*128) + (threadIdx.y*4)) + ax4)]), 0), 2131207242, 31, -24, dtype=int32), 127), -128))
      T_cast_2[(((((((blockIdx.z*100352) + (blockIdx.y*6272)) + (threadIdx.y*196)) + (blockIdx.x*28)) + (threadIdx.x*4)) + ax4) + 25088)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 8)], 2054051438, 31, 16, dtype=int32) + (int32*)placeholder_10[(((blockIdx.y*128) + (threadIdx.y*4)) + ax4)]), 1073741938, 31, 1, dtype=int32) + (int32*)placeholder_8[(((blockIdx.y*128) + (threadIdx.y*4)) + ax4)]), 0), 2131207242, 31, -24, dtype=int32), 127), -128))
      T_cast_2[(((((((blockIdx.z*100352) + (blockIdx.y*6272)) + (threadIdx.y*196)) + (blockIdx.x*28)) + (threadIdx.x*4)) + ax4) + 50176)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 16)], 2054051438, 31, 16, dtype=int32) + (int32*)placeholder_10[(((blockIdx.y*128) + (threadIdx.y*4)) + ax4)]), 1073741938, 31, 1, dtype=int32) + (int32*)placeholder_8[(((blockIdx.y*128) + (threadIdx.y*4)) + ax4)]), 0), 2131207242, 31, -24, dtype=int32), 127), -128))
      T_cast_2[(((((((blockIdx.z*100352) + (blockIdx.y*6272)) + (threadIdx.y*196)) + (blockIdx.x*28)) + (threadIdx.x*4)) + ax4) + 75264)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 24)], 2054051438, 31, 16, dtype=int32) + (int32*)placeholder_10[(((blockIdx.y*128) + (threadIdx.y*4)) + ax4)]), 1073741938, 31, 1, dtype=int32) + (int32*)placeholder_8[(((blockIdx.y*128) + (threadIdx.y*4)) + ax4)]), 0), 2131207242, 31, -24, dtype=int32), 127), -128))
      T_cast_2[(((((((blockIdx.z*100352) + (blockIdx.y*6272)) + (threadIdx.y*196)) + (blockIdx.x*28)) + (threadIdx.x*4)) + ax4) + 3136)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 4)], 2054051438, 31, 16, dtype=int32) + (int32*)placeholder_10[((((blockIdx.y*128) + (threadIdx.y*4)) + ax4) + 64)]), 1073741938, 31, 1, dtype=int32) + (int32*)placeholder_8[((((blockIdx.y*128) + (threadIdx.y*4)) + ax4) + 64)]), 0), 2131207242, 31, -24, dtype=int32), 127), -128))
      T_cast_2[(((((((blockIdx.z*100352) + (blockIdx.y*6272)) + (threadIdx.y*196)) + (blockIdx.x*28)) + (threadIdx.x*4)) + ax4) + 28224)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 12)], 2054051438, 31, 16, dtype=int32) + (int32*)placeholder_10[((((blockIdx.y*128) + (threadIdx.y*4)) + ax4) + 64)]), 1073741938, 31, 1, dtype=int32) + (int32*)placeholder_8[((((blockIdx.y*128) + (threadIdx.y*4)) + ax4) + 64)]), 0), 2131207242, 31, -24, dtype=int32), 127), -128))
      T_cast_2[(((((((blockIdx.z*100352) + (blockIdx.y*6272)) + (threadIdx.y*196)) + (blockIdx.x*28)) + (threadIdx.x*4)) + ax4) + 53312)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 20)], 2054051438, 31, 16, dtype=int32) + (int32*)placeholder_10[((((blockIdx.y*128) + (threadIdx.y*4)) + ax4) + 64)]), 1073741938, 31, 1, dtype=int32) + (int32*)placeholder_8[((((blockIdx.y*128) + (threadIdx.y*4)) + ax4) + 64)]), 0), 2131207242, 31, -24, dtype=int32), 127), -128))
      T_cast_2[(((((((blockIdx.z*100352) + (blockIdx.y*6272)) + (threadIdx.y*196)) + (blockIdx.x*28)) + (threadIdx.x*4)) + ax4) + 78400)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 28)], 2054051438, 31, 16, dtype=int32) + (int32*)placeholder_10[((((blockIdx.y*128) + (threadIdx.y*4)) + ax4) + 64)]), 1073741938, 31, 1, dtype=int32) + (int32*)placeholder_8[((((blockIdx.y*128) + (threadIdx.y*4)) + ax4) + 64)]), 0), 2131207242, 31, -24, dtype=int32), 127), -128))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_fixed_point_multiply_clip_cast_1", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [32, 512, 7, 7, 4], []),
             placeholder: Buffer(placeholder_2: handle, int32, [32, 512, 7, 7, 4], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer: int32, 0, 13) {
    if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*65536) + (blockIdx.x*256)) + floordiv(threadIdx.x, 4)) < 802816) {
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x) < 3211264) {
        T_cast_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = cast(int8, max(min(@tir.q_multiply_shift((int32*)placeholder_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)], 2056266911, 31, -24, dtype=int32), 127), -128))
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
primfn(placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, placeholder_8: handle, placeholder_9: handle, T_relu_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_fixed_point_multiply_add_cast_12402219635377536017_", "tir.noalias": True}
  buffers = {placeholder_1: Buffer(placeholder_10: handle, int32, [1, 512, 1, 1, 4], []),
             T_relu: Buffer(T_relu_2: handle, int32, [32, 512, 7, 7, 4], []),
             placeholder: Buffer(placeholder_11: handle, int8, [32, 128, 7, 7, 4], []),
             placeholder_4: Buffer(placeholder_12: handle, int32, [32, 512, 7, 7, 4], []),
             placeholder_2: Buffer(placeholder_13: handle, int32, [1, 512, 1, 1, 4], []),
             placeholder_3: Buffer(placeholder_14: handle, int8, [512, 128, 1, 1, 4, 4], [])}
  buffer_map = {placeholder_5: placeholder, placeholder_8: placeholder_1, T_relu_1: T_relu, placeholder_7: placeholder_2, placeholder_6: placeholder_3, placeholder_9: placeholder_4} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 32;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [28]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [1568]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [2048]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 32;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7 {
    for (oh.init: int32, 0, 7) "unroll" {
      for (oc_block.init: int32, 0, 4) "unroll" {
        compute[((oh.init*4) + oc_block.init)] = 0
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 7) "unroll" {
      attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
      pad_data.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*448) + (threadIdx.y_1*28)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_11[ramp(((((blockIdx.z*25088) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*448)) + (threadIdx.y_1*28)) + (threadIdx.x_1*4)), 1, 4)]
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 10) "unroll" {
      attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
      attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*112) + (threadIdx.y_2*7)) + threadIdx.x_2) < 1024) {
        if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*16) + threadIdx.y_2) < 147) {
          placeholder.shared[ramp((((floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 64)*256) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*28) + floordiv(((threadIdx.y_2*7) + threadIdx.x_2), 4)), 16)*16)) + (floormod(((threadIdx.y_2*7) + threadIdx.x_2), 4)*4)), 1, 4)] = (int8x4*)placeholder_14[ramp(((((blockIdx.y*32768) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 64)*2048)) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*28) + floordiv(((threadIdx.y_2*7) + threadIdx.x_2), 4)), 16)*16)) + (floormod(((threadIdx.y_2*7) + threadIdx.x_2), 4)*4)), 1, 4)]
        }
      }
    }
    for (ic_chunk.outer.outer: int32, 0, 7) {
      attr [pad_data.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1: int32, 0, 7) "unroll" {
        attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
        attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
        pad_data.shared[ramp(((((floormod((ic_chunk.outer.outer + 1), 2)*3136) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*448)) + (threadIdx.y_1*28)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_11[ramp(((((((blockIdx.z*25088) + (ic_chunk.outer.outer*3136)) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*448)) + (threadIdx.y_1*28)) + (threadIdx.x_1*4)) + 3136), 1, 4)]
      }
      attr [placeholder.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 10) "unroll" {
        attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
        attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*112) + (threadIdx.y_2*7)) + threadIdx.x_2) < 1024) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*16) + threadIdx.y_2) < 147) {
            placeholder.shared[ramp(((((floormod((ic_chunk.outer.outer + 1), 2)*4096) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 64)*256)) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*28) + floordiv(((threadIdx.y_2*7) + threadIdx.x_2), 4)), 16)*16)) + (floormod(((threadIdx.y_2*7) + threadIdx.x_2), 4)*4)), 1, 4)] = (int8x4*)placeholder_14[ramp(((((((blockIdx.y*32768) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 64)*2048)) + (ic_chunk.outer.outer*256)) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*28) + floordiv(((threadIdx.y_2*7) + threadIdx.x_2), 4)), 16)*16)) + (floormod(((threadIdx.y_2*7) + threadIdx.x_2), 4)*4)) + 256), 1, 4)]
          }
        }
      }
      for (ic_chunk.inner: int32, 0, 16) "unroll" {
        for (oh: int32, 0, 7) "unroll" {
          for (oc_block: int32, 0, 4) "unroll" {
            compute[((oh*4) + oc_block)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*3136) + (ic_chunk.inner*196)) + (oh*28)) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*4096) + (threadIdx.y*256)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[((oh*4) + oc_block)], dtype=int32)
          }
        }
      }
    }
    for (ic_chunk.inner_1: int32, 0, 16) "unroll" {
      for (oh_1: int32, 0, 7) "unroll" {
        for (oc_block_1: int32, 0, 4) "unroll" {
          compute[((oh_1*4) + oc_block_1)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((ic_chunk.inner_1*196) + (oh_1*28)) + (threadIdx.x*4)) + 3136), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*256) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 4096), 1, 4)], (int32*)compute[((oh_1*4) + oc_block_1)], dtype=int32)
        }
      }
    }
    for (ax2.inner.inner.inner: int32, 0, 7) "unroll" {
      for (ax4: int32, 0, 4) "unroll" {
        T_relu_2[((((((blockIdx.z*100352) + (blockIdx.y*3136)) + (threadIdx.y*196)) + (ax2.inner.inner.inner*28)) + (threadIdx.x*4)) + ax4)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[((ax2.inner.inner.inner*4) + ax4)], 1173567685, 31, 18, dtype=int32) + (int32*)placeholder_13[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 1073742008, 31, 1, dtype=int32) + (int32*)placeholder_10[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 1592540765, 31, 0, dtype=int32) + (int32*)placeholder_12[((((((blockIdx.z*100352) + (blockIdx.y*3136)) + (threadIdx.y*196)) + (ax2.inner.inner.inner*28)) + (threadIdx.x*4)) + ax4)]), 0)
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_nn_relu_cast_fixed_point_mult_18399029763786111876__2", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [32, 128, 7, 7, 4], []),
             placeholder_2: Buffer(placeholder_6: handle, int32, [1, 128, 1, 1, 4], []),
             placeholder: Buffer(placeholder_7: handle, int8, [32, 128, 7, 7, 4], []),
             placeholder_1: Buffer(placeholder_8: handle, int8, [128, 128, 3, 3, 4, 4], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 4;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [16]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [864]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [1152]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 16;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 7;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7 {
    for (n.init: int32, 0, 4) "unroll" {
      for (oc_block.init: int32, 0, 4) "unroll" {
        compute[((n.init*4) + oc_block.init)] = 0
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 4) "unroll" {
      attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
      attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
      if (((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1) < 432) {
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*16) + (threadIdx.z_1*8)) + threadIdx.y_1) < 62) {
          pad_data.shared[ramp(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*448) + (threadIdx.z_1*224)) + (threadIdx.y_1*28)) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((1 <= (floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1), 27), 9) + blockIdx.x)) && ((floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1), 27), 9) + blockIdx.x) < 8)) && (1 <= floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1), 9))) && (floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1), 9) < 8)), (int8x4*)placeholder_7[ramp((((((((blockIdx.z*200704) + (floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1), 54)*25088)) + (floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1), 54), 27)*196)) + (floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1), 27), 9)*28)) + (blockIdx.x*28)) + (floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1), 9)*4)) - 32), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
        }
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 6) "unroll" {
      attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
      attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
      attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
      if (((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*112) + (threadIdx.z_2*56)) + (threadIdx.y_2*7)) + threadIdx.x_2) < 576) {
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*16) + (threadIdx.z_2*8)) + threadIdx.y_2) < 83) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*2) + threadIdx.z_2) < 11) {
            placeholder.shared[ramp((((floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*112) + (threadIdx.z_2*56)) + (threadIdx.y_2*7)) + threadIdx.x_2), 12)*48) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*28) + (threadIdx.z_2*14)) + floordiv(((threadIdx.y_2*7) + threadIdx.x_2), 4)), 3)*16)) + (floormod(((threadIdx.y_2*7) + threadIdx.x_2), 4)*4)), 1, 4)] = (int8x4*)placeholder_8[ramp((((((blockIdx.y*147456) + (floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*112) + (threadIdx.z_2*56)) + (threadIdx.y_2*7)) + threadIdx.x_2), 72)*18432)) + (floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*112) + (threadIdx.z_2*56)) + (threadIdx.y_2*7)) + threadIdx.x_2), 72), 12)*48)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*28) + (threadIdx.z_2*14)) + floordiv(((threadIdx.y_2*7) + threadIdx.x_2), 4)), 3)*16)) + (floormod(((threadIdx.y_2*7) + threadIdx.x_2), 4)*4)), 1, 4)]
          }
        }
      }
    }
    for (ic_chunk.outer.outer: int32, 0, 63) {
      attr [pad_data.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1: int32, 0, 4) "unroll" {
        attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
        attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
        attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
        if (((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1) < 432) {
          if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*16) + (threadIdx.z_1*8)) + threadIdx.y_1) < 62) {
            pad_data.shared[ramp((((((floormod((ic_chunk.outer.outer + 1), 2)*1728) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*448)) + (threadIdx.z_1*224)) + (threadIdx.y_1*28)) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((1 <= (floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1), 27), 9) + blockIdx.x)) && ((floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1), 27), 9) + blockIdx.x) < 8)) && (1 <= floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1), 9))) && (floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1), 9) < 8)), (int8x4*)placeholder_7[ramp(((((((((blockIdx.z*200704) + (floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1), 54)*25088)) + (ic_chunk.outer.outer*392)) + (floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1), 54), 27)*196)) + (floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1), 27), 9)*28)) + (blockIdx.x*28)) + (floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*112) + (threadIdx.z_1*56)) + (threadIdx.y_1*7)) + threadIdx.x_1), 9)*4)) + 360), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
          }
        }
      }
      attr [placeholder.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 6) "unroll" {
        attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
        attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
        attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
        if (((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*112) + (threadIdx.z_2*56)) + (threadIdx.y_2*7)) + threadIdx.x_2) < 576) {
          if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*16) + (threadIdx.z_2*8)) + threadIdx.y_2) < 83) {
            if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*2) + threadIdx.z_2) < 11) {
              placeholder.shared[ramp(((((floormod((ic_chunk.outer.outer + 1), 2)*2304) + (floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*112) + (threadIdx.z_2*56)) + (threadIdx.y_2*7)) + threadIdx.x_2), 12)*48)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*28) + (threadIdx.z_2*14)) + floordiv(((threadIdx.y_2*7) + threadIdx.x_2), 4)), 3)*16)) + (floormod(((threadIdx.y_2*7) + threadIdx.x_2), 4)*4)), 1, 4)] = (int8x4*)placeholder_8[ramp((((((((blockIdx.y*147456) + (floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*112) + (threadIdx.z_2*56)) + (threadIdx.y_2*7)) + threadIdx.x_2), 72)*18432)) + (ic_chunk.outer.outer*288)) + (floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*112) + (threadIdx.z_2*56)) + (threadIdx.y_2*7)) + threadIdx.x_2), 72), 12)*48)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*28) + (threadIdx.z_2*14)) + floordiv(((threadIdx.y_2*7) + threadIdx.x_2), 4)), 3)*16)) + (floormod(((threadIdx.y_2*7) + threadIdx.x_2), 4)*4)) + 288), 1, 4)]
            }
          }
        }
      }
      for (kh.inner: int32, 0, 3) "unroll" {
        for (ic_chunk.inner: int32, 0, 2) "unroll" {
          for (kw.inner: int32, 0, 3) "unroll" {
            for (n: int32, 0, 4) "unroll" {
              for (oc_block: int32, 0, 4) "unroll" {
                compute[((n*4) + oc_block)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((((floormod(ic_chunk.outer.outer, 2)*1728) + (threadIdx.z*864)) + (n*216)) + (ic_chunk.inner*108)) + (kh.inner*36)) + (threadIdx.x*4)) + (kw.inner*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((((floormod(ic_chunk.outer.outer, 2)*2304) + (threadIdx.y*288)) + (ic_chunk.inner*144)) + (kh.inner*48)) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[((n*4) + oc_block)], dtype=int32)
              }
            }
          }
        }
      }
    }
    for (kh.inner_1: int32, 0, 3) "unroll" {
      for (ic_chunk.inner_1: int32, 0, 2) "unroll" {
        for (kw.inner_1: int32, 0, 3) "unroll" {
          for (n_1: int32, 0, 4) "unroll" {
            for (oc_block_1: int32, 0, 4) "unroll" {
              compute[((n_1*4) + oc_block_1)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((((threadIdx.z*864) + (n_1*216)) + (ic_chunk.inner_1*108)) + (kh.inner_1*36)) + (threadIdx.x*4)) + (kw.inner_1*4)) + 1728), 1, 4)], (int8x4*)placeholder.shared[ramp(((((((threadIdx.y*288) + (ic_chunk.inner_1*144)) + (kh.inner_1*48)) + (kw.inner_1*16)) + (oc_block_1*4)) + 2304), 1, 4)], (int32*)compute[((n_1*4) + oc_block_1)], dtype=int32)
            }
          }
        }
      }
    }
    for (ax0.inner.inner.inner.inner: int32, 0, 4) "unroll" {
      for (ax4: int32, 0, 4) "unroll" {
        T_cast_2[((((((((blockIdx.z*200704) + (threadIdx.z*100352)) + (ax0.inner.inner.inner.inner*25088)) + (blockIdx.y*1568)) + (threadIdx.y*196)) + (blockIdx.x*28)) + (threadIdx.x*4)) + ax4)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((int32*)compute[((ax0.inner.inner.inner.inner*4) + ax4)], 1627237775, 31, 16, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*32) + (threadIdx.y*4)) + ax4)]), 0), 1350577355, 31, -23, dtype=int32), 127), -128))
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_fixed_point_multiply_add_cast_16086763325481941859__1", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [32, 128, 7, 7, 4], []),
             placeholder_3: Buffer(placeholder_8: handle, int8, [128, 256, 1, 1, 4, 4], []),
             placeholder: Buffer(placeholder_9: handle, int32, [1, 128, 1, 1, 4], []),
             placeholder_2: Buffer(placeholder_10: handle, int8, [32, 256, 14, 14, 4], []),
             placeholder_1: Buffer(placeholder_11: handle, int32, [1, 128, 1, 1, 4], [])}
  buffer_map = {placeholder_7: placeholder, placeholder_6: placeholder_1, placeholder_4: placeholder_2, placeholder_5: placeholder_3, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 8;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [16]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [1024]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [208]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 4;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 7;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 32;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7 {
    for (oc_block.init: int32, 0, 4) "unroll" {
      compute[oc_block.init] = 0
      compute[(oc_block.init + 4)] = 0
      compute[(oc_block.init + 8)] = 0
      compute[(oc_block.init + 12)] = 0
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 3) "unroll" {
      attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 32;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*224) + (threadIdx.y_1*7)) + threadIdx.x_1) < 512) {
        if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + threadIdx.y_1) < 74) {
          if ((((blockIdx.y*32) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*14)) + floordiv(((threadIdx.y_1*7) + threadIdx.x_1), 16)) < 128) {
            placeholder.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*896) + (threadIdx.y_1*28)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_8[ramp(((((blockIdx.y*131072) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*57344)) + (floordiv(((threadIdx.y_1*7) + threadIdx.x_1), 16)*4096)) + (floormod(((threadIdx.y_1*7) + threadIdx.x_1), 16)*4)), 1, 4)]
          }
        }
      }
    }
    for (ic_chunk.outer.outer: int32, 0, 63) {
      attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 32;
      attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
      if (((threadIdx.y_2*7) + threadIdx.x_2) < 208) {
        if (threadIdx.y_2 < 30) {
          pad_data.shared[ramp(((threadIdx.y_2*28) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_10[ramp(((((((blockIdx.z*802816) + (floordiv(((threadIdx.y_2*7) + threadIdx.x_2), 52)*200704)) + (ic_chunk.outer.outer*3136)) + (floordiv(floormod(((threadIdx.y_2*7) + threadIdx.x_2), 52), 13)*784)) + (blockIdx.x*112)) + (floormod(((threadIdx.y_2*7) + threadIdx.x_2), 13)*4)), 1, 4)]
        }
      }
      attr [placeholder.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 3) "unroll" {
        attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 32;
        attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*224) + (threadIdx.y_1*7)) + threadIdx.x_1) < 512) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + threadIdx.y_1) < 74) {
            if ((((blockIdx.y*32) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*14)) + floordiv(((threadIdx.y_1*7) + threadIdx.x_1), 16)) < 128) {
              placeholder.shared[ramp(((((floormod((ic_chunk.outer.outer + 1), 2)*2048) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*896)) + (threadIdx.y_1*28)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_8[ramp(((((((blockIdx.y*131072) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*57344)) + (floordiv(((threadIdx.y_1*7) + threadIdx.x_1), 16)*4096)) + (ic_chunk.outer.outer*64)) + (floormod(((threadIdx.y_1*7) + threadIdx.x_1), 16)*4)) + 64), 1, 4)]
            }
          }
        }
      }
      for (ic_chunk.inner: int32, 0, 4) "unroll" {
        for (oc_block: int32, 0, 4) "unroll" {
          compute[oc_block] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((ic_chunk.inner*52) + (threadIdx.x*8)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*2048) + (threadIdx.y*64)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[oc_block], dtype=int32)
          compute[(oc_block + 4)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*52) + (threadIdx.x*8)) + 208), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*2048) + (threadIdx.y*64)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 4)], dtype=int32)
          compute[(oc_block + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*52) + (threadIdx.x*8)) + 416), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*2048) + (threadIdx.y*64)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 8)], dtype=int32)
          compute[(oc_block + 12)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*52) + (threadIdx.x*8)) + 624), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*2048) + (threadIdx.y*64)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 12)], dtype=int32)
        }
      }
    }
    attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
    attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 32;
    attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
    if (((threadIdx.y_2*7) + threadIdx.x_2) < 208) {
      if (threadIdx.y_2 < 30) {
        pad_data.shared[ramp(((threadIdx.y_2*28) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_10[ramp(((((((blockIdx.z*802816) + (floordiv(((threadIdx.y_2*7) + threadIdx.x_2), 52)*200704)) + (floordiv(floormod(((threadIdx.y_2*7) + threadIdx.x_2), 52), 13)*784)) + (blockIdx.x*112)) + (floormod(((threadIdx.y_2*7) + threadIdx.x_2), 13)*4)) + 197568), 1, 4)]
      }
    }
    for (ic_chunk.inner_1: int32, 0, 4) "unroll" {
      for (oc_block_1: int32, 0, 4) "unroll" {
        compute[oc_block_1] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((ic_chunk.inner_1*52) + (threadIdx.x*8)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*64) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 2048), 1, 4)], (int32*)compute[oc_block_1], dtype=int32)
        compute[(oc_block_1 + 4)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner_1*52) + (threadIdx.x*8)) + 208), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*64) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 2048), 1, 4)], (int32*)compute[(oc_block_1 + 4)], dtype=int32)
        compute[(oc_block_1 + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner_1*52) + (threadIdx.x*8)) + 416), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*64) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 2048), 1, 4)], (int32*)compute[(oc_block_1 + 8)], dtype=int32)
        compute[(oc_block_1 + 12)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner_1*52) + (threadIdx.x*8)) + 624), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*64) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 2048), 1, 4)], (int32*)compute[(oc_block_1 + 12)], dtype=int32)
      }
    }
    for (ax4: int32, 0, 4) "unroll" {
      T_cast_2[((((((blockIdx.z*100352) + (blockIdx.y*6272)) + (threadIdx.y*196)) + (blockIdx.x*28)) + (threadIdx.x*4)) + ax4)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[ax4], 1184596221, 31, 18, dtype=int32) + (int32*)placeholder_11[(((blockIdx.y*128) + (threadIdx.y*4)) + ax4)]), 1073741959, 31, 1, dtype=int32) + (int32*)placeholder_9[(((blockIdx.y*128) + (threadIdx.y*4)) + ax4)]), 0), 2114189816, 31, -24, dtype=int32), 127), -128))
      T_cast_2[(((((((blockIdx.z*100352) + (blockIdx.y*6272)) + (threadIdx.y*196)) + (blockIdx.x*28)) + (threadIdx.x*4)) + ax4) + 25088)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 4)], 1184596221, 31, 18, dtype=int32) + (int32*)placeholder_11[(((blockIdx.y*128) + (threadIdx.y*4)) + ax4)]), 1073741959, 31, 1, dtype=int32) + (int32*)placeholder_9[(((blockIdx.y*128) + (threadIdx.y*4)) + ax4)]), 0), 2114189816, 31, -24, dtype=int32), 127), -128))
      T_cast_2[(((((((blockIdx.z*100352) + (blockIdx.y*6272)) + (threadIdx.y*196)) + (blockIdx.x*28)) + (threadIdx.x*4)) + ax4) + 50176)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 8)], 1184596221, 31, 18, dtype=int32) + (int32*)placeholder_11[(((blockIdx.y*128) + (threadIdx.y*4)) + ax4)]), 1073741959, 31, 1, dtype=int32) + (int32*)placeholder_9[(((blockIdx.y*128) + (threadIdx.y*4)) + ax4)]), 0), 2114189816, 31, -24, dtype=int32), 127), -128))
      T_cast_2[(((((((blockIdx.z*100352) + (blockIdx.y*6272)) + (threadIdx.y*196)) + (blockIdx.x*28)) + (threadIdx.x*4)) + ax4) + 75264)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 12)], 1184596221, 31, 18, dtype=int32) + (int32*)placeholder_11[(((blockIdx.y*128) + (threadIdx.y*4)) + ax4)]), 1073741959, 31, 1, dtype=int32) + (int32*)placeholder_9[(((blockIdx.y*128) + (threadIdx.y*4)) + ax4)]), 0), 2114189816, 31, -24, dtype=int32), 127), -128))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_fixed_point_multiply_clip_cast_2", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [32, 256, 14, 14, 4], []),
             placeholder: Buffer(placeholder_2: handle, int32, [32, 256, 14, 14, 4], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer: int32, 0, 25) {
    if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*65536) + (blockIdx.x*256)) + floordiv(threadIdx.x, 4)) < 1605632) {
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x) < 6422528) {
        T_cast_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = cast(int8, max(min(@tir.q_multiply_shift((int32*)placeholder_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)], 2131420559, 31, -24, dtype=int32), 127), -128))
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
primfn(placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, placeholder_8: handle, placeholder_9: handle, T_relu_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_fixed_point_multiply_add_cast_15119380522063600768__1", "tir.noalias": True}
  buffers = {T_relu: Buffer(T_relu_2: handle, int32, [32, 256, 14, 14, 4], []),
             placeholder_4: Buffer(placeholder_10: handle, int32, [1, 256, 1, 1, 4], []),
             placeholder_2: Buffer(placeholder_11: handle, int32, [32, 256, 14, 14, 4], []),
             placeholder: Buffer(placeholder_12: handle, int32, [1, 256, 1, 1, 4], []),
             placeholder_1: Buffer(placeholder_13: handle, int8, [256, 64, 1, 1, 4, 4], []),
             placeholder_3: Buffer(placeholder_14: handle, int8, [32, 64, 14, 14, 4], [])}
  buffer_map = {placeholder_8: placeholder, T_relu_1: T_relu, placeholder_6: placeholder_1, placeholder_9: placeholder_2, placeholder_5: placeholder_3, placeholder_7: placeholder_4} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 16;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [16]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [1792]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [2048]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 16;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 7;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28 {
    for (oc_block.init: int32, 0, 4) "unroll" {
      compute[oc_block.init] = 0
      compute[(oc_block.init + 8)] = 0
      compute[(oc_block.init + 4)] = 0
      compute[(oc_block.init + 12)] = 0
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 4) "unroll" {
      attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28;
      pad_data.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*896) + (threadIdx.y_1*112)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_14[ramp((((((blockIdx.z*100352) + (floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*8) + threadIdx.y_1), 16)*50176)) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*8) + threadIdx.y_1), 16)*784)) + (blockIdx.x*112)) + (threadIdx.x_1*4)), 1, 4)]
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 5) "unroll" {
      attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
      attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28;
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.y_2*7)) + floordiv(threadIdx.x_2, 4)) < 256) {
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*224) + (threadIdx.y_2*28)) + threadIdx.x_2) < 1024) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*8) + threadIdx.y_2) < 37) {
            placeholder.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*896) + (threadIdx.y_2*112)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_13[ramp(((((blockIdx.y*16384) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.y_2*7)) + floordiv(threadIdx.x_2, 4)), 16)*1024)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.y_2*7)) + floordiv(threadIdx.x_2, 4)), 16)*16)) + (floormod(threadIdx.x_2, 4)*4)), 1, 4)]
          }
        }
      }
    }
    for (ic_chunk.outer.outer: int32, 0, 3) {
      attr [pad_data.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1: int32, 0, 4) "unroll" {
        attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
        attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28;
        pad_data.shared[ramp(((((floormod((ic_chunk.outer.outer + 1), 2)*3584) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*896)) + (threadIdx.y_1*112)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_14[ramp((((((((blockIdx.z*100352) + (floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*8) + threadIdx.y_1), 16)*50176)) + (ic_chunk.outer.outer*12544)) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*8) + threadIdx.y_1), 16)*784)) + (blockIdx.x*112)) + (threadIdx.x_1*4)) + 12544), 1, 4)]
      }
      attr [placeholder.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 5) "unroll" {
        attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
        attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.y_2*7)) + floordiv(threadIdx.x_2, 4)) < 256) {
          if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*224) + (threadIdx.y_2*28)) + threadIdx.x_2) < 1024) {
            if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*8) + threadIdx.y_2) < 37) {
              placeholder.shared[ramp(((((floormod((ic_chunk.outer.outer + 1), 2)*4096) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*896)) + (threadIdx.y_2*112)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_13[ramp(((((((blockIdx.y*16384) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.y_2*7)) + floordiv(threadIdx.x_2, 4)), 16)*1024)) + (ic_chunk.outer.outer*256)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.y_2*7)) + floordiv(threadIdx.x_2, 4)), 16)*16)) + (floormod(threadIdx.x_2, 4)*4)) + 256), 1, 4)]
            }
          }
        }
      }
      for (ic_chunk.inner: int32, 0, 16) "unroll" {
        for (oc_block: int32, 0, 4) "unroll" {
          compute[oc_block] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((floormod(ic_chunk.outer.outer, 2)*3584) + (ic_chunk.inner*112)) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*4096) + (threadIdx.y*256)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[oc_block], dtype=int32)
          compute[(oc_block + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*3584) + (ic_chunk.inner*112)) + (threadIdx.x*4)) + 1792), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*4096) + (threadIdx.y*256)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 8)], dtype=int32)
          compute[(oc_block + 4)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((floormod(ic_chunk.outer.outer, 2)*3584) + (ic_chunk.inner*112)) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*4096) + (threadIdx.y*256)) + (ic_chunk.inner*16)) + (oc_block*4)) + 2048), 1, 4)], (int32*)compute[(oc_block + 4)], dtype=int32)
          compute[(oc_block + 12)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*3584) + (ic_chunk.inner*112)) + (threadIdx.x*4)) + 1792), 1, 4)], (int8x4*)placeholder.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*4096) + (threadIdx.y*256)) + (ic_chunk.inner*16)) + (oc_block*4)) + 2048), 1, 4)], (int32*)compute[(oc_block + 12)], dtype=int32)
        }
      }
    }
    for (ic_chunk.inner_1: int32, 0, 16) "unroll" {
      for (oc_block_1: int32, 0, 4) "unroll" {
        compute[oc_block_1] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner_1*112) + (threadIdx.x*4)) + 3584), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*256) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 4096), 1, 4)], (int32*)compute[oc_block_1], dtype=int32)
        compute[(oc_block_1 + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner_1*112) + (threadIdx.x*4)) + 5376), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*256) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 4096), 1, 4)], (int32*)compute[(oc_block_1 + 8)], dtype=int32)
        compute[(oc_block_1 + 4)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner_1*112) + (threadIdx.x*4)) + 3584), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*256) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 6144), 1, 4)], (int32*)compute[(oc_block_1 + 4)], dtype=int32)
        compute[(oc_block_1 + 12)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner_1*112) + (threadIdx.x*4)) + 5376), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*256) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 6144), 1, 4)], (int32*)compute[(oc_block_1 + 12)], dtype=int32)
      }
    }
    for (ax4: int32, 0, 4) "unroll" {
      T_relu_2[((((((blockIdx.z*401408) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[ax4], 1971949056, 31, 17, dtype=int32) + (int32*)placeholder_10[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 1073767020, 31, 1, dtype=int32) + (int32*)placeholder_12[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 1367864638, 31, 0, dtype=int32) + @tir.q_multiply_shift((int32*)placeholder_11[((((((blockIdx.z*401408) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4)], 1595052047, 31, 0, dtype=int32)), 0)
      T_relu_2[(((((((blockIdx.z*401408) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4) + 200704)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 8)], 1971949056, 31, 17, dtype=int32) + (int32*)placeholder_10[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 1073767020, 31, 1, dtype=int32) + (int32*)placeholder_12[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 1367864638, 31, 0, dtype=int32) + @tir.q_multiply_shift((int32*)placeholder_11[(((((((blockIdx.z*401408) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4) + 200704)], 1595052047, 31, 0, dtype=int32)), 0)
      T_relu_2[(((((((blockIdx.z*401408) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4) + 6272)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 4)], 1971949056, 31, 17, dtype=int32) + (int32*)placeholder_10[((((blockIdx.y*64) + (threadIdx.y*4)) + ax4) + 32)]), 1073767020, 31, 1, dtype=int32) + (int32*)placeholder_12[((((blockIdx.y*64) + (threadIdx.y*4)) + ax4) + 32)]), 1367864638, 31, 0, dtype=int32) + @tir.q_multiply_shift((int32*)placeholder_11[(((((((blockIdx.z*401408) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4) + 6272)], 1595052047, 31, 0, dtype=int32)), 0)
      T_relu_2[(((((((blockIdx.z*401408) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4) + 206976)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 12)], 1971949056, 31, 17, dtype=int32) + (int32*)placeholder_10[((((blockIdx.y*64) + (threadIdx.y*4)) + ax4) + 32)]), 1073767020, 31, 1, dtype=int32) + (int32*)placeholder_12[((((blockIdx.y*64) + (threadIdx.y*4)) + ax4) + 32)]), 1367864638, 31, 0, dtype=int32) + @tir.q_multiply_shift((int32*)placeholder_11[(((((((blockIdx.z*401408) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4) + 206976)], 1595052047, 31, 0, dtype=int32)), 0)
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_nn_relu_cast_fixed_point_mult_18399029763786111876__3", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [32, 64, 14, 14, 4], []),
             placeholder_2: Buffer(placeholder_6: handle, int32, [1, 64, 1, 1, 4], []),
             placeholder: Buffer(placeholder_7: handle, int8, [32, 64, 14, 14, 4], []),
             placeholder_1: Buffer(placeholder_8: handle, int8, [64, 64, 3, 3, 4, 4], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 16;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [28]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [256]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [576]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 4;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 7;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4 {
    for (oh.init: int32, 0, 7) "unroll" {
      for (oc_block.init: int32, 0, 4) "unroll" {
        compute[((oh.init*4) + oc_block.init)] = 0
      }
    }
    attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
    attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
    attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
    pad_data.shared[ramp((((threadIdx.z_1*256) + (threadIdx.y_1*16)) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((1 <= threadIdx.y_1) && (threadIdx.y_1 < 15)) && (1 <= ((blockIdx.x*2) + threadIdx.x_1))) && (((blockIdx.x*2) + threadIdx.x_1) < 15)), (int8x4*)placeholder_7[ramp(((((((blockIdx.z*100352) + (threadIdx.z_1*50176)) + (threadIdx.y_1*56)) + (blockIdx.x*8)) + (threadIdx.x_1*4)) - 60), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
    for (ic_chunk.outer.outer: int32, 0, 63) {
      attr [pad_data.shared] "double_buffer_write" = 1;
      attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
      attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
      attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
      pad_data.shared[ramp(((((floormod((ic_chunk.outer.outer + 1), 2)*512) + (threadIdx.z_1*256)) + (threadIdx.y_1*16)) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((1 <= threadIdx.y_1) && (threadIdx.y_1 < 15)) && (1 <= ((blockIdx.x*2) + threadIdx.x_1))) && (((blockIdx.x*2) + threadIdx.x_1) < 15)), (int8x4*)placeholder_7[ramp((((((((blockIdx.z*100352) + (threadIdx.z_1*50176)) + (ic_chunk.outer.outer*784)) + (threadIdx.y_1*56)) + (blockIdx.x*8)) + (threadIdx.x_1*4)) + 724), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 5) "unroll" {
        attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
        attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.z_2*16)) + threadIdx.y_2) < 144) {
          if (((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*128) + (threadIdx.z_2*64)) + (threadIdx.y_2*4)) + threadIdx.x_2) < 576) {
            if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*2) + threadIdx.z_2) < 9) {
              placeholder.shared[ramp(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*512) + (threadIdx.z_2*256)) + (threadIdx.y_2*16)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp((((((blockIdx.y*147456) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.z_2*16)) + threadIdx.y_2), 9)*9216)) + (ic_chunk.outer.outer*144)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.z_2*16)) + threadIdx.y_2), 9)*16)) + (threadIdx.x_2*4)), 1, 4)]
            }
          }
        }
      }
      for (kw.inner: int32, 0, 3) "unroll" {
        for (kh.inner: int32, 0, 3) "unroll" {
          for (oh: int32, 0, 7) "unroll" {
            for (oc_block: int32, 0, 4) "unroll" {
              compute[((oh*4) + oc_block)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((((floormod(ic_chunk.outer.outer, 2)*512) + (threadIdx.z*256)) + (floordiv(threadIdx.x, 2)*112)) + (oh*16)) + (kh.inner*16)) + (kw.inner*4)) + (floormod(threadIdx.x, 2)*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*144) + (kh.inner*48)) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[((oh*4) + oc_block)], dtype=int32)
            }
          }
        }
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 5) "unroll" {
      attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
      attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
      attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.z_2*16)) + threadIdx.y_2) < 144) {
        if (((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_2*64)) + (threadIdx.y_2*4)) + threadIdx.x_2) < 576) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*2) + threadIdx.z_2) < 9) {
            placeholder.shared[ramp(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*512) + (threadIdx.z_2*256)) + (threadIdx.y_2*16)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp((((((blockIdx.y*147456) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.z_2*16)) + threadIdx.y_2), 9)*9216)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.z_2*16)) + threadIdx.y_2), 9)*16)) + (threadIdx.x_2*4)) + 9072), 1, 4)]
          }
        }
      }
    }
    for (kw.inner_1: int32, 0, 3) "unroll" {
      for (kh.inner_1: int32, 0, 3) "unroll" {
        for (oh_1: int32, 0, 7) "unroll" {
          for (oc_block_1: int32, 0, 4) "unroll" {
            compute[((oh_1*4) + oc_block_1)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((((threadIdx.z*256) + (floordiv(threadIdx.x, 2)*112)) + (oh_1*16)) + (kh.inner_1*16)) + (kw.inner_1*4)) + (floormod(threadIdx.x, 2)*4)) + 512), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*144) + (kh.inner_1*48)) + (kw.inner_1*16)) + (oc_block_1*4)), 1, 4)], (int32*)compute[((oh_1*4) + oc_block_1)], dtype=int32)
          }
        }
      }
    }
    for (ax2.inner.inner.inner: int32, 0, 7) "unroll" {
      for (ax4: int32, 0, 4) "unroll" {
        T_cast_2[(((((((((blockIdx.z*100352) + (threadIdx.z*50176)) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (floordiv(threadIdx.x, 2)*392)) + (ax2.inner.inner.inner*56)) + (blockIdx.x*8)) + (floormod(threadIdx.x, 2)*4)) + ax4)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((int32*)compute[((ax2.inner.inner.inner*4) + ax4)], 1310439947, 31, 17, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 0), 2139368712, 31, -24, dtype=int32), 127), -128))
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_fixed_point_multiply_add_cast_16086763325481941859__2", "tir.noalias": True}
  buffers = {placeholder_3: Buffer(placeholder_8: handle, int32, [1, 64, 1, 1, 4], []),
             placeholder_2: Buffer(placeholder_9: handle, int8, [64, 256, 1, 1, 4, 4], []),
             T_cast: Buffer(T_cast_2: handle, int8, [32, 64, 14, 14, 4], []),
             placeholder: Buffer(placeholder_10: handle, int8, [32, 256, 14, 14, 4], []),
             placeholder_1: Buffer(placeholder_11: handle, int32, [1, 64, 1, 1, 4], [])}
  buffer_map = {placeholder_4: placeholder, placeholder_6: placeholder_1, T_cast_1: T_cast, placeholder_5: placeholder_2, placeholder_7: placeholder_3} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 16;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [16]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [2048]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [896]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 4;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 7;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28 {
    for (n.init: int32, 0, 2) "unroll" {
      for (oc_block.init: int32, 0, 4) "unroll" {
        compute[((n.init*4) + oc_block.init)] = 0
        compute[(((n.init*4) + oc_block.init) + 8)] = 0
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 5) "unroll" {
      attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28;
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.y_1*7)) + floordiv(threadIdx.x_1, 4)) < 256) {
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*224) + (threadIdx.y_1*28)) + threadIdx.x_1) < 1024) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*8) + threadIdx.y_1) < 37) {
            placeholder.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*896) + (threadIdx.y_1*112)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_9[ramp(((((blockIdx.y*65536) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.y_1*7)) + floordiv(threadIdx.x_1, 4)), 16)*4096)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.y_1*7)) + floordiv(threadIdx.x_1, 4)), 16)*16)) + (floormod(threadIdx.x_1, 4)*4)), 1, 4)]
          }
        }
      }
    }
    for (ic_chunk.outer.outer: int32, 0, 15) {
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 4) "unroll" {
        attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28;
        pad_data.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*896) + (threadIdx.y_2*112)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_10[ramp(((((((blockIdx.z*401408) + (floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*8) + threadIdx.y_2), 16)*200704)) + (ic_chunk.outer.outer*12544)) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*8) + threadIdx.y_2), 16)*784)) + (blockIdx.x*112)) + (threadIdx.x_2*4)), 1, 4)]
      }
      attr [placeholder.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 5) "unroll" {
        attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
        attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.y_1*7)) + floordiv(threadIdx.x_1, 4)) < 256) {
          if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*224) + (threadIdx.y_1*28)) + threadIdx.x_1) < 1024) {
            if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*8) + threadIdx.y_1) < 37) {
              placeholder.shared[ramp(((((floormod((ic_chunk.outer.outer + 1), 2)*4096) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*896)) + (threadIdx.y_1*112)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_9[ramp(((((((blockIdx.y*65536) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.y_1*7)) + floordiv(threadIdx.x_1, 4)), 16)*4096)) + (ic_chunk.outer.outer*256)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.y_1*7)) + floordiv(threadIdx.x_1, 4)), 16)*16)) + (floormod(threadIdx.x_1, 4)*4)) + 256), 1, 4)]
            }
          }
        }
      }
      for (ic_chunk.inner: int32, 0, 16) "unroll" {
        for (n: int32, 0, 2) "unroll" {
          for (oc_block: int32, 0, 4) "unroll" {
            compute[((n*4) + oc_block)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((n*1792) + (ic_chunk.inner*112)) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*4096) + (threadIdx.y*256)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[((n*4) + oc_block)], dtype=int32)
            compute[(((n*4) + oc_block) + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((n*1792) + (ic_chunk.inner*112)) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*4096) + (threadIdx.y*256)) + (ic_chunk.inner*16)) + (oc_block*4)) + 2048), 1, 4)], (int32*)compute[(((n*4) + oc_block) + 8)], dtype=int32)
          }
        }
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1: int32, 0, 4) "unroll" {
      attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
      attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28;
      pad_data.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*896) + (threadIdx.y_2*112)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_10[ramp(((((((blockIdx.z*401408) + (floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*8) + threadIdx.y_2), 16)*200704)) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*8) + threadIdx.y_2), 16)*784)) + (blockIdx.x*112)) + (threadIdx.x_2*4)) + 188160), 1, 4)]
    }
    for (ic_chunk.inner_1: int32, 0, 16) "unroll" {
      for (n_1: int32, 0, 2) "unroll" {
        for (oc_block_1: int32, 0, 4) "unroll" {
          compute[((n_1*4) + oc_block_1)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((n_1*1792) + (ic_chunk.inner_1*112)) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*256) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 4096), 1, 4)], (int32*)compute[((n_1*4) + oc_block_1)], dtype=int32)
          compute[(((n_1*4) + oc_block_1) + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((n_1*1792) + (ic_chunk.inner_1*112)) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*256) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 6144), 1, 4)], (int32*)compute[(((n_1*4) + oc_block_1) + 8)], dtype=int32)
        }
      }
    }
    for (ax0.inner.inner.inner.inner: int32, 0, 2) "unroll" {
      for (ax4: int32, 0, 4) "unroll" {
        T_cast_2[(((((((blockIdx.z*100352) + (ax0.inner.inner.inner.inner*50176)) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[((ax0.inner.inner.inner.inner*4) + ax4)], 2032905037, 31, 17, dtype=int32) + (int32*)placeholder_11[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 2147476825, 31, 0, dtype=int32) + (int32*)placeholder_8[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 0), 1118430789, 31, -23, dtype=int32), 127), -128))
        T_cast_2[((((((((blockIdx.z*100352) + (ax0.inner.inner.inner.inner*50176)) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4) + 6272)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(((ax0.inner.inner.inner.inner*4) + ax4) + 8)], 2032905037, 31, 17, dtype=int32) + (int32*)placeholder_11[((((blockIdx.y*64) + (threadIdx.y*4)) + ax4) + 32)]), 2147476825, 31, 0, dtype=int32) + (int32*)placeholder_8[((((blockIdx.y*64) + (threadIdx.y*4)) + ax4) + 32)]), 0), 1118430789, 31, -23, dtype=int32), 127), -128))
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_fixed_point_multiply_clip_cast_3", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [32, 256, 14, 14, 4], []),
             placeholder: Buffer(placeholder_2: handle, int32, [32, 256, 14, 14, 4], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer: int32, 0, 25) {
    if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*65536) + (blockIdx.x*256)) + floordiv(threadIdx.x, 4)) < 1605632) {
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x) < 6422528) {
        T_cast_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = cast(int8, max(min(@tir.q_multiply_shift((int32*)placeholder_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)], 1595052047, 31, -24, dtype=int32), 127), -128))
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
primfn(placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, placeholder_8: handle, placeholder_9: handle, T_relu_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_fixed_point_multiply_add_cast_15119380522063600768__2", "tir.noalias": True}
  buffers = {placeholder_4: Buffer(placeholder_10: handle, int32, [32, 256, 14, 14, 4], []),
             placeholder_1: Buffer(placeholder_11: handle, int8, [256, 64, 1, 1, 4, 4], []),
             placeholder_2: Buffer(placeholder_12: handle, int32, [1, 256, 1, 1, 4], []),
             placeholder: Buffer(placeholder_13: handle, int8, [32, 64, 14, 14, 4], []),
             placeholder_3: Buffer(placeholder_14: handle, int32, [1, 256, 1, 1, 4], []),
             T_relu: Buffer(T_relu_2: handle, int32, [32, 256, 14, 14, 4], [])}
  buffer_map = {placeholder_5: placeholder, placeholder_6: placeholder_1, placeholder_7: placeholder_2, placeholder_8: placeholder_3, T_relu_1: T_relu, placeholder_9: placeholder_4} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 16;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [16]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [1792]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [2048]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 16;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 7;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28 {
    for (oc_block.init: int32, 0, 4) "unroll" {
      compute[oc_block.init] = 0
      compute[(oc_block.init + 8)] = 0
      compute[(oc_block.init + 4)] = 0
      compute[(oc_block.init + 12)] = 0
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 4) "unroll" {
      attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28;
      pad_data.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*896) + (threadIdx.y_1*112)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_13[ramp((((((blockIdx.z*100352) + (floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*8) + threadIdx.y_1), 16)*50176)) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*8) + threadIdx.y_1), 16)*784)) + (blockIdx.x*112)) + (threadIdx.x_1*4)), 1, 4)]
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 5) "unroll" {
      attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
      attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28;
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.y_2*7)) + floordiv(threadIdx.x_2, 4)) < 256) {
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*224) + (threadIdx.y_2*28)) + threadIdx.x_2) < 1024) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*8) + threadIdx.y_2) < 37) {
            placeholder.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*896) + (threadIdx.y_2*112)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_11[ramp(((((blockIdx.y*16384) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.y_2*7)) + floordiv(threadIdx.x_2, 4)), 16)*1024)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.y_2*7)) + floordiv(threadIdx.x_2, 4)), 16)*16)) + (floormod(threadIdx.x_2, 4)*4)), 1, 4)]
          }
        }
      }
    }
    for (ic_chunk.outer.outer: int32, 0, 3) {
      attr [pad_data.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1: int32, 0, 4) "unroll" {
        attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
        attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28;
        pad_data.shared[ramp(((((floormod((ic_chunk.outer.outer + 1), 2)*3584) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*896)) + (threadIdx.y_1*112)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_13[ramp((((((((blockIdx.z*100352) + (floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*8) + threadIdx.y_1), 16)*50176)) + (ic_chunk.outer.outer*12544)) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*8) + threadIdx.y_1), 16)*784)) + (blockIdx.x*112)) + (threadIdx.x_1*4)) + 12544), 1, 4)]
      }
      attr [placeholder.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 5) "unroll" {
        attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
        attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.y_2*7)) + floordiv(threadIdx.x_2, 4)) < 256) {
          if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*224) + (threadIdx.y_2*28)) + threadIdx.x_2) < 1024) {
            if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*8) + threadIdx.y_2) < 37) {
              placeholder.shared[ramp(((((floormod((ic_chunk.outer.outer + 1), 2)*4096) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*896)) + (threadIdx.y_2*112)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_11[ramp(((((((blockIdx.y*16384) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.y_2*7)) + floordiv(threadIdx.x_2, 4)), 16)*1024)) + (ic_chunk.outer.outer*256)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.y_2*7)) + floordiv(threadIdx.x_2, 4)), 16)*16)) + (floormod(threadIdx.x_2, 4)*4)) + 256), 1, 4)]
            }
          }
        }
      }
      for (ic_chunk.inner: int32, 0, 16) "unroll" {
        for (oc_block: int32, 0, 4) "unroll" {
          compute[oc_block] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((floormod(ic_chunk.outer.outer, 2)*3584) + (ic_chunk.inner*112)) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*4096) + (threadIdx.y*256)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[oc_block], dtype=int32)
          compute[(oc_block + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*3584) + (ic_chunk.inner*112)) + (threadIdx.x*4)) + 1792), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*4096) + (threadIdx.y*256)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 8)], dtype=int32)
          compute[(oc_block + 4)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((floormod(ic_chunk.outer.outer, 2)*3584) + (ic_chunk.inner*112)) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*4096) + (threadIdx.y*256)) + (ic_chunk.inner*16)) + (oc_block*4)) + 2048), 1, 4)], (int32*)compute[(oc_block + 4)], dtype=int32)
          compute[(oc_block + 12)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*3584) + (ic_chunk.inner*112)) + (threadIdx.x*4)) + 1792), 1, 4)], (int8x4*)placeholder.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*4096) + (threadIdx.y*256)) + (ic_chunk.inner*16)) + (oc_block*4)) + 2048), 1, 4)], (int32*)compute[(oc_block + 12)], dtype=int32)
        }
      }
    }
    for (ic_chunk.inner_1: int32, 0, 16) "unroll" {
      for (oc_block_1: int32, 0, 4) "unroll" {
        compute[oc_block_1] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner_1*112) + (threadIdx.x*4)) + 3584), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*256) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 4096), 1, 4)], (int32*)compute[oc_block_1], dtype=int32)
        compute[(oc_block_1 + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner_1*112) + (threadIdx.x*4)) + 5376), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*256) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 4096), 1, 4)], (int32*)compute[(oc_block_1 + 8)], dtype=int32)
        compute[(oc_block_1 + 4)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner_1*112) + (threadIdx.x*4)) + 3584), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*256) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 6144), 1, 4)], (int32*)compute[(oc_block_1 + 4)], dtype=int32)
        compute[(oc_block_1 + 12)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner_1*112) + (threadIdx.x*4)) + 5376), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*256) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 6144), 1, 4)], (int32*)compute[(oc_block_1 + 12)], dtype=int32)
      }
    }
    for (ax4: int32, 0, 4) "unroll" {
      T_relu_2[((((((blockIdx.z*401408) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[ax4], 1255636241, 31, 19, dtype=int32) + (int32*)placeholder_12[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 2147438515, 31, 0, dtype=int32) + (int32*)placeholder_14[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 1640264770, 31, 0, dtype=int32) + @tir.q_multiply_shift((int32*)placeholder_10[((((((blockIdx.z*401408) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4)], 1978965331, 31, 0, dtype=int32)), 0)
      T_relu_2[(((((((blockIdx.z*401408) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4) + 200704)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 8)], 1255636241, 31, 19, dtype=int32) + (int32*)placeholder_12[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 2147438515, 31, 0, dtype=int32) + (int32*)placeholder_14[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 1640264770, 31, 0, dtype=int32) + @tir.q_multiply_shift((int32*)placeholder_10[(((((((blockIdx.z*401408) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4) + 200704)], 1978965331, 31, 0, dtype=int32)), 0)
      T_relu_2[(((((((blockIdx.z*401408) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4) + 6272)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 4)], 1255636241, 31, 19, dtype=int32) + (int32*)placeholder_12[((((blockIdx.y*64) + (threadIdx.y*4)) + ax4) + 32)]), 2147438515, 31, 0, dtype=int32) + (int32*)placeholder_14[((((blockIdx.y*64) + (threadIdx.y*4)) + ax4) + 32)]), 1640264770, 31, 0, dtype=int32) + @tir.q_multiply_shift((int32*)placeholder_10[(((((((blockIdx.z*401408) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4) + 6272)], 1978965331, 31, 0, dtype=int32)), 0)
      T_relu_2[(((((((blockIdx.z*401408) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4) + 206976)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 12)], 1255636241, 31, 19, dtype=int32) + (int32*)placeholder_12[((((blockIdx.y*64) + (threadIdx.y*4)) + ax4) + 32)]), 2147438515, 31, 0, dtype=int32) + (int32*)placeholder_14[((((blockIdx.y*64) + (threadIdx.y*4)) + ax4) + 32)]), 1640264770, 31, 0, dtype=int32) + @tir.q_multiply_shift((int32*)placeholder_10[(((((((blockIdx.z*401408) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4) + 206976)], 1978965331, 31, 0, dtype=int32)), 0)
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_nn_relu_cast_fixed_point_mult_18399029763786111876__4", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [32, 64, 14, 14, 4], []),
             placeholder_2: Buffer(placeholder_6: handle, int32, [1, 64, 1, 1, 4], []),
             placeholder: Buffer(placeholder_7: handle, int8, [32, 64, 14, 14, 4], []),
             placeholder_1: Buffer(placeholder_8: handle, int8, [64, 64, 3, 3, 4, 4], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 16;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [28]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [256]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [576]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 4;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 7;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4 {
    for (oh.init: int32, 0, 7) "unroll" {
      for (oc_block.init: int32, 0, 4) "unroll" {
        compute[((oh.init*4) + oc_block.init)] = 0
      }
    }
    attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
    attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
    attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
    pad_data.shared[ramp((((threadIdx.z_1*256) + (threadIdx.y_1*16)) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((1 <= threadIdx.y_1) && (threadIdx.y_1 < 15)) && (1 <= ((blockIdx.x*2) + threadIdx.x_1))) && (((blockIdx.x*2) + threadIdx.x_1) < 15)), (int8x4*)placeholder_7[ramp(((((((blockIdx.z*100352) + (threadIdx.z_1*50176)) + (threadIdx.y_1*56)) + (blockIdx.x*8)) + (threadIdx.x_1*4)) - 60), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
    for (ic_chunk.outer.outer: int32, 0, 63) {
      attr [pad_data.shared] "double_buffer_write" = 1;
      attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
      attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
      attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
      pad_data.shared[ramp(((((floormod((ic_chunk.outer.outer + 1), 2)*512) + (threadIdx.z_1*256)) + (threadIdx.y_1*16)) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((1 <= threadIdx.y_1) && (threadIdx.y_1 < 15)) && (1 <= ((blockIdx.x*2) + threadIdx.x_1))) && (((blockIdx.x*2) + threadIdx.x_1) < 15)), (int8x4*)placeholder_7[ramp((((((((blockIdx.z*100352) + (threadIdx.z_1*50176)) + (ic_chunk.outer.outer*784)) + (threadIdx.y_1*56)) + (blockIdx.x*8)) + (threadIdx.x_1*4)) + 724), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 5) "unroll" {
        attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
        attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.z_2*16)) + threadIdx.y_2) < 144) {
          if (((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*128) + (threadIdx.z_2*64)) + (threadIdx.y_2*4)) + threadIdx.x_2) < 576) {
            if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*2) + threadIdx.z_2) < 9) {
              placeholder.shared[ramp(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*512) + (threadIdx.z_2*256)) + (threadIdx.y_2*16)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp((((((blockIdx.y*147456) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.z_2*16)) + threadIdx.y_2), 9)*9216)) + (ic_chunk.outer.outer*144)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.z_2*16)) + threadIdx.y_2), 9)*16)) + (threadIdx.x_2*4)), 1, 4)]
            }
          }
        }
      }
      for (kw.inner: int32, 0, 3) "unroll" {
        for (kh.inner: int32, 0, 3) "unroll" {
          for (oh: int32, 0, 7) "unroll" {
            for (oc_block: int32, 0, 4) "unroll" {
              compute[((oh*4) + oc_block)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((((floormod(ic_chunk.outer.outer, 2)*512) + (threadIdx.z*256)) + (floordiv(threadIdx.x, 2)*112)) + (oh*16)) + (kh.inner*16)) + (kw.inner*4)) + (floormod(threadIdx.x, 2)*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*144) + (kh.inner*48)) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[((oh*4) + oc_block)], dtype=int32)
            }
          }
        }
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 5) "unroll" {
      attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
      attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
      attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.z_2*16)) + threadIdx.y_2) < 144) {
        if (((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_2*64)) + (threadIdx.y_2*4)) + threadIdx.x_2) < 576) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*2) + threadIdx.z_2) < 9) {
            placeholder.shared[ramp(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*512) + (threadIdx.z_2*256)) + (threadIdx.y_2*16)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp((((((blockIdx.y*147456) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.z_2*16)) + threadIdx.y_2), 9)*9216)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.z_2*16)) + threadIdx.y_2), 9)*16)) + (threadIdx.x_2*4)) + 9072), 1, 4)]
          }
        }
      }
    }
    for (kw.inner_1: int32, 0, 3) "unroll" {
      for (kh.inner_1: int32, 0, 3) "unroll" {
        for (oh_1: int32, 0, 7) "unroll" {
          for (oc_block_1: int32, 0, 4) "unroll" {
            compute[((oh_1*4) + oc_block_1)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((((threadIdx.z*256) + (floordiv(threadIdx.x, 2)*112)) + (oh_1*16)) + (kh.inner_1*16)) + (kw.inner_1*4)) + (floormod(threadIdx.x, 2)*4)) + 512), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*144) + (kh.inner_1*48)) + (kw.inner_1*16)) + (oc_block_1*4)), 1, 4)], (int32*)compute[((oh_1*4) + oc_block_1)], dtype=int32)
          }
        }
      }
    }
    for (ax2.inner.inner.inner: int32, 0, 7) "unroll" {
      for (ax4: int32, 0, 4) "unroll" {
        T_cast_2[(((((((((blockIdx.z*100352) + (threadIdx.z*50176)) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (floordiv(threadIdx.x, 2)*392)) + (ax2.inner.inner.inner*56)) + (blockIdx.x*8)) + (floormod(threadIdx.x, 2)*4)) + ax4)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((int32*)compute[((ax2.inner.inner.inner*4) + ax4)], 1972495247, 31, 16, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 0), 1152190013, 31, -23, dtype=int32), 127), -128))
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_fixed_point_multiply_add_cast_16086763325481941859__3", "tir.noalias": True}
  buffers = {placeholder_2: Buffer(placeholder_8: handle, int32, [1, 64, 1, 1, 4], []),
             placeholder_3: Buffer(placeholder_9: handle, int8, [32, 256, 14, 14, 4], []),
             T_cast: Buffer(T_cast_2: handle, int8, [32, 64, 14, 14, 4], []),
             placeholder: Buffer(placeholder_10: handle, int8, [64, 256, 1, 1, 4, 4], []),
             placeholder_1: Buffer(placeholder_11: handle, int32, [1, 64, 1, 1, 4], [])}
  buffer_map = {placeholder_5: placeholder, placeholder_7: placeholder_1, placeholder_6: placeholder_2, T_cast_1: T_cast, placeholder_4: placeholder_3} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 16;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [16]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [2048]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [896]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 4;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 7;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28 {
    for (n.init: int32, 0, 2) "unroll" {
      for (oc_block.init: int32, 0, 4) "unroll" {
        compute[((n.init*4) + oc_block.init)] = 0
        compute[(((n.init*4) + oc_block.init) + 8)] = 0
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 5) "unroll" {
      attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28;
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.y_1*7)) + floordiv(threadIdx.x_1, 4)) < 256) {
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*224) + (threadIdx.y_1*28)) + threadIdx.x_1) < 1024) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*8) + threadIdx.y_1) < 37) {
            placeholder.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*896) + (threadIdx.y_1*112)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_10[ramp(((((blockIdx.y*65536) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.y_1*7)) + floordiv(threadIdx.x_1, 4)), 16)*4096)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.y_1*7)) + floordiv(threadIdx.x_1, 4)), 16)*16)) + (floormod(threadIdx.x_1, 4)*4)), 1, 4)]
          }
        }
      }
    }
    for (ic_chunk.outer.outer: int32, 0, 15) {
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 4) "unroll" {
        attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28;
        pad_data.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*896) + (threadIdx.y_2*112)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_9[ramp(((((((blockIdx.z*401408) + (floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*8) + threadIdx.y_2), 16)*200704)) + (ic_chunk.outer.outer*12544)) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*8) + threadIdx.y_2), 16)*784)) + (blockIdx.x*112)) + (threadIdx.x_2*4)), 1, 4)]
      }
      attr [placeholder.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 5) "unroll" {
        attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
        attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.y_1*7)) + floordiv(threadIdx.x_1, 4)) < 256) {
          if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*224) + (threadIdx.y_1*28)) + threadIdx.x_1) < 1024) {
            if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*8) + threadIdx.y_1) < 37) {
              placeholder.shared[ramp(((((floormod((ic_chunk.outer.outer + 1), 2)*4096) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*896)) + (threadIdx.y_1*112)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_10[ramp(((((((blockIdx.y*65536) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.y_1*7)) + floordiv(threadIdx.x_1, 4)), 16)*4096)) + (ic_chunk.outer.outer*256)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.y_1*7)) + floordiv(threadIdx.x_1, 4)), 16)*16)) + (floormod(threadIdx.x_1, 4)*4)) + 256), 1, 4)]
            }
          }
        }
      }
      for (ic_chunk.inner: int32, 0, 16) "unroll" {
        for (n: int32, 0, 2) "unroll" {
          for (oc_block: int32, 0, 4) "unroll" {
            compute[((n*4) + oc_block)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((n*1792) + (ic_chunk.inner*112)) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*4096) + (threadIdx.y*256)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[((n*4) + oc_block)], dtype=int32)
            compute[(((n*4) + oc_block) + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((n*1792) + (ic_chunk.inner*112)) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*4096) + (threadIdx.y*256)) + (ic_chunk.inner*16)) + (oc_block*4)) + 2048), 1, 4)], (int32*)compute[(((n*4) + oc_block) + 8)], dtype=int32)
          }
        }
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1: int32, 0, 4) "unroll" {
      attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
      attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28;
      pad_data.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*896) + (threadIdx.y_2*112)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_9[ramp(((((((blockIdx.z*401408) + (floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*8) + threadIdx.y_2), 16)*200704)) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*8) + threadIdx.y_2), 16)*784)) + (blockIdx.x*112)) + (threadIdx.x_2*4)) + 188160), 1, 4)]
    }
    for (ic_chunk.inner_1: int32, 0, 16) "unroll" {
      for (n_1: int32, 0, 2) "unroll" {
        for (oc_block_1: int32, 0, 4) "unroll" {
          compute[((n_1*4) + oc_block_1)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((n_1*1792) + (ic_chunk.inner_1*112)) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*256) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 4096), 1, 4)], (int32*)compute[((n_1*4) + oc_block_1)], dtype=int32)
          compute[(((n_1*4) + oc_block_1) + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((n_1*1792) + (ic_chunk.inner_1*112)) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*256) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 6144), 1, 4)], (int32*)compute[(((n_1*4) + oc_block_1) + 8)], dtype=int32)
        }
      }
    }
    for (ax0.inner.inner.inner.inner: int32, 0, 2) "unroll" {
      for (ax4: int32, 0, 4) "unroll" {
        T_cast_2[(((((((blockIdx.z*100352) + (ax0.inner.inner.inner.inner*50176)) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[((ax0.inner.inner.inner.inner*4) + ax4)], 1488572971, 31, 17, dtype=int32) + (int32*)placeholder_8[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 2147475317, 31, 0, dtype=int32) + (int32*)placeholder_11[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 0), 1085271558, 31, -23, dtype=int32), 127), -128))
        T_cast_2[((((((((blockIdx.z*100352) + (ax0.inner.inner.inner.inner*50176)) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4) + 6272)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(((ax0.inner.inner.inner.inner*4) + ax4) + 8)], 1488572971, 31, 17, dtype=int32) + (int32*)placeholder_8[((((blockIdx.y*64) + (threadIdx.y*4)) + ax4) + 32)]), 2147475317, 31, 0, dtype=int32) + (int32*)placeholder_11[((((blockIdx.y*64) + (threadIdx.y*4)) + ax4) + 32)]), 0), 1085271558, 31, -23, dtype=int32), 127), -128))
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_fixed_point_multiply_clip_cast_4", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [32, 256, 14, 14, 4], []),
             placeholder: Buffer(placeholder_2: handle, int32, [32, 256, 14, 14, 4], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer: int32, 0, 25) {
    if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*65536) + (blockIdx.x*256)) + floordiv(threadIdx.x, 4)) < 1605632) {
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x) < 6422528) {
        T_cast_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = cast(int8, max(min(@tir.q_multiply_shift((int32*)placeholder_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)], 1978965331, 31, -24, dtype=int32), 127), -128))
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
primfn(placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, placeholder_8: handle, placeholder_9: handle, T_relu_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_fixed_point_multiply_add_cast_15119380522063600768__3", "tir.noalias": True}
  buffers = {placeholder_4: Buffer(placeholder_10: handle, int32, [32, 256, 14, 14, 4], []),
             placeholder_1: Buffer(placeholder_11: handle, int32, [1, 256, 1, 1, 4], []),
             placeholder: Buffer(placeholder_12: handle, int8, [32, 64, 14, 14, 4], []),
             placeholder_2: Buffer(placeholder_13: handle, int32, [1, 256, 1, 1, 4], []),
             T_relu: Buffer(T_relu_2: handle, int32, [32, 256, 14, 14, 4], []),
             placeholder_3: Buffer(placeholder_14: handle, int8, [256, 64, 1, 1, 4, 4], [])}
  buffer_map = {placeholder_5: placeholder, placeholder_7: placeholder_1, placeholder_8: placeholder_2, T_relu_1: T_relu, placeholder_6: placeholder_3, placeholder_9: placeholder_4} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 16;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [16]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [1792]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [2048]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 16;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 7;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28 {
    for (oc_block.init: int32, 0, 4) "unroll" {
      compute[oc_block.init] = 0
      compute[(oc_block.init + 8)] = 0
      compute[(oc_block.init + 4)] = 0
      compute[(oc_block.init + 12)] = 0
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 4) "unroll" {
      attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28;
      pad_data.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*896) + (threadIdx.y_1*112)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_12[ramp((((((blockIdx.z*100352) + (floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*8) + threadIdx.y_1), 16)*50176)) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*8) + threadIdx.y_1), 16)*784)) + (blockIdx.x*112)) + (threadIdx.x_1*4)), 1, 4)]
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 5) "unroll" {
      attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
      attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28;
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.y_2*7)) + floordiv(threadIdx.x_2, 4)) < 256) {
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*224) + (threadIdx.y_2*28)) + threadIdx.x_2) < 1024) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*8) + threadIdx.y_2) < 37) {
            placeholder.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*896) + (threadIdx.y_2*112)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_14[ramp(((((blockIdx.y*16384) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.y_2*7)) + floordiv(threadIdx.x_2, 4)), 16)*1024)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.y_2*7)) + floordiv(threadIdx.x_2, 4)), 16)*16)) + (floormod(threadIdx.x_2, 4)*4)), 1, 4)]
          }
        }
      }
    }
    for (ic_chunk.outer.outer: int32, 0, 3) {
      attr [pad_data.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1: int32, 0, 4) "unroll" {
        attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
        attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28;
        pad_data.shared[ramp(((((floormod((ic_chunk.outer.outer + 1), 2)*3584) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*896)) + (threadIdx.y_1*112)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_12[ramp((((((((blockIdx.z*100352) + (floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*8) + threadIdx.y_1), 16)*50176)) + (ic_chunk.outer.outer*12544)) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*8) + threadIdx.y_1), 16)*784)) + (blockIdx.x*112)) + (threadIdx.x_1*4)) + 12544), 1, 4)]
      }
      attr [placeholder.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 5) "unroll" {
        attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
        attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.y_2*7)) + floordiv(threadIdx.x_2, 4)) < 256) {
          if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*224) + (threadIdx.y_2*28)) + threadIdx.x_2) < 1024) {
            if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*8) + threadIdx.y_2) < 37) {
              placeholder.shared[ramp(((((floormod((ic_chunk.outer.outer + 1), 2)*4096) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*896)) + (threadIdx.y_2*112)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_14[ramp(((((((blockIdx.y*16384) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.y_2*7)) + floordiv(threadIdx.x_2, 4)), 16)*1024)) + (ic_chunk.outer.outer*256)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.y_2*7)) + floordiv(threadIdx.x_2, 4)), 16)*16)) + (floormod(threadIdx.x_2, 4)*4)) + 256), 1, 4)]
            }
          }
        }
      }
      for (ic_chunk.inner: int32, 0, 16) "unroll" {
        for (oc_block: int32, 0, 4) "unroll" {
          compute[oc_block] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((floormod(ic_chunk.outer.outer, 2)*3584) + (ic_chunk.inner*112)) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*4096) + (threadIdx.y*256)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[oc_block], dtype=int32)
          compute[(oc_block + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*3584) + (ic_chunk.inner*112)) + (threadIdx.x*4)) + 1792), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*4096) + (threadIdx.y*256)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 8)], dtype=int32)
          compute[(oc_block + 4)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((floormod(ic_chunk.outer.outer, 2)*3584) + (ic_chunk.inner*112)) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*4096) + (threadIdx.y*256)) + (ic_chunk.inner*16)) + (oc_block*4)) + 2048), 1, 4)], (int32*)compute[(oc_block + 4)], dtype=int32)
          compute[(oc_block + 12)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*3584) + (ic_chunk.inner*112)) + (threadIdx.x*4)) + 1792), 1, 4)], (int8x4*)placeholder.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*4096) + (threadIdx.y*256)) + (ic_chunk.inner*16)) + (oc_block*4)) + 2048), 1, 4)], (int32*)compute[(oc_block + 12)], dtype=int32)
        }
      }
    }
    for (ic_chunk.inner_1: int32, 0, 16) "unroll" {
      for (oc_block_1: int32, 0, 4) "unroll" {
        compute[oc_block_1] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner_1*112) + (threadIdx.x*4)) + 3584), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*256) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 4096), 1, 4)], (int32*)compute[oc_block_1], dtype=int32)
        compute[(oc_block_1 + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner_1*112) + (threadIdx.x*4)) + 5376), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*256) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 4096), 1, 4)], (int32*)compute[(oc_block_1 + 8)], dtype=int32)
        compute[(oc_block_1 + 4)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner_1*112) + (threadIdx.x*4)) + 3584), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*256) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 6144), 1, 4)], (int32*)compute[(oc_block_1 + 4)], dtype=int32)
        compute[(oc_block_1 + 12)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner_1*112) + (threadIdx.x*4)) + 5376), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*256) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 6144), 1, 4)], (int32*)compute[(oc_block_1 + 12)], dtype=int32)
      }
    }
    for (ax4: int32, 0, 4) "unroll" {
      T_relu_2[((((((blockIdx.z*401408) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[ax4], 1098578370, 31, 18, dtype=int32) + (int32*)placeholder_11[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 2147430505, 31, 0, dtype=int32) + (int32*)placeholder_13[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 1786494896, 31, 0, dtype=int32) + @tir.q_multiply_shift((int32*)placeholder_10[((((((blockIdx.z*401408) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4)], 2089225123, 31, 0, dtype=int32)), 0)
      T_relu_2[(((((((blockIdx.z*401408) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4) + 200704)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 8)], 1098578370, 31, 18, dtype=int32) + (int32*)placeholder_11[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 2147430505, 31, 0, dtype=int32) + (int32*)placeholder_13[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 1786494896, 31, 0, dtype=int32) + @tir.q_multiply_shift((int32*)placeholder_10[(((((((blockIdx.z*401408) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4) + 200704)], 2089225123, 31, 0, dtype=int32)), 0)
      T_relu_2[(((((((blockIdx.z*401408) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4) + 6272)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 4)], 1098578370, 31, 18, dtype=int32) + (int32*)placeholder_11[((((blockIdx.y*64) + (threadIdx.y*4)) + ax4) + 32)]), 2147430505, 31, 0, dtype=int32) + (int32*)placeholder_13[((((blockIdx.y*64) + (threadIdx.y*4)) + ax4) + 32)]), 1786494896, 31, 0, dtype=int32) + @tir.q_multiply_shift((int32*)placeholder_10[(((((((blockIdx.z*401408) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4) + 6272)], 2089225123, 31, 0, dtype=int32)), 0)
      T_relu_2[(((((((blockIdx.z*401408) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4) + 206976)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 12)], 1098578370, 31, 18, dtype=int32) + (int32*)placeholder_11[((((blockIdx.y*64) + (threadIdx.y*4)) + ax4) + 32)]), 2147430505, 31, 0, dtype=int32) + (int32*)placeholder_13[((((blockIdx.y*64) + (threadIdx.y*4)) + ax4) + 32)]), 1786494896, 31, 0, dtype=int32) + @tir.q_multiply_shift((int32*)placeholder_10[(((((((blockIdx.z*401408) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4) + 206976)], 2089225123, 31, 0, dtype=int32)), 0)
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_nn_relu_cast_fixed_point_mult_18399029763786111876__5", "tir.noalias": True}
  buffers = {placeholder_2: Buffer(placeholder_6: handle, int32, [1, 64, 1, 1, 4], []),
             T_cast: Buffer(T_cast_2: handle, int8, [32, 64, 14, 14, 4], []),
             placeholder: Buffer(placeholder_7: handle, int8, [32, 64, 14, 14, 4], []),
             placeholder_1: Buffer(placeholder_8: handle, int8, [64, 64, 3, 3, 4, 4], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 16;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [28]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [256]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [576]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 4;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 7;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4 {
    for (oh.init: int32, 0, 7) "unroll" {
      for (oc_block.init: int32, 0, 4) "unroll" {
        compute[((oh.init*4) + oc_block.init)] = 0
      }
    }
    attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
    attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
    attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
    pad_data.shared[ramp((((threadIdx.z_1*256) + (threadIdx.y_1*16)) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((1 <= threadIdx.y_1) && (threadIdx.y_1 < 15)) && (1 <= ((blockIdx.x*2) + threadIdx.x_1))) && (((blockIdx.x*2) + threadIdx.x_1) < 15)), (int8x4*)placeholder_7[ramp(((((((blockIdx.z*100352) + (threadIdx.z_1*50176)) + (threadIdx.y_1*56)) + (blockIdx.x*8)) + (threadIdx.x_1*4)) - 60), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
    for (ic_chunk.outer.outer: int32, 0, 63) {
      attr [pad_data.shared] "double_buffer_write" = 1;
      attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
      attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
      attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
      pad_data.shared[ramp(((((floormod((ic_chunk.outer.outer + 1), 2)*512) + (threadIdx.z_1*256)) + (threadIdx.y_1*16)) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((1 <= threadIdx.y_1) && (threadIdx.y_1 < 15)) && (1 <= ((blockIdx.x*2) + threadIdx.x_1))) && (((blockIdx.x*2) + threadIdx.x_1) < 15)), (int8x4*)placeholder_7[ramp((((((((blockIdx.z*100352) + (threadIdx.z_1*50176)) + (ic_chunk.outer.outer*784)) + (threadIdx.y_1*56)) + (blockIdx.x*8)) + (threadIdx.x_1*4)) + 724), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 5) "unroll" {
        attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
        attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.z_2*16)) + threadIdx.y_2) < 144) {
          if (((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*128) + (threadIdx.z_2*64)) + (threadIdx.y_2*4)) + threadIdx.x_2) < 576) {
            if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*2) + threadIdx.z_2) < 9) {
              placeholder.shared[ramp(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*512) + (threadIdx.z_2*256)) + (threadIdx.y_2*16)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp((((((blockIdx.y*147456) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.z_2*16)) + threadIdx.y_2), 9)*9216)) + (ic_chunk.outer.outer*144)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.z_2*16)) + threadIdx.y_2), 9)*16)) + (threadIdx.x_2*4)), 1, 4)]
            }
          }
        }
      }
      for (kw.inner: int32, 0, 3) "unroll" {
        for (kh.inner: int32, 0, 3) "unroll" {
          for (oh: int32, 0, 7) "unroll" {
            for (oc_block: int32, 0, 4) "unroll" {
              compute[((oh*4) + oc_block)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((((floormod(ic_chunk.outer.outer, 2)*512) + (threadIdx.z*256)) + (floordiv(threadIdx.x, 2)*112)) + (oh*16)) + (kh.inner*16)) + (kw.inner*4)) + (floormod(threadIdx.x, 2)*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*144) + (kh.inner*48)) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[((oh*4) + oc_block)], dtype=int32)
            }
          }
        }
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 5) "unroll" {
      attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
      attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
      attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.z_2*16)) + threadIdx.y_2) < 144) {
        if (((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_2*64)) + (threadIdx.y_2*4)) + threadIdx.x_2) < 576) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*2) + threadIdx.z_2) < 9) {
            placeholder.shared[ramp(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*512) + (threadIdx.z_2*256)) + (threadIdx.y_2*16)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp((((((blockIdx.y*147456) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.z_2*16)) + threadIdx.y_2), 9)*9216)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.z_2*16)) + threadIdx.y_2), 9)*16)) + (threadIdx.x_2*4)) + 9072), 1, 4)]
          }
        }
      }
    }
    for (kw.inner_1: int32, 0, 3) "unroll" {
      for (kh.inner_1: int32, 0, 3) "unroll" {
        for (oh_1: int32, 0, 7) "unroll" {
          for (oc_block_1: int32, 0, 4) "unroll" {
            compute[((oh_1*4) + oc_block_1)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((((threadIdx.z*256) + (floordiv(threadIdx.x, 2)*112)) + (oh_1*16)) + (kh.inner_1*16)) + (kw.inner_1*4)) + (floormod(threadIdx.x, 2)*4)) + 512), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*144) + (kh.inner_1*48)) + (kw.inner_1*16)) + (oc_block_1*4)), 1, 4)], (int32*)compute[((oh_1*4) + oc_block_1)], dtype=int32)
          }
        }
      }
    }
    for (ax2.inner.inner.inner: int32, 0, 7) "unroll" {
      for (ax4: int32, 0, 4) "unroll" {
        T_cast_2[(((((((((blockIdx.z*100352) + (threadIdx.z*50176)) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (floordiv(threadIdx.x, 2)*392)) + (ax2.inner.inner.inner*56)) + (blockIdx.x*8)) + (floormod(threadIdx.x, 2)*4)) + ax4)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((int32*)compute[((ax2.inner.inner.inner*4) + ax4)], 1266188500, 31, 17, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 0), 1185323653, 31, -23, dtype=int32), 127), -128))
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_fixed_point_multiply_add_cast_16086763325481941859__4", "tir.noalias": True}
  buffers = {placeholder_2: Buffer(placeholder_8: handle, int8, [32, 256, 14, 14, 4], []),
             placeholder_3: Buffer(placeholder_9: handle, int32, [1, 64, 1, 1, 4], []),
             placeholder: Buffer(placeholder_10: handle, int8, [64, 256, 1, 1, 4, 4], []),
             T_cast: Buffer(T_cast_2: handle, int8, [32, 64, 14, 14, 4], []),
             placeholder_1: Buffer(placeholder_11: handle, int32, [1, 64, 1, 1, 4], [])}
  buffer_map = {placeholder_5: placeholder, placeholder_6: placeholder_1, placeholder_4: placeholder_2, T_cast_1: T_cast, placeholder_7: placeholder_3} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 16;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [16]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [2048]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [896]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 4;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 7;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28 {
    for (n.init: int32, 0, 2) "unroll" {
      for (oc_block.init: int32, 0, 4) "unroll" {
        compute[((n.init*4) + oc_block.init)] = 0
        compute[(((n.init*4) + oc_block.init) + 8)] = 0
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 5) "unroll" {
      attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28;
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.y_1*7)) + floordiv(threadIdx.x_1, 4)) < 256) {
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*224) + (threadIdx.y_1*28)) + threadIdx.x_1) < 1024) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*8) + threadIdx.y_1) < 37) {
            placeholder.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*896) + (threadIdx.y_1*112)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_10[ramp(((((blockIdx.y*65536) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.y_1*7)) + floordiv(threadIdx.x_1, 4)), 16)*4096)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.y_1*7)) + floordiv(threadIdx.x_1, 4)), 16)*16)) + (floormod(threadIdx.x_1, 4)*4)), 1, 4)]
          }
        }
      }
    }
    for (ic_chunk.outer.outer: int32, 0, 15) {
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 4) "unroll" {
        attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28;
        pad_data.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*896) + (threadIdx.y_2*112)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp(((((((blockIdx.z*401408) + (floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*8) + threadIdx.y_2), 16)*200704)) + (ic_chunk.outer.outer*12544)) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*8) + threadIdx.y_2), 16)*784)) + (blockIdx.x*112)) + (threadIdx.x_2*4)), 1, 4)]
      }
      attr [placeholder.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 5) "unroll" {
        attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
        attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.y_1*7)) + floordiv(threadIdx.x_1, 4)) < 256) {
          if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*224) + (threadIdx.y_1*28)) + threadIdx.x_1) < 1024) {
            if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*8) + threadIdx.y_1) < 37) {
              placeholder.shared[ramp(((((floormod((ic_chunk.outer.outer + 1), 2)*4096) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*896)) + (threadIdx.y_1*112)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_10[ramp(((((((blockIdx.y*65536) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.y_1*7)) + floordiv(threadIdx.x_1, 4)), 16)*4096)) + (ic_chunk.outer.outer*256)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.y_1*7)) + floordiv(threadIdx.x_1, 4)), 16)*16)) + (floormod(threadIdx.x_1, 4)*4)) + 256), 1, 4)]
            }
          }
        }
      }
      for (ic_chunk.inner: int32, 0, 16) "unroll" {
        for (n: int32, 0, 2) "unroll" {
          for (oc_block: int32, 0, 4) "unroll" {
            compute[((n*4) + oc_block)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((n*1792) + (ic_chunk.inner*112)) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*4096) + (threadIdx.y*256)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[((n*4) + oc_block)], dtype=int32)
            compute[(((n*4) + oc_block) + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((n*1792) + (ic_chunk.inner*112)) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*4096) + (threadIdx.y*256)) + (ic_chunk.inner*16)) + (oc_block*4)) + 2048), 1, 4)], (int32*)compute[(((n*4) + oc_block) + 8)], dtype=int32)
          }
        }
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1: int32, 0, 4) "unroll" {
      attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
      attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28;
      pad_data.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*896) + (threadIdx.y_2*112)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp(((((((blockIdx.z*401408) + (floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*8) + threadIdx.y_2), 16)*200704)) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*8) + threadIdx.y_2), 16)*784)) + (blockIdx.x*112)) + (threadIdx.x_2*4)) + 188160), 1, 4)]
    }
    for (ic_chunk.inner_1: int32, 0, 16) "unroll" {
      for (n_1: int32, 0, 2) "unroll" {
        for (oc_block_1: int32, 0, 4) "unroll" {
          compute[((n_1*4) + oc_block_1)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((n_1*1792) + (ic_chunk.inner_1*112)) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*256) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 4096), 1, 4)], (int32*)compute[((n_1*4) + oc_block_1)], dtype=int32)
          compute[(((n_1*4) + oc_block_1) + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((n_1*1792) + (ic_chunk.inner_1*112)) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*256) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 6144), 1, 4)], (int32*)compute[(((n_1*4) + oc_block_1) + 8)], dtype=int32)
        }
      }
    }
    for (ax0.inner.inner.inner.inner: int32, 0, 2) "unroll" {
      for (ax4: int32, 0, 4) "unroll" {
        T_cast_2[(((((((blockIdx.z*100352) + (ax0.inner.inner.inner.inner*50176)) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[((ax0.inner.inner.inner.inner*4) + ax4)], 1421641144, 31, 17, dtype=int32) + (int32*)placeholder_11[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 2147473910, 31, 0, dtype=int32) + (int32*)placeholder_9[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 0), 1077860244, 31, -23, dtype=int32), 127), -128))
        T_cast_2[((((((((blockIdx.z*100352) + (ax0.inner.inner.inner.inner*50176)) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4) + 6272)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(((ax0.inner.inner.inner.inner*4) + ax4) + 8)], 1421641144, 31, 17, dtype=int32) + (int32*)placeholder_11[((((blockIdx.y*64) + (threadIdx.y*4)) + ax4) + 32)]), 2147473910, 31, 0, dtype=int32) + (int32*)placeholder_9[((((blockIdx.y*64) + (threadIdx.y*4)) + ax4) + 32)]), 0), 1077860244, 31, -23, dtype=int32), 127), -128))
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_fixed_point_multiply_clip_cast_5", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [32, 256, 14, 14, 4], []),
             placeholder: Buffer(placeholder_2: handle, int32, [32, 256, 14, 14, 4], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer: int32, 0, 25) {
    if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*65536) + (blockIdx.x*256)) + floordiv(threadIdx.x, 4)) < 1605632) {
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x) < 6422528) {
        T_cast_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = cast(int8, max(min(@tir.q_multiply_shift((int32*)placeholder_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)], 2089225123, 31, -24, dtype=int32), 127), -128))
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
primfn(placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, placeholder_8: handle, placeholder_9: handle, T_relu_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_fixed_point_multiply_add_cast_15119380522063600768__4", "tir.noalias": True}
  buffers = {placeholder_4: Buffer(placeholder_10: handle, int32, [32, 256, 14, 14, 4], []),
             placeholder_1: Buffer(placeholder_11: handle, int8, [256, 64, 1, 1, 4, 4], []),
             placeholder: Buffer(placeholder_12: handle, int8, [32, 64, 14, 14, 4], []),
             placeholder_3: Buffer(placeholder_13: handle, int32, [1, 256, 1, 1, 4], []),
             placeholder_2: Buffer(placeholder_14: handle, int32, [1, 256, 1, 1, 4], []),
             T_relu: Buffer(T_relu_2: handle, int32, [32, 256, 14, 14, 4], [])}
  buffer_map = {placeholder_5: placeholder, placeholder_6: placeholder_1, placeholder_7: placeholder_2, placeholder_8: placeholder_3, T_relu_1: T_relu, placeholder_9: placeholder_4} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 16;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [16]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [1792]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [2048]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 16;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 7;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28 {
    for (oc_block.init: int32, 0, 4) "unroll" {
      compute[oc_block.init] = 0
      compute[(oc_block.init + 8)] = 0
      compute[(oc_block.init + 4)] = 0
      compute[(oc_block.init + 12)] = 0
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 4) "unroll" {
      attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28;
      pad_data.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*896) + (threadIdx.y_1*112)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_12[ramp((((((blockIdx.z*100352) + (floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*8) + threadIdx.y_1), 16)*50176)) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*8) + threadIdx.y_1), 16)*784)) + (blockIdx.x*112)) + (threadIdx.x_1*4)), 1, 4)]
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 5) "unroll" {
      attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
      attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28;
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.y_2*7)) + floordiv(threadIdx.x_2, 4)) < 256) {
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*224) + (threadIdx.y_2*28)) + threadIdx.x_2) < 1024) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*8) + threadIdx.y_2) < 37) {
            placeholder.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*896) + (threadIdx.y_2*112)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_11[ramp(((((blockIdx.y*16384) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.y_2*7)) + floordiv(threadIdx.x_2, 4)), 16)*1024)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.y_2*7)) + floordiv(threadIdx.x_2, 4)), 16)*16)) + (floormod(threadIdx.x_2, 4)*4)), 1, 4)]
          }
        }
      }
    }
    for (ic_chunk.outer.outer: int32, 0, 3) {
      attr [pad_data.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1: int32, 0, 4) "unroll" {
        attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
        attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28;
        pad_data.shared[ramp(((((floormod((ic_chunk.outer.outer + 1), 2)*3584) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*896)) + (threadIdx.y_1*112)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_12[ramp((((((((blockIdx.z*100352) + (floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*8) + threadIdx.y_1), 16)*50176)) + (ic_chunk.outer.outer*12544)) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*8) + threadIdx.y_1), 16)*784)) + (blockIdx.x*112)) + (threadIdx.x_1*4)) + 12544), 1, 4)]
      }
      attr [placeholder.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 5) "unroll" {
        attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
        attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.y_2*7)) + floordiv(threadIdx.x_2, 4)) < 256) {
          if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*224) + (threadIdx.y_2*28)) + threadIdx.x_2) < 1024) {
            if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*8) + threadIdx.y_2) < 37) {
              placeholder.shared[ramp(((((floormod((ic_chunk.outer.outer + 1), 2)*4096) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*896)) + (threadIdx.y_2*112)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_11[ramp(((((((blockIdx.y*16384) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.y_2*7)) + floordiv(threadIdx.x_2, 4)), 16)*1024)) + (ic_chunk.outer.outer*256)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.y_2*7)) + floordiv(threadIdx.x_2, 4)), 16)*16)) + (floormod(threadIdx.x_2, 4)*4)) + 256), 1, 4)]
            }
          }
        }
      }
      for (ic_chunk.inner: int32, 0, 16) "unroll" {
        for (oc_block: int32, 0, 4) "unroll" {
          compute[oc_block] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((floormod(ic_chunk.outer.outer, 2)*3584) + (ic_chunk.inner*112)) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*4096) + (threadIdx.y*256)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[oc_block], dtype=int32)
          compute[(oc_block + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*3584) + (ic_chunk.inner*112)) + (threadIdx.x*4)) + 1792), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*4096) + (threadIdx.y*256)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 8)], dtype=int32)
          compute[(oc_block + 4)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((floormod(ic_chunk.outer.outer, 2)*3584) + (ic_chunk.inner*112)) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*4096) + (threadIdx.y*256)) + (ic_chunk.inner*16)) + (oc_block*4)) + 2048), 1, 4)], (int32*)compute[(oc_block + 4)], dtype=int32)
          compute[(oc_block + 12)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*3584) + (ic_chunk.inner*112)) + (threadIdx.x*4)) + 1792), 1, 4)], (int8x4*)placeholder.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*4096) + (threadIdx.y*256)) + (ic_chunk.inner*16)) + (oc_block*4)) + 2048), 1, 4)], (int32*)compute[(oc_block + 12)], dtype=int32)
        }
      }
    }
    for (ic_chunk.inner_1: int32, 0, 16) "unroll" {
      for (oc_block_1: int32, 0, 4) "unroll" {
        compute[oc_block_1] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner_1*112) + (threadIdx.x*4)) + 3584), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*256) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 4096), 1, 4)], (int32*)compute[oc_block_1], dtype=int32)
        compute[(oc_block_1 + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner_1*112) + (threadIdx.x*4)) + 5376), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*256) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 4096), 1, 4)], (int32*)compute[(oc_block_1 + 8)], dtype=int32)
        compute[(oc_block_1 + 4)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner_1*112) + (threadIdx.x*4)) + 3584), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*256) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 6144), 1, 4)], (int32*)compute[(oc_block_1 + 4)], dtype=int32)
        compute[(oc_block_1 + 12)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner_1*112) + (threadIdx.x*4)) + 5376), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*256) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 6144), 1, 4)], (int32*)compute[(oc_block_1 + 12)], dtype=int32)
      }
    }
    for (ax4: int32, 0, 4) "unroll" {
      T_relu_2[((((((blockIdx.z*401408) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[ax4], 1376935399, 31, 18, dtype=int32) + (int32*)placeholder_14[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 2147411797, 31, 0, dtype=int32) + (int32*)placeholder_13[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 1787090516, 31, 0, dtype=int32) + @tir.q_multiply_shift((int32*)placeholder_10[((((((blockIdx.z*401408) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4)], 1169394485, 31, 1, dtype=int32)), 0)
      T_relu_2[(((((((blockIdx.z*401408) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4) + 200704)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 8)], 1376935399, 31, 18, dtype=int32) + (int32*)placeholder_14[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 2147411797, 31, 0, dtype=int32) + (int32*)placeholder_13[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 1787090516, 31, 0, dtype=int32) + @tir.q_multiply_shift((int32*)placeholder_10[(((((((blockIdx.z*401408) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4) + 200704)], 1169394485, 31, 1, dtype=int32)), 0)
      T_relu_2[(((((((blockIdx.z*401408) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4) + 6272)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 4)], 1376935399, 31, 18, dtype=int32) + (int32*)placeholder_14[((((blockIdx.y*64) + (threadIdx.y*4)) + ax4) + 32)]), 2147411797, 31, 0, dtype=int32) + (int32*)placeholder_13[((((blockIdx.y*64) + (threadIdx.y*4)) + ax4) + 32)]), 1787090516, 31, 0, dtype=int32) + @tir.q_multiply_shift((int32*)placeholder_10[(((((((blockIdx.z*401408) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4) + 6272)], 1169394485, 31, 1, dtype=int32)), 0)
      T_relu_2[(((((((blockIdx.z*401408) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4) + 206976)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 12)], 1376935399, 31, 18, dtype=int32) + (int32*)placeholder_14[((((blockIdx.y*64) + (threadIdx.y*4)) + ax4) + 32)]), 2147411797, 31, 0, dtype=int32) + (int32*)placeholder_13[((((blockIdx.y*64) + (threadIdx.y*4)) + ax4) + 32)]), 1787090516, 31, 0, dtype=int32) + @tir.q_multiply_shift((int32*)placeholder_10[(((((((blockIdx.z*401408) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4) + 206976)], 1169394485, 31, 1, dtype=int32)), 0)
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_nn_relu_cast_fixed_point_mult_18399029763786111876__6", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [32, 64, 14, 14, 4], []),
             placeholder_2: Buffer(placeholder_6: handle, int32, [1, 64, 1, 1, 4], []),
             placeholder: Buffer(placeholder_7: handle, int8, [32, 64, 14, 14, 4], []),
             placeholder_1: Buffer(placeholder_8: handle, int8, [64, 64, 3, 3, 4, 4], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 16;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [28]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [256]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [576]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 4;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 7;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4 {
    for (oh.init: int32, 0, 7) "unroll" {
      for (oc_block.init: int32, 0, 4) "unroll" {
        compute[((oh.init*4) + oc_block.init)] = 0
      }
    }
    attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
    attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
    attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
    pad_data.shared[ramp((((threadIdx.z_1*256) + (threadIdx.y_1*16)) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((1 <= threadIdx.y_1) && (threadIdx.y_1 < 15)) && (1 <= ((blockIdx.x*2) + threadIdx.x_1))) && (((blockIdx.x*2) + threadIdx.x_1) < 15)), (int8x4*)placeholder_7[ramp(((((((blockIdx.z*100352) + (threadIdx.z_1*50176)) + (threadIdx.y_1*56)) + (blockIdx.x*8)) + (threadIdx.x_1*4)) - 60), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
    for (ic_chunk.outer.outer: int32, 0, 63) {
      attr [pad_data.shared] "double_buffer_write" = 1;
      attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
      attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
      attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
      pad_data.shared[ramp(((((floormod((ic_chunk.outer.outer + 1), 2)*512) + (threadIdx.z_1*256)) + (threadIdx.y_1*16)) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((1 <= threadIdx.y_1) && (threadIdx.y_1 < 15)) && (1 <= ((blockIdx.x*2) + threadIdx.x_1))) && (((blockIdx.x*2) + threadIdx.x_1) < 15)), (int8x4*)placeholder_7[ramp((((((((blockIdx.z*100352) + (threadIdx.z_1*50176)) + (ic_chunk.outer.outer*784)) + (threadIdx.y_1*56)) + (blockIdx.x*8)) + (threadIdx.x_1*4)) + 724), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 5) "unroll" {
        attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
        attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.z_2*16)) + threadIdx.y_2) < 144) {
          if (((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*128) + (threadIdx.z_2*64)) + (threadIdx.y_2*4)) + threadIdx.x_2) < 576) {
            if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*2) + threadIdx.z_2) < 9) {
              placeholder.shared[ramp(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*512) + (threadIdx.z_2*256)) + (threadIdx.y_2*16)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp((((((blockIdx.y*147456) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.z_2*16)) + threadIdx.y_2), 9)*9216)) + (ic_chunk.outer.outer*144)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.z_2*16)) + threadIdx.y_2), 9)*16)) + (threadIdx.x_2*4)), 1, 4)]
            }
          }
        }
      }
      for (kw.inner: int32, 0, 3) "unroll" {
        for (kh.inner: int32, 0, 3) "unroll" {
          for (oh: int32, 0, 7) "unroll" {
            for (oc_block: int32, 0, 4) "unroll" {
              compute[((oh*4) + oc_block)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((((floormod(ic_chunk.outer.outer, 2)*512) + (threadIdx.z*256)) + (floordiv(threadIdx.x, 2)*112)) + (oh*16)) + (kh.inner*16)) + (kw.inner*4)) + (floormod(threadIdx.x, 2)*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*144) + (kh.inner*48)) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[((oh*4) + oc_block)], dtype=int32)
            }
          }
        }
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 5) "unroll" {
      attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
      attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
      attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.z_2*16)) + threadIdx.y_2) < 144) {
        if (((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_2*64)) + (threadIdx.y_2*4)) + threadIdx.x_2) < 576) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*2) + threadIdx.z_2) < 9) {
            placeholder.shared[ramp(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*512) + (threadIdx.z_2*256)) + (threadIdx.y_2*16)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp((((((blockIdx.y*147456) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.z_2*16)) + threadIdx.y_2), 9)*9216)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.z_2*16)) + threadIdx.y_2), 9)*16)) + (threadIdx.x_2*4)) + 9072), 1, 4)]
          }
        }
      }
    }
    for (kw.inner_1: int32, 0, 3) "unroll" {
      for (kh.inner_1: int32, 0, 3) "unroll" {
        for (oh_1: int32, 0, 7) "unroll" {
          for (oc_block_1: int32, 0, 4) "unroll" {
            compute[((oh_1*4) + oc_block_1)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((((threadIdx.z*256) + (floordiv(threadIdx.x, 2)*112)) + (oh_1*16)) + (kh.inner_1*16)) + (kw.inner_1*4)) + (floormod(threadIdx.x, 2)*4)) + 512), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*144) + (kh.inner_1*48)) + (kw.inner_1*16)) + (oc_block_1*4)), 1, 4)], (int32*)compute[((oh_1*4) + oc_block_1)], dtype=int32)
          }
        }
      }
    }
    for (ax2.inner.inner.inner: int32, 0, 7) "unroll" {
      for (ax4: int32, 0, 4) "unroll" {
        T_cast_2[(((((((((blockIdx.z*100352) + (threadIdx.z*50176)) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (floordiv(threadIdx.x, 2)*392)) + (ax2.inner.inner.inner*56)) + (blockIdx.x*8)) + (floormod(threadIdx.x, 2)*4)) + ax4)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((int32*)compute[((ax2.inner.inner.inner*4) + ax4)], 1571730312, 31, 16, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 0), 2130801582, 31, -24, dtype=int32), 127), -128))
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_fixed_point_multiply_add_cast_16086763325481941859__5", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [32, 64, 14, 14, 4], []),
             placeholder_2: Buffer(placeholder_8: handle, int32, [1, 64, 1, 1, 4], []),
             placeholder: Buffer(placeholder_9: handle, int8, [32, 256, 14, 14, 4], []),
             placeholder_3: Buffer(placeholder_10: handle, int8, [64, 256, 1, 1, 4, 4], []),
             placeholder_1: Buffer(placeholder_11: handle, int32, [1, 64, 1, 1, 4], [])}
  buffer_map = {placeholder_4: placeholder, placeholder_7: placeholder_1, placeholder_6: placeholder_2, T_cast_1: T_cast, placeholder_5: placeholder_3} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 16;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [16]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [2048]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [896]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 4;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 7;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28 {
    for (n.init: int32, 0, 2) "unroll" {
      for (oc_block.init: int32, 0, 4) "unroll" {
        compute[((n.init*4) + oc_block.init)] = 0
        compute[(((n.init*4) + oc_block.init) + 8)] = 0
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 5) "unroll" {
      attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28;
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.y_1*7)) + floordiv(threadIdx.x_1, 4)) < 256) {
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*224) + (threadIdx.y_1*28)) + threadIdx.x_1) < 1024) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*8) + threadIdx.y_1) < 37) {
            placeholder.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*896) + (threadIdx.y_1*112)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_10[ramp(((((blockIdx.y*65536) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.y_1*7)) + floordiv(threadIdx.x_1, 4)), 16)*4096)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.y_1*7)) + floordiv(threadIdx.x_1, 4)), 16)*16)) + (floormod(threadIdx.x_1, 4)*4)), 1, 4)]
          }
        }
      }
    }
    for (ic_chunk.outer.outer: int32, 0, 15) {
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 4) "unroll" {
        attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28;
        pad_data.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*896) + (threadIdx.y_2*112)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_9[ramp(((((((blockIdx.z*401408) + (floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*8) + threadIdx.y_2), 16)*200704)) + (ic_chunk.outer.outer*12544)) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*8) + threadIdx.y_2), 16)*784)) + (blockIdx.x*112)) + (threadIdx.x_2*4)), 1, 4)]
      }
      attr [placeholder.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 5) "unroll" {
        attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
        attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.y_1*7)) + floordiv(threadIdx.x_1, 4)) < 256) {
          if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*224) + (threadIdx.y_1*28)) + threadIdx.x_1) < 1024) {
            if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*8) + threadIdx.y_1) < 37) {
              placeholder.shared[ramp(((((floormod((ic_chunk.outer.outer + 1), 2)*4096) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*896)) + (threadIdx.y_1*112)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_10[ramp(((((((blockIdx.y*65536) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.y_1*7)) + floordiv(threadIdx.x_1, 4)), 16)*4096)) + (ic_chunk.outer.outer*256)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.y_1*7)) + floordiv(threadIdx.x_1, 4)), 16)*16)) + (floormod(threadIdx.x_1, 4)*4)) + 256), 1, 4)]
            }
          }
        }
      }
      for (ic_chunk.inner: int32, 0, 16) "unroll" {
        for (n: int32, 0, 2) "unroll" {
          for (oc_block: int32, 0, 4) "unroll" {
            compute[((n*4) + oc_block)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((n*1792) + (ic_chunk.inner*112)) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*4096) + (threadIdx.y*256)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[((n*4) + oc_block)], dtype=int32)
            compute[(((n*4) + oc_block) + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((n*1792) + (ic_chunk.inner*112)) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*4096) + (threadIdx.y*256)) + (ic_chunk.inner*16)) + (oc_block*4)) + 2048), 1, 4)], (int32*)compute[(((n*4) + oc_block) + 8)], dtype=int32)
          }
        }
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1: int32, 0, 4) "unroll" {
      attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
      attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28;
      pad_data.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*896) + (threadIdx.y_2*112)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_9[ramp(((((((blockIdx.z*401408) + (floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*8) + threadIdx.y_2), 16)*200704)) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*8) + threadIdx.y_2), 16)*784)) + (blockIdx.x*112)) + (threadIdx.x_2*4)) + 188160), 1, 4)]
    }
    for (ic_chunk.inner_1: int32, 0, 16) "unroll" {
      for (n_1: int32, 0, 2) "unroll" {
        for (oc_block_1: int32, 0, 4) "unroll" {
          compute[((n_1*4) + oc_block_1)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((n_1*1792) + (ic_chunk.inner_1*112)) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*256) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 4096), 1, 4)], (int32*)compute[((n_1*4) + oc_block_1)], dtype=int32)
          compute[(((n_1*4) + oc_block_1) + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((n_1*1792) + (ic_chunk.inner_1*112)) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*256) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 6144), 1, 4)], (int32*)compute[(((n_1*4) + oc_block_1) + 8)], dtype=int32)
        }
      }
    }
    for (ax0.inner.inner.inner.inner: int32, 0, 2) "unroll" {
      for (ax4: int32, 0, 4) "unroll" {
        T_cast_2[(((((((blockIdx.z*100352) + (ax0.inner.inner.inner.inner*50176)) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[((ax0.inner.inner.inner.inner*4) + ax4)], 1449996968, 31, 17, dtype=int32) + (int32*)placeholder_8[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 2147473765, 31, 0, dtype=int32) + (int32*)placeholder_11[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 0), 1169894908, 31, -23, dtype=int32), 127), -128))
        T_cast_2[((((((((blockIdx.z*100352) + (ax0.inner.inner.inner.inner*50176)) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4) + 6272)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(((ax0.inner.inner.inner.inner*4) + ax4) + 8)], 1449996968, 31, 17, dtype=int32) + (int32*)placeholder_8[((((blockIdx.y*64) + (threadIdx.y*4)) + ax4) + 32)]), 2147473765, 31, 0, dtype=int32) + (int32*)placeholder_11[((((blockIdx.y*64) + (threadIdx.y*4)) + ax4) + 32)]), 0), 1169894908, 31, -23, dtype=int32), 127), -128))
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_fixed_point_multiply_clip_cast_6", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [32, 256, 14, 14, 4], []),
             placeholder: Buffer(placeholder_2: handle, int32, [32, 256, 14, 14, 4], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer: int32, 0, 25) {
    if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*65536) + (blockIdx.x*256)) + floordiv(threadIdx.x, 4)) < 1605632) {
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x) < 6422528) {
        T_cast_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = cast(int8, max(min(@tir.q_multiply_shift((int32*)placeholder_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)], 1169394485, 31, -23, dtype=int32), 127), -128))
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
primfn(placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, placeholder_8: handle, placeholder_9: handle, T_relu_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_fixed_point_multiply_add_cast_15119380522063600768__5", "tir.noalias": True}
  buffers = {T_relu: Buffer(T_relu_2: handle, int32, [32, 256, 14, 14, 4], []),
             placeholder_4: Buffer(placeholder_10: handle, int8, [256, 64, 1, 1, 4, 4], []),
             placeholder_1: Buffer(placeholder_11: handle, int32, [1, 256, 1, 1, 4], []),
             placeholder: Buffer(placeholder_12: handle, int8, [32, 64, 14, 14, 4], []),
             placeholder_2: Buffer(placeholder_13: handle, int32, [1, 256, 1, 1, 4], []),
             placeholder_3: Buffer(placeholder_14: handle, int32, [32, 256, 14, 14, 4], [])}
  buffer_map = {placeholder_5: placeholder, placeholder_8: placeholder_1, placeholder_7: placeholder_2, placeholder_9: placeholder_3, placeholder_6: placeholder_4, T_relu_1: T_relu} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 16;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [16]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [1792]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [2048]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 16;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 7;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28 {
    for (oc_block.init: int32, 0, 4) "unroll" {
      compute[oc_block.init] = 0
      compute[(oc_block.init + 8)] = 0
      compute[(oc_block.init + 4)] = 0
      compute[(oc_block.init + 12)] = 0
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 4) "unroll" {
      attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28;
      pad_data.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*896) + (threadIdx.y_1*112)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_12[ramp((((((blockIdx.z*100352) + (floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*8) + threadIdx.y_1), 16)*50176)) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*8) + threadIdx.y_1), 16)*784)) + (blockIdx.x*112)) + (threadIdx.x_1*4)), 1, 4)]
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 5) "unroll" {
      attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
      attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28;
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.y_2*7)) + floordiv(threadIdx.x_2, 4)) < 256) {
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*224) + (threadIdx.y_2*28)) + threadIdx.x_2) < 1024) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*8) + threadIdx.y_2) < 37) {
            placeholder.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*896) + (threadIdx.y_2*112)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_10[ramp(((((blockIdx.y*16384) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.y_2*7)) + floordiv(threadIdx.x_2, 4)), 16)*1024)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.y_2*7)) + floordiv(threadIdx.x_2, 4)), 16)*16)) + (floormod(threadIdx.x_2, 4)*4)), 1, 4)]
          }
        }
      }
    }
    for (ic_chunk.outer.outer: int32, 0, 3) {
      attr [pad_data.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1: int32, 0, 4) "unroll" {
        attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
        attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28;
        pad_data.shared[ramp(((((floormod((ic_chunk.outer.outer + 1), 2)*3584) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*896)) + (threadIdx.y_1*112)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_12[ramp((((((((blockIdx.z*100352) + (floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*8) + threadIdx.y_1), 16)*50176)) + (ic_chunk.outer.outer*12544)) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*8) + threadIdx.y_1), 16)*784)) + (blockIdx.x*112)) + (threadIdx.x_1*4)) + 12544), 1, 4)]
      }
      attr [placeholder.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 5) "unroll" {
        attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
        attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.y_2*7)) + floordiv(threadIdx.x_2, 4)) < 256) {
          if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*224) + (threadIdx.y_2*28)) + threadIdx.x_2) < 1024) {
            if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*8) + threadIdx.y_2) < 37) {
              placeholder.shared[ramp(((((floormod((ic_chunk.outer.outer + 1), 2)*4096) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*896)) + (threadIdx.y_2*112)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_10[ramp(((((((blockIdx.y*16384) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.y_2*7)) + floordiv(threadIdx.x_2, 4)), 16)*1024)) + (ic_chunk.outer.outer*256)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.y_2*7)) + floordiv(threadIdx.x_2, 4)), 16)*16)) + (floormod(threadIdx.x_2, 4)*4)) + 256), 1, 4)]
            }
          }
        }
      }
      for (ic_chunk.inner: int32, 0, 16) "unroll" {
        for (oc_block: int32, 0, 4) "unroll" {
          compute[oc_block] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((floormod(ic_chunk.outer.outer, 2)*3584) + (ic_chunk.inner*112)) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*4096) + (threadIdx.y*256)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[oc_block], dtype=int32)
          compute[(oc_block + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*3584) + (ic_chunk.inner*112)) + (threadIdx.x*4)) + 1792), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*4096) + (threadIdx.y*256)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 8)], dtype=int32)
          compute[(oc_block + 4)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((floormod(ic_chunk.outer.outer, 2)*3584) + (ic_chunk.inner*112)) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*4096) + (threadIdx.y*256)) + (ic_chunk.inner*16)) + (oc_block*4)) + 2048), 1, 4)], (int32*)compute[(oc_block + 4)], dtype=int32)
          compute[(oc_block + 12)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*3584) + (ic_chunk.inner*112)) + (threadIdx.x*4)) + 1792), 1, 4)], (int8x4*)placeholder.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*4096) + (threadIdx.y*256)) + (ic_chunk.inner*16)) + (oc_block*4)) + 2048), 1, 4)], (int32*)compute[(oc_block + 12)], dtype=int32)
        }
      }
    }
    for (ic_chunk.inner_1: int32, 0, 16) "unroll" {
      for (oc_block_1: int32, 0, 4) "unroll" {
        compute[oc_block_1] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner_1*112) + (threadIdx.x*4)) + 3584), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*256) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 4096), 1, 4)], (int32*)compute[oc_block_1], dtype=int32)
        compute[(oc_block_1 + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner_1*112) + (threadIdx.x*4)) + 5376), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*256) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 4096), 1, 4)], (int32*)compute[(oc_block_1 + 8)], dtype=int32)
        compute[(oc_block_1 + 4)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner_1*112) + (threadIdx.x*4)) + 3584), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*256) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 6144), 1, 4)], (int32*)compute[(oc_block_1 + 4)], dtype=int32)
        compute[(oc_block_1 + 12)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner_1*112) + (threadIdx.x*4)) + 5376), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*256) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 6144), 1, 4)], (int32*)compute[(oc_block_1 + 12)], dtype=int32)
      }
    }
    for (ax4: int32, 0, 4) "unroll" {
      T_relu_2[((((((blockIdx.z*401408) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[ax4], 1222145805, 31, 18, dtype=int32) + (int32*)placeholder_13[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 1073788074, 31, 1, dtype=int32) + (int32*)placeholder_11[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 1113814462, 31, 0, dtype=int32) + @tir.q_multiply_shift((int32*)placeholder_14[((((((blockIdx.z*401408) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4)], 1837567025, 31, 0, dtype=int32)), 0)
      T_relu_2[(((((((blockIdx.z*401408) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4) + 200704)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 8)], 1222145805, 31, 18, dtype=int32) + (int32*)placeholder_13[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 1073788074, 31, 1, dtype=int32) + (int32*)placeholder_11[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 1113814462, 31, 0, dtype=int32) + @tir.q_multiply_shift((int32*)placeholder_14[(((((((blockIdx.z*401408) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4) + 200704)], 1837567025, 31, 0, dtype=int32)), 0)
      T_relu_2[(((((((blockIdx.z*401408) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4) + 6272)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 4)], 1222145805, 31, 18, dtype=int32) + (int32*)placeholder_13[((((blockIdx.y*64) + (threadIdx.y*4)) + ax4) + 32)]), 1073788074, 31, 1, dtype=int32) + (int32*)placeholder_11[((((blockIdx.y*64) + (threadIdx.y*4)) + ax4) + 32)]), 1113814462, 31, 0, dtype=int32) + @tir.q_multiply_shift((int32*)placeholder_14[(((((((blockIdx.z*401408) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4) + 6272)], 1837567025, 31, 0, dtype=int32)), 0)
      T_relu_2[(((((((blockIdx.z*401408) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4) + 206976)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 12)], 1222145805, 31, 18, dtype=int32) + (int32*)placeholder_13[((((blockIdx.y*64) + (threadIdx.y*4)) + ax4) + 32)]), 1073788074, 31, 1, dtype=int32) + (int32*)placeholder_11[((((blockIdx.y*64) + (threadIdx.y*4)) + ax4) + 32)]), 1113814462, 31, 0, dtype=int32) + @tir.q_multiply_shift((int32*)placeholder_14[(((((((blockIdx.z*401408) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4) + 206976)], 1837567025, 31, 0, dtype=int32)), 0)
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_nn_relu_cast_fixed_point_mult_18399029763786111876__7", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [32, 64, 14, 14, 4], []),
             placeholder_2: Buffer(placeholder_6: handle, int32, [1, 64, 1, 1, 4], []),
             placeholder: Buffer(placeholder_7: handle, int8, [32, 64, 14, 14, 4], []),
             placeholder_1: Buffer(placeholder_8: handle, int8, [64, 64, 3, 3, 4, 4], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 16;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [28]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [256]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [576]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 4;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 7;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4 {
    for (oh.init: int32, 0, 7) "unroll" {
      for (oc_block.init: int32, 0, 4) "unroll" {
        compute[((oh.init*4) + oc_block.init)] = 0
      }
    }
    attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
    attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
    attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
    pad_data.shared[ramp((((threadIdx.z_1*256) + (threadIdx.y_1*16)) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((1 <= threadIdx.y_1) && (threadIdx.y_1 < 15)) && (1 <= ((blockIdx.x*2) + threadIdx.x_1))) && (((blockIdx.x*2) + threadIdx.x_1) < 15)), (int8x4*)placeholder_7[ramp(((((((blockIdx.z*100352) + (threadIdx.z_1*50176)) + (threadIdx.y_1*56)) + (blockIdx.x*8)) + (threadIdx.x_1*4)) - 60), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
    for (ic_chunk.outer.outer: int32, 0, 63) {
      attr [pad_data.shared] "double_buffer_write" = 1;
      attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
      attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
      attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
      pad_data.shared[ramp(((((floormod((ic_chunk.outer.outer + 1), 2)*512) + (threadIdx.z_1*256)) + (threadIdx.y_1*16)) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((1 <= threadIdx.y_1) && (threadIdx.y_1 < 15)) && (1 <= ((blockIdx.x*2) + threadIdx.x_1))) && (((blockIdx.x*2) + threadIdx.x_1) < 15)), (int8x4*)placeholder_7[ramp((((((((blockIdx.z*100352) + (threadIdx.z_1*50176)) + (ic_chunk.outer.outer*784)) + (threadIdx.y_1*56)) + (blockIdx.x*8)) + (threadIdx.x_1*4)) + 724), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 5) "unroll" {
        attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
        attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.z_2*16)) + threadIdx.y_2) < 144) {
          if (((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*128) + (threadIdx.z_2*64)) + (threadIdx.y_2*4)) + threadIdx.x_2) < 576) {
            if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*2) + threadIdx.z_2) < 9) {
              placeholder.shared[ramp(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*512) + (threadIdx.z_2*256)) + (threadIdx.y_2*16)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp((((((blockIdx.y*147456) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.z_2*16)) + threadIdx.y_2), 9)*9216)) + (ic_chunk.outer.outer*144)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.z_2*16)) + threadIdx.y_2), 9)*16)) + (threadIdx.x_2*4)), 1, 4)]
            }
          }
        }
      }
      for (kw.inner: int32, 0, 3) "unroll" {
        for (kh.inner: int32, 0, 3) "unroll" {
          for (oh: int32, 0, 7) "unroll" {
            for (oc_block: int32, 0, 4) "unroll" {
              compute[((oh*4) + oc_block)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((((floormod(ic_chunk.outer.outer, 2)*512) + (threadIdx.z*256)) + (floordiv(threadIdx.x, 2)*112)) + (oh*16)) + (kh.inner*16)) + (kw.inner*4)) + (floormod(threadIdx.x, 2)*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*144) + (kh.inner*48)) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[((oh*4) + oc_block)], dtype=int32)
            }
          }
        }
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 5) "unroll" {
      attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
      attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
      attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.z_2*16)) + threadIdx.y_2) < 144) {
        if (((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_2*64)) + (threadIdx.y_2*4)) + threadIdx.x_2) < 576) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*2) + threadIdx.z_2) < 9) {
            placeholder.shared[ramp(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*512) + (threadIdx.z_2*256)) + (threadIdx.y_2*16)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp((((((blockIdx.y*147456) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.z_2*16)) + threadIdx.y_2), 9)*9216)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.z_2*16)) + threadIdx.y_2), 9)*16)) + (threadIdx.x_2*4)) + 9072), 1, 4)]
          }
        }
      }
    }
    for (kw.inner_1: int32, 0, 3) "unroll" {
      for (kh.inner_1: int32, 0, 3) "unroll" {
        for (oh_1: int32, 0, 7) "unroll" {
          for (oc_block_1: int32, 0, 4) "unroll" {
            compute[((oh_1*4) + oc_block_1)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((((threadIdx.z*256) + (floordiv(threadIdx.x, 2)*112)) + (oh_1*16)) + (kh.inner_1*16)) + (kw.inner_1*4)) + (floormod(threadIdx.x, 2)*4)) + 512), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*144) + (kh.inner_1*48)) + (kw.inner_1*16)) + (oc_block_1*4)), 1, 4)], (int32*)compute[((oh_1*4) + oc_block_1)], dtype=int32)
          }
        }
      }
    }
    for (ax2.inner.inner.inner: int32, 0, 7) "unroll" {
      for (ax4: int32, 0, 4) "unroll" {
        T_cast_2[(((((((((blockIdx.z*100352) + (threadIdx.z*50176)) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (floordiv(threadIdx.x, 2)*392)) + (ax2.inner.inner.inner*56)) + (blockIdx.x*8)) + (floormod(threadIdx.x, 2)*4)) + ax4)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((int32*)compute[((ax2.inner.inner.inner*4) + ax4)], 1327850369, 31, 16, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 0), 1199626064, 31, -23, dtype=int32), 127), -128))
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_fixed_point_multiply_add_cast_16086763325481941859__6", "tir.noalias": True}
  buffers = {placeholder_3: Buffer(placeholder_8: handle, int32, [1, 64, 1, 1, 4], []),
             placeholder_1: Buffer(placeholder_9: handle, int32, [1, 64, 1, 1, 4], []),
             placeholder_2: Buffer(placeholder_10: handle, int8, [64, 256, 1, 1, 4, 4], []),
             placeholder: Buffer(placeholder_11: handle, int8, [32, 256, 14, 14, 4], []),
             T_cast: Buffer(T_cast_2: handle, int8, [32, 64, 14, 14, 4], [])}
  buffer_map = {placeholder_4: placeholder, T_cast_1: T_cast, placeholder_6: placeholder_1, placeholder_5: placeholder_2, placeholder_7: placeholder_3} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 16;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [16]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [2048]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [896]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 4;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 7;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28 {
    for (n.init: int32, 0, 2) "unroll" {
      for (oc_block.init: int32, 0, 4) "unroll" {
        compute[((n.init*4) + oc_block.init)] = 0
        compute[(((n.init*4) + oc_block.init) + 8)] = 0
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 5) "unroll" {
      attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28;
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.y_1*7)) + floordiv(threadIdx.x_1, 4)) < 256) {
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*224) + (threadIdx.y_1*28)) + threadIdx.x_1) < 1024) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*8) + threadIdx.y_1) < 37) {
            placeholder.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*896) + (threadIdx.y_1*112)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_10[ramp(((((blockIdx.y*65536) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.y_1*7)) + floordiv(threadIdx.x_1, 4)), 16)*4096)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.y_1*7)) + floordiv(threadIdx.x_1, 4)), 16)*16)) + (floormod(threadIdx.x_1, 4)*4)), 1, 4)]
          }
        }
      }
    }
    for (ic_chunk.outer.outer: int32, 0, 15) {
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 4) "unroll" {
        attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28;
        pad_data.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*896) + (threadIdx.y_2*112)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_11[ramp(((((((blockIdx.z*401408) + (floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*8) + threadIdx.y_2), 16)*200704)) + (ic_chunk.outer.outer*12544)) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*8) + threadIdx.y_2), 16)*784)) + (blockIdx.x*112)) + (threadIdx.x_2*4)), 1, 4)]
      }
      attr [placeholder.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 5) "unroll" {
        attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
        attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.y_1*7)) + floordiv(threadIdx.x_1, 4)) < 256) {
          if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*224) + (threadIdx.y_1*28)) + threadIdx.x_1) < 1024) {
            if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*8) + threadIdx.y_1) < 37) {
              placeholder.shared[ramp(((((floormod((ic_chunk.outer.outer + 1), 2)*4096) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*896)) + (threadIdx.y_1*112)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_10[ramp(((((((blockIdx.y*65536) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.y_1*7)) + floordiv(threadIdx.x_1, 4)), 16)*4096)) + (ic_chunk.outer.outer*256)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.y_1*7)) + floordiv(threadIdx.x_1, 4)), 16)*16)) + (floormod(threadIdx.x_1, 4)*4)) + 256), 1, 4)]
            }
          }
        }
      }
      for (ic_chunk.inner: int32, 0, 16) "unroll" {
        for (n: int32, 0, 2) "unroll" {
          for (oc_block: int32, 0, 4) "unroll" {
            compute[((n*4) + oc_block)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((n*1792) + (ic_chunk.inner*112)) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*4096) + (threadIdx.y*256)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[((n*4) + oc_block)], dtype=int32)
            compute[(((n*4) + oc_block) + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((n*1792) + (ic_chunk.inner*112)) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*4096) + (threadIdx.y*256)) + (ic_chunk.inner*16)) + (oc_block*4)) + 2048), 1, 4)], (int32*)compute[(((n*4) + oc_block) + 8)], dtype=int32)
          }
        }
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1: int32, 0, 4) "unroll" {
      attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
      attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28;
      pad_data.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*896) + (threadIdx.y_2*112)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_11[ramp(((((((blockIdx.z*401408) + (floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*8) + threadIdx.y_2), 16)*200704)) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*8) + threadIdx.y_2), 16)*784)) + (blockIdx.x*112)) + (threadIdx.x_2*4)) + 188160), 1, 4)]
    }
    for (ic_chunk.inner_1: int32, 0, 16) "unroll" {
      for (n_1: int32, 0, 2) "unroll" {
        for (oc_block_1: int32, 0, 4) "unroll" {
          compute[((n_1*4) + oc_block_1)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((n_1*1792) + (ic_chunk.inner_1*112)) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*256) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 4096), 1, 4)], (int32*)compute[((n_1*4) + oc_block_1)], dtype=int32)
          compute[(((n_1*4) + oc_block_1) + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((n_1*1792) + (ic_chunk.inner_1*112)) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*256) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 6144), 1, 4)], (int32*)compute[(((n_1*4) + oc_block_1) + 8)], dtype=int32)
        }
      }
    }
    for (ax0.inner.inner.inner.inner: int32, 0, 2) "unroll" {
      for (ax4: int32, 0, 4) "unroll" {
        T_cast_2[(((((((blockIdx.z*100352) + (ax0.inner.inner.inner.inner*50176)) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[((ax0.inner.inner.inner.inner*4) + ax4)], 1250824417, 31, 17, dtype=int32) + (int32*)placeholder_9[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 2147474446, 31, 0, dtype=int32) + (int32*)placeholder_8[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 0), 1228982520, 31, -23, dtype=int32), 127), -128))
        T_cast_2[((((((((blockIdx.z*100352) + (ax0.inner.inner.inner.inner*50176)) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4) + 6272)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(((ax0.inner.inner.inner.inner*4) + ax4) + 8)], 1250824417, 31, 17, dtype=int32) + (int32*)placeholder_9[((((blockIdx.y*64) + (threadIdx.y*4)) + ax4) + 32)]), 2147474446, 31, 0, dtype=int32) + (int32*)placeholder_8[((((blockIdx.y*64) + (threadIdx.y*4)) + ax4) + 32)]), 0), 1228982520, 31, -23, dtype=int32), 127), -128))
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_fixed_point_multiply_clip_cast_7", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [32, 256, 14, 14, 4], []),
             placeholder: Buffer(placeholder_2: handle, int32, [32, 256, 14, 14, 4], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer: int32, 0, 25) {
    if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*65536) + (blockIdx.x*256)) + floordiv(threadIdx.x, 4)) < 1605632) {
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x) < 6422528) {
        T_cast_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = cast(int8, max(min(@tir.q_multiply_shift((int32*)placeholder_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)], 1837567025, 31, -24, dtype=int32), 127), -128))
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
primfn(placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, placeholder_8: handle, placeholder_9: handle, T_relu_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_fixed_point_multiply_add_cast_12402219635377536017__1", "tir.noalias": True}
  buffers = {placeholder_4: Buffer(placeholder_10: handle, int32, [1, 256, 1, 1, 4], []),
             placeholder_1: Buffer(placeholder_11: handle, int32, [32, 256, 14, 14, 4], []),
             placeholder: Buffer(placeholder_12: handle, int8, [32, 64, 14, 14, 4], []),
             placeholder_3: Buffer(placeholder_13: handle, int32, [1, 256, 1, 1, 4], []),
             placeholder_2: Buffer(placeholder_14: handle, int8, [256, 64, 1, 1, 4, 4], []),
             T_relu: Buffer(T_relu_2: handle, int32, [32, 256, 14, 14, 4], [])}
  buffer_map = {placeholder_5: placeholder, placeholder_9: placeholder_1, placeholder_6: placeholder_2, T_relu_1: T_relu, placeholder_7: placeholder_3, placeholder_8: placeholder_4} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 16;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [16]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [1792]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [2048]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 16;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 7;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28 {
    for (oc_block.init: int32, 0, 4) "unroll" {
      compute[oc_block.init] = 0
      compute[(oc_block.init + 8)] = 0
      compute[(oc_block.init + 4)] = 0
      compute[(oc_block.init + 12)] = 0
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 4) "unroll" {
      attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28;
      pad_data.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*896) + (threadIdx.y_1*112)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_12[ramp((((((blockIdx.z*100352) + (floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*8) + threadIdx.y_1), 16)*50176)) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*8) + threadIdx.y_1), 16)*784)) + (blockIdx.x*112)) + (threadIdx.x_1*4)), 1, 4)]
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 5) "unroll" {
      attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
      attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28;
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.y_2*7)) + floordiv(threadIdx.x_2, 4)) < 256) {
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*224) + (threadIdx.y_2*28)) + threadIdx.x_2) < 1024) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*8) + threadIdx.y_2) < 37) {
            placeholder.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*896) + (threadIdx.y_2*112)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_14[ramp(((((blockIdx.y*16384) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.y_2*7)) + floordiv(threadIdx.x_2, 4)), 16)*1024)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.y_2*7)) + floordiv(threadIdx.x_2, 4)), 16)*16)) + (floormod(threadIdx.x_2, 4)*4)), 1, 4)]
          }
        }
      }
    }
    for (ic_chunk.outer.outer: int32, 0, 3) {
      attr [pad_data.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1: int32, 0, 4) "unroll" {
        attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
        attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28;
        pad_data.shared[ramp(((((floormod((ic_chunk.outer.outer + 1), 2)*3584) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*896)) + (threadIdx.y_1*112)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_12[ramp((((((((blockIdx.z*100352) + (floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*8) + threadIdx.y_1), 16)*50176)) + (ic_chunk.outer.outer*12544)) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*8) + threadIdx.y_1), 16)*784)) + (blockIdx.x*112)) + (threadIdx.x_1*4)) + 12544), 1, 4)]
      }
      attr [placeholder.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 5) "unroll" {
        attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
        attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.y_2*7)) + floordiv(threadIdx.x_2, 4)) < 256) {
          if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*224) + (threadIdx.y_2*28)) + threadIdx.x_2) < 1024) {
            if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*8) + threadIdx.y_2) < 37) {
              placeholder.shared[ramp(((((floormod((ic_chunk.outer.outer + 1), 2)*4096) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*896)) + (threadIdx.y_2*112)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_14[ramp(((((((blockIdx.y*16384) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.y_2*7)) + floordiv(threadIdx.x_2, 4)), 16)*1024)) + (ic_chunk.outer.outer*256)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.y_2*7)) + floordiv(threadIdx.x_2, 4)), 16)*16)) + (floormod(threadIdx.x_2, 4)*4)) + 256), 1, 4)]
            }
          }
        }
      }
      for (ic_chunk.inner: int32, 0, 16) "unroll" {
        for (oc_block: int32, 0, 4) "unroll" {
          compute[oc_block] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((floormod(ic_chunk.outer.outer, 2)*3584) + (ic_chunk.inner*112)) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*4096) + (threadIdx.y*256)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[oc_block], dtype=int32)
          compute[(oc_block + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*3584) + (ic_chunk.inner*112)) + (threadIdx.x*4)) + 1792), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*4096) + (threadIdx.y*256)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 8)], dtype=int32)
          compute[(oc_block + 4)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((floormod(ic_chunk.outer.outer, 2)*3584) + (ic_chunk.inner*112)) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*4096) + (threadIdx.y*256)) + (ic_chunk.inner*16)) + (oc_block*4)) + 2048), 1, 4)], (int32*)compute[(oc_block + 4)], dtype=int32)
          compute[(oc_block + 12)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*3584) + (ic_chunk.inner*112)) + (threadIdx.x*4)) + 1792), 1, 4)], (int8x4*)placeholder.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*4096) + (threadIdx.y*256)) + (ic_chunk.inner*16)) + (oc_block*4)) + 2048), 1, 4)], (int32*)compute[(oc_block + 12)], dtype=int32)
        }
      }
    }
    for (ic_chunk.inner_1: int32, 0, 16) "unroll" {
      for (oc_block_1: int32, 0, 4) "unroll" {
        compute[oc_block_1] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner_1*112) + (threadIdx.x*4)) + 3584), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*256) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 4096), 1, 4)], (int32*)compute[oc_block_1], dtype=int32)
        compute[(oc_block_1 + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner_1*112) + (threadIdx.x*4)) + 5376), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*256) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 4096), 1, 4)], (int32*)compute[(oc_block_1 + 8)], dtype=int32)
        compute[(oc_block_1 + 4)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner_1*112) + (threadIdx.x*4)) + 3584), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*256) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 6144), 1, 4)], (int32*)compute[(oc_block_1 + 4)], dtype=int32)
        compute[(oc_block_1 + 12)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner_1*112) + (threadIdx.x*4)) + 5376), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*256) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 6144), 1, 4)], (int32*)compute[(oc_block_1 + 12)], dtype=int32)
      }
    }
    for (ax4: int32, 0, 4) "unroll" {
      T_relu_2[((((((blockIdx.z*401408) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[ax4], 2105581540, 31, 17, dtype=int32) + (int32*)placeholder_13[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 1073757977, 31, 1, dtype=int32) + (int32*)placeholder_10[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 1719164685, 31, 0, dtype=int32) + (int32*)placeholder_11[((((((blockIdx.z*401408) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4)]), 0)
      T_relu_2[(((((((blockIdx.z*401408) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4) + 200704)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 8)], 2105581540, 31, 17, dtype=int32) + (int32*)placeholder_13[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 1073757977, 31, 1, dtype=int32) + (int32*)placeholder_10[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 1719164685, 31, 0, dtype=int32) + (int32*)placeholder_11[(((((((blockIdx.z*401408) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4) + 200704)]), 0)
      T_relu_2[(((((((blockIdx.z*401408) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4) + 6272)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 4)], 2105581540, 31, 17, dtype=int32) + (int32*)placeholder_13[((((blockIdx.y*64) + (threadIdx.y*4)) + ax4) + 32)]), 1073757977, 31, 1, dtype=int32) + (int32*)placeholder_10[((((blockIdx.y*64) + (threadIdx.y*4)) + ax4) + 32)]), 1719164685, 31, 0, dtype=int32) + (int32*)placeholder_11[(((((((blockIdx.z*401408) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4) + 6272)]), 0)
      T_relu_2[(((((((blockIdx.z*401408) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4) + 206976)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 12)], 2105581540, 31, 17, dtype=int32) + (int32*)placeholder_13[((((blockIdx.y*64) + (threadIdx.y*4)) + ax4) + 32)]), 1073757977, 31, 1, dtype=int32) + (int32*)placeholder_10[((((blockIdx.y*64) + (threadIdx.y*4)) + ax4) + 32)]), 1719164685, 31, 0, dtype=int32) + (int32*)placeholder_11[(((((((blockIdx.z*401408) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4) + 206976)]), 0)
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_nn_relu_cast_fixed_point_mult_18399029763786111876__8", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [32, 64, 14, 14, 4], []),
             placeholder_2: Buffer(placeholder_6: handle, int32, [1, 64, 1, 1, 4], []),
             placeholder: Buffer(placeholder_7: handle, int8, [32, 64, 14, 14, 4], []),
             placeholder_1: Buffer(placeholder_8: handle, int8, [64, 64, 3, 3, 4, 4], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 16;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [28]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [256]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [576]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 4;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 7;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4 {
    for (oh.init: int32, 0, 7) "unroll" {
      for (oc_block.init: int32, 0, 4) "unroll" {
        compute[((oh.init*4) + oc_block.init)] = 0
      }
    }
    attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
    attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
    attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
    pad_data.shared[ramp((((threadIdx.z_1*256) + (threadIdx.y_1*16)) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((1 <= threadIdx.y_1) && (threadIdx.y_1 < 15)) && (1 <= ((blockIdx.x*2) + threadIdx.x_1))) && (((blockIdx.x*2) + threadIdx.x_1) < 15)), (int8x4*)placeholder_7[ramp(((((((blockIdx.z*100352) + (threadIdx.z_1*50176)) + (threadIdx.y_1*56)) + (blockIdx.x*8)) + (threadIdx.x_1*4)) - 60), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
    for (ic_chunk.outer.outer: int32, 0, 63) {
      attr [pad_data.shared] "double_buffer_write" = 1;
      attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
      attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
      attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
      pad_data.shared[ramp(((((floormod((ic_chunk.outer.outer + 1), 2)*512) + (threadIdx.z_1*256)) + (threadIdx.y_1*16)) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((1 <= threadIdx.y_1) && (threadIdx.y_1 < 15)) && (1 <= ((blockIdx.x*2) + threadIdx.x_1))) && (((blockIdx.x*2) + threadIdx.x_1) < 15)), (int8x4*)placeholder_7[ramp((((((((blockIdx.z*100352) + (threadIdx.z_1*50176)) + (ic_chunk.outer.outer*784)) + (threadIdx.y_1*56)) + (blockIdx.x*8)) + (threadIdx.x_1*4)) + 724), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 5) "unroll" {
        attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
        attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.z_2*16)) + threadIdx.y_2) < 144) {
          if (((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*128) + (threadIdx.z_2*64)) + (threadIdx.y_2*4)) + threadIdx.x_2) < 576) {
            if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*2) + threadIdx.z_2) < 9) {
              placeholder.shared[ramp(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*512) + (threadIdx.z_2*256)) + (threadIdx.y_2*16)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp((((((blockIdx.y*147456) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.z_2*16)) + threadIdx.y_2), 9)*9216)) + (ic_chunk.outer.outer*144)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.z_2*16)) + threadIdx.y_2), 9)*16)) + (threadIdx.x_2*4)), 1, 4)]
            }
          }
        }
      }
      for (kw.inner: int32, 0, 3) "unroll" {
        for (kh.inner: int32, 0, 3) "unroll" {
          for (oh: int32, 0, 7) "unroll" {
            for (oc_block: int32, 0, 4) "unroll" {
              compute[((oh*4) + oc_block)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((((floormod(ic_chunk.outer.outer, 2)*512) + (threadIdx.z*256)) + (floordiv(threadIdx.x, 2)*112)) + (oh*16)) + (kh.inner*16)) + (kw.inner*4)) + (floormod(threadIdx.x, 2)*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*144) + (kh.inner*48)) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[((oh*4) + oc_block)], dtype=int32)
            }
          }
        }
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 5) "unroll" {
      attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
      attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
      attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.z_2*16)) + threadIdx.y_2) < 144) {
        if (((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_2*64)) + (threadIdx.y_2*4)) + threadIdx.x_2) < 576) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*2) + threadIdx.z_2) < 9) {
            placeholder.shared[ramp(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*512) + (threadIdx.z_2*256)) + (threadIdx.y_2*16)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp((((((blockIdx.y*147456) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.z_2*16)) + threadIdx.y_2), 9)*9216)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.z_2*16)) + threadIdx.y_2), 9)*16)) + (threadIdx.x_2*4)) + 9072), 1, 4)]
          }
        }
      }
    }
    for (kw.inner_1: int32, 0, 3) "unroll" {
      for (kh.inner_1: int32, 0, 3) "unroll" {
        for (oh_1: int32, 0, 7) "unroll" {
          for (oc_block_1: int32, 0, 4) "unroll" {
            compute[((oh_1*4) + oc_block_1)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((((threadIdx.z*256) + (floordiv(threadIdx.x, 2)*112)) + (oh_1*16)) + (kh.inner_1*16)) + (kw.inner_1*4)) + (floormod(threadIdx.x, 2)*4)) + 512), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*144) + (kh.inner_1*48)) + (kw.inner_1*16)) + (oc_block_1*4)), 1, 4)], (int32*)compute[((oh_1*4) + oc_block_1)], dtype=int32)
          }
        }
      }
    }
    for (ax2.inner.inner.inner: int32, 0, 7) "unroll" {
      for (ax4: int32, 0, 4) "unroll" {
        T_cast_2[(((((((((blockIdx.z*100352) + (threadIdx.z*50176)) + (blockIdx.y*12544)) + (threadIdx.y*784)) + (floordiv(threadIdx.x, 2)*392)) + (ax2.inner.inner.inner*56)) + (blockIdx.x*8)) + (floormod(threadIdx.x, 2)*4)) + ax4)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((int32*)compute[((ax2.inner.inner.inner*4) + ax4)], 1733956305, 31, 15, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 0), 1659014097, 31, -23, dtype=int32), 127), -128))
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_fixed_point_multiply_add_cast_16086763325481941859__7", "tir.noalias": True}
  buffers = {placeholder_2: Buffer(placeholder_8: handle, int8, [64, 128, 1, 1, 4, 4], []),
             placeholder: Buffer(placeholder_9: handle, int32, [1, 64, 1, 1, 4], []),
             placeholder_3: Buffer(placeholder_10: handle, int32, [1, 64, 1, 1, 4], []),
             T_cast: Buffer(T_cast_2: handle, int8, [32, 64, 14, 14, 4], []),
             placeholder_1: Buffer(placeholder_11: handle, int8, [32, 128, 28, 28, 4], [])}
  buffer_map = {placeholder_6: placeholder, placeholder_4: placeholder_1, T_cast_1: T_cast, placeholder_5: placeholder_2, placeholder_7: placeholder_3} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 32;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [28]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [1296]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [2048]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 2;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 7;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 32;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 2;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 2 {
    for (oc_block.init: int32, 0, 4) "unroll" {
      compute[oc_block.init] = 0
      compute[(oc_block.init + 4)] = 0
      compute[(oc_block.init + 8)] = 0
      compute[(oc_block.init + 12)] = 0
      compute[(oc_block.init + 16)] = 0
      compute[(oc_block.init + 20)] = 0
      compute[(oc_block.init + 24)] = 0
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 6) "unroll" {
      attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 32;
      attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 2;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 2;
      if (((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*4)) + (threadIdx.y_1*2)) + threadIdx.x_1) < 648) {
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*64) + (threadIdx.z_1*2)) + threadIdx.y_1) < 324) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*32) + threadIdx.z_1) < 162) {
            pad_data.shared[ramp(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*512) + (threadIdx.z_1*16)) + (threadIdx.y_1*8)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_11[ramp((((((blockIdx.z*401408) + (floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*4)) + (threadIdx.y_1*2)) + threadIdx.x_1), 81)*3136)) + (blockIdx.x*448)) + (floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*4)) + (threadIdx.y_1*2)) + threadIdx.x_1), 81), 27)*112)) + (floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*4)) + (threadIdx.y_1*2)) + threadIdx.x_1), 27)*4)), 1, 4)]
          }
        }
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 8) "unroll" {
      attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 32;
      attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 2;
      attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 2;
      placeholder.shared[ramp((((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*512) + (floordiv((((threadIdx.z_2*4) + (threadIdx.y_2*2)) + threadIdx.x_2), 32)*128)) + (floormod(threadIdx.z_2, 8)*16)) + (threadIdx.y_2*8)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp(((((((blockIdx.y*65536) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*8192)) + (floordiv((((threadIdx.z_2*4) + (threadIdx.y_2*2)) + threadIdx.x_2), 32)*2048)) + (floormod(threadIdx.z_2, 8)*16)) + (threadIdx.y_2*8)) + (threadIdx.x_2*4)), 1, 4)]
    }
    for (ic_chunk.outer.outer: int32, 0, 15) {
      attr [pad_data.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1: int32, 0, 6) "unroll" {
        attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 32;
        attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 2;
        attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 2;
        if (((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_1*4)) + (threadIdx.y_1*2)) + threadIdx.x_1) < 648) {
          if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*64) + (threadIdx.z_1*2)) + threadIdx.y_1) < 324) {
            if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*32) + threadIdx.z_1) < 162) {
              pad_data.shared[ramp((((((floormod((ic_chunk.outer.outer + 1), 2)*2592) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*512)) + (threadIdx.z_1*16)) + (threadIdx.y_1*8)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_11[ramp((((((((blockIdx.z*401408) + (ic_chunk.outer.outer*25088)) + (floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_1*4)) + (threadIdx.y_1*2)) + threadIdx.x_1), 81)*3136)) + (blockIdx.x*448)) + (floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_1*4)) + (threadIdx.y_1*2)) + threadIdx.x_1), 81), 27)*112)) + (floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_1*4)) + (threadIdx.y_1*2)) + threadIdx.x_1), 27)*4)) + 25088), 1, 4)]
            }
          }
        }
      }
      attr [placeholder.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 8) "unroll" {
        attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 32;
        attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 2;
        attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 2;
        placeholder.shared[ramp(((((((floormod((ic_chunk.outer.outer + 1), 2)*4096) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*512)) + (floordiv((((threadIdx.z_2*4) + (threadIdx.y_2*2)) + threadIdx.x_2), 32)*128)) + (floormod(threadIdx.z_2, 8)*16)) + (threadIdx.y_2*8)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp(((((((((blockIdx.y*65536) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*8192)) + (floordiv((((threadIdx.z_2*4) + (threadIdx.y_2*2)) + threadIdx.x_2), 32)*2048)) + (ic_chunk.outer.outer*128)) + (floormod(threadIdx.z_2, 8)*16)) + (threadIdx.y_2*8)) + (threadIdx.x_2*4)) + 128), 1, 4)]
      }
      for (ic_chunk.inner: int32, 0, 8) "unroll" {
        for (oc_block: int32, 0, 4) "unroll" {
          compute[oc_block] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*2592) + (ic_chunk.inner*324)) + (threadIdx.y*216)) + (threadIdx.x*8)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*4096) + (threadIdx.z*128)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[oc_block], dtype=int32)
          compute[(oc_block + 4)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*2592) + (ic_chunk.inner*324)) + (threadIdx.y*216)) + (threadIdx.x*8)) + 16), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*4096) + (threadIdx.z*128)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 4)], dtype=int32)
          compute[(oc_block + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*2592) + (ic_chunk.inner*324)) + (threadIdx.y*216)) + (threadIdx.x*8)) + 32), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*4096) + (threadIdx.z*128)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 8)], dtype=int32)
          compute[(oc_block + 12)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*2592) + (ic_chunk.inner*324)) + (threadIdx.y*216)) + (threadIdx.x*8)) + 48), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*4096) + (threadIdx.z*128)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 12)], dtype=int32)
          compute[(oc_block + 16)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*2592) + (ic_chunk.inner*324)) + (threadIdx.y*216)) + (threadIdx.x*8)) + 64), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*4096) + (threadIdx.z*128)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 16)], dtype=int32)
          compute[(oc_block + 20)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*2592) + (ic_chunk.inner*324)) + (threadIdx.y*216)) + (threadIdx.x*8)) + 80), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*4096) + (threadIdx.z*128)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 20)], dtype=int32)
          compute[(oc_block + 24)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*2592) + (ic_chunk.inner*324)) + (threadIdx.y*216)) + (threadIdx.x*8)) + 96), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*4096) + (threadIdx.z*128)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 24)], dtype=int32)
        }
      }
    }
    for (ic_chunk.inner_1: int32, 0, 8) "unroll" {
      for (oc_block_1: int32, 0, 4) "unroll" {
        compute[oc_block_1] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((ic_chunk.inner_1*324) + (threadIdx.y*216)) + (threadIdx.x*8)) + 2592), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.z*128) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 4096), 1, 4)], (int32*)compute[oc_block_1], dtype=int32)
        compute[(oc_block_1 + 4)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((ic_chunk.inner_1*324) + (threadIdx.y*216)) + (threadIdx.x*8)) + 2608), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.z*128) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 4096), 1, 4)], (int32*)compute[(oc_block_1 + 4)], dtype=int32)
        compute[(oc_block_1 + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((ic_chunk.inner_1*324) + (threadIdx.y*216)) + (threadIdx.x*8)) + 2624), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.z*128) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 4096), 1, 4)], (int32*)compute[(oc_block_1 + 8)], dtype=int32)
        compute[(oc_block_1 + 12)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((ic_chunk.inner_1*324) + (threadIdx.y*216)) + (threadIdx.x*8)) + 2640), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.z*128) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 4096), 1, 4)], (int32*)compute[(oc_block_1 + 12)], dtype=int32)
        compute[(oc_block_1 + 16)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((ic_chunk.inner_1*324) + (threadIdx.y*216)) + (threadIdx.x*8)) + 2656), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.z*128) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 4096), 1, 4)], (int32*)compute[(oc_block_1 + 16)], dtype=int32)
        compute[(oc_block_1 + 20)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((ic_chunk.inner_1*324) + (threadIdx.y*216)) + (threadIdx.x*8)) + 2672), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.z*128) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 4096), 1, 4)], (int32*)compute[(oc_block_1 + 20)], dtype=int32)
        compute[(oc_block_1 + 24)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((ic_chunk.inner_1*324) + (threadIdx.y*216)) + (threadIdx.x*8)) + 2688), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.z*128) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 4096), 1, 4)], (int32*)compute[(oc_block_1 + 24)], dtype=int32)
      }
    }
    for (ax4: int32, 0, 4) "unroll" {
      T_cast_2[(((((((blockIdx.z*50176) + (blockIdx.y*25088)) + (threadIdx.z*784)) + (blockIdx.x*112)) + (threadIdx.y*56)) + (threadIdx.x*4)) + ax4)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[ax4], 1321667431, 31, 18, dtype=int32) + (int32*)placeholder_9[(((blockIdx.y*128) + (threadIdx.z*4)) + ax4)]), 2147473582, 31, 0, dtype=int32) + (int32*)placeholder_10[(((blockIdx.y*128) + (threadIdx.z*4)) + ax4)]), 0), 1121749979, 31, -23, dtype=int32), 127), -128))
      T_cast_2[((((((((blockIdx.z*50176) + (blockIdx.y*25088)) + (threadIdx.z*784)) + (blockIdx.x*112)) + (threadIdx.y*56)) + (threadIdx.x*4)) + ax4) + 8)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 4)], 1321667431, 31, 18, dtype=int32) + (int32*)placeholder_9[(((blockIdx.y*128) + (threadIdx.z*4)) + ax4)]), 2147473582, 31, 0, dtype=int32) + (int32*)placeholder_10[(((blockIdx.y*128) + (threadIdx.z*4)) + ax4)]), 0), 1121749979, 31, -23, dtype=int32), 127), -128))
      T_cast_2[((((((((blockIdx.z*50176) + (blockIdx.y*25088)) + (threadIdx.z*784)) + (blockIdx.x*112)) + (threadIdx.y*56)) + (threadIdx.x*4)) + ax4) + 16)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 8)], 1321667431, 31, 18, dtype=int32) + (int32*)placeholder_9[(((blockIdx.y*128) + (threadIdx.z*4)) + ax4)]), 2147473582, 31, 0, dtype=int32) + (int32*)placeholder_10[(((blockIdx.y*128) + (threadIdx.z*4)) + ax4)]), 0), 1121749979, 31, -23, dtype=int32), 127), -128))
      T_cast_2[((((((((blockIdx.z*50176) + (blockIdx.y*25088)) + (threadIdx.z*784)) + (blockIdx.x*112)) + (threadIdx.y*56)) + (threadIdx.x*4)) + ax4) + 24)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 12)], 1321667431, 31, 18, dtype=int32) + (int32*)placeholder_9[(((blockIdx.y*128) + (threadIdx.z*4)) + ax4)]), 2147473582, 31, 0, dtype=int32) + (int32*)placeholder_10[(((blockIdx.y*128) + (threadIdx.z*4)) + ax4)]), 0), 1121749979, 31, -23, dtype=int32), 127), -128))
      T_cast_2[((((((((blockIdx.z*50176) + (blockIdx.y*25088)) + (threadIdx.z*784)) + (blockIdx.x*112)) + (threadIdx.y*56)) + (threadIdx.x*4)) + ax4) + 32)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 16)], 1321667431, 31, 18, dtype=int32) + (int32*)placeholder_9[(((blockIdx.y*128) + (threadIdx.z*4)) + ax4)]), 2147473582, 31, 0, dtype=int32) + (int32*)placeholder_10[(((blockIdx.y*128) + (threadIdx.z*4)) + ax4)]), 0), 1121749979, 31, -23, dtype=int32), 127), -128))
      T_cast_2[((((((((blockIdx.z*50176) + (blockIdx.y*25088)) + (threadIdx.z*784)) + (blockIdx.x*112)) + (threadIdx.y*56)) + (threadIdx.x*4)) + ax4) + 40)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 20)], 1321667431, 31, 18, dtype=int32) + (int32*)placeholder_9[(((blockIdx.y*128) + (threadIdx.z*4)) + ax4)]), 2147473582, 31, 0, dtype=int32) + (int32*)placeholder_10[(((blockIdx.y*128) + (threadIdx.z*4)) + ax4)]), 0), 1121749979, 31, -23, dtype=int32), 127), -128))
      T_cast_2[((((((((blockIdx.z*50176) + (blockIdx.y*25088)) + (threadIdx.z*784)) + (blockIdx.x*112)) + (threadIdx.y*56)) + (threadIdx.x*4)) + ax4) + 48)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 24)], 1321667431, 31, 18, dtype=int32) + (int32*)placeholder_9[(((blockIdx.y*128) + (threadIdx.z*4)) + ax4)]), 2147473582, 31, 0, dtype=int32) + (int32*)placeholder_10[(((blockIdx.y*128) + (threadIdx.z*4)) + ax4)]), 0), 1121749979, 31, -23, dtype=int32), 127), -128))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_fixed_point_multiply_clip_cast_8", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [32, 128, 28, 28, 4], []),
             placeholder: Buffer(placeholder_2: handle, int32, [32, 128, 28, 28, 4], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer: int32, 0, 49) {
    T_cast_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = cast(int8, max(min(@tir.q_multiply_shift((int32*)placeholder_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)], 1769513466, 31, -24, dtype=int32), 127), -128))
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
primfn(placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, placeholder_8: handle, placeholder_9: handle, T_relu_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_fixed_point_multiply_add_cast_15119380522063600768__6", "tir.noalias": True}
  buffers = {placeholder_4: Buffer(placeholder_10: handle, int32, [1, 128, 1, 1, 4], []),
             T_relu: Buffer(T_relu_2: handle, int32, [32, 128, 28, 28, 4], []),
             placeholder: Buffer(placeholder_11: handle, int32, [1, 128, 1, 1, 4], []),
             placeholder_3: Buffer(placeholder_12: handle, int8, [32, 32, 28, 28, 4], []),
             placeholder_1: Buffer(placeholder_13: handle, int32, [32, 128, 28, 28, 4], []),
             placeholder_2: Buffer(placeholder_14: handle, int8, [128, 32, 1, 1, 4, 4], [])}
  buffer_map = {placeholder_7: placeholder, T_relu_1: T_relu, placeholder_9: placeholder_1, placeholder_6: placeholder_2, placeholder_5: placeholder_3, placeholder_8: placeholder_4} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 32;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [32]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [3584]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [1024]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 8;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 7;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 4;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 56 {
    for (oc_chunk.init: int32, 0, 2) "unroll" {
      for (oc_block.init: int32, 0, 4) "unroll" {
        compute[((oc_chunk.init*4) + oc_block.init)] = 0
        compute[(((oc_chunk.init*4) + oc_block.init) + 16)] = 0
        compute[(((oc_chunk.init*4) + oc_block.init) + 8)] = 0
        compute[(((oc_chunk.init*4) + oc_block.init) + 24)] = 0
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 8) "unroll" {
      attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 4;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 56;
      pad_data.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*896) + (((threadIdx.y_1*2) + floordiv(threadIdx.x_1, 28))*112)) + (floormod(threadIdx.x_1, 28)*4)), 1, 4)] = (int8x4*)placeholder_12[ramp(((((((blockIdx.z*100352) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*6272)) + (floordiv(((threadIdx.y_1*2) + floordiv(threadIdx.x_1, 28)), 4)*3136)) + (blockIdx.x*448)) + (floormod(((threadIdx.y_1*2) + floordiv(threadIdx.x_1, 28)), 4)*112)) + (floormod(threadIdx.x_1, 28)*4)), 1, 4)]
    }
    for (ic_chunk.outer.outer: int32, 0, 1) "unroll" {
      attr [pad_data.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1: int32, 0, 8) "unroll" {
        attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 4;
        attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 56;
        pad_data.shared[ramp(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*896) + (((threadIdx.y_1*2) + floordiv(threadIdx.x_1, 28))*112)) + (floormod(threadIdx.x_1, 28)*4)) + 7168), 1, 4)] = (int8x4*)placeholder_12[ramp((((((((blockIdx.z*100352) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*6272)) + (floordiv(((threadIdx.y_1*2) + floordiv(threadIdx.x_1, 28)), 4)*3136)) + (blockIdx.x*448)) + (floormod(((threadIdx.y_1*2) + floordiv(threadIdx.x_1, 28)), 4)*112)) + (floormod(threadIdx.x_1, 28)*4)) + 50176), 1, 4)]
      }
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 5) "unroll" {
        attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 4;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 56;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.y_2*14)) + floordiv(threadIdx.x_2, 4)) < 256) {
          if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*224) + (threadIdx.y_2*56)) + threadIdx.x_2) < 1024) {
            if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*4) + threadIdx.y_2) < 19) {
              placeholder.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*896) + (threadIdx.y_2*224)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_14[ramp(((((blockIdx.y*8192) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.y_2*14)) + floordiv(threadIdx.x_2, 4)), 16)*512)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.y_2*14)) + floordiv(threadIdx.x_2, 4)), 16)*16)) + (floormod(threadIdx.x_2, 4)*4)), 1, 4)]
            }
          }
        }
      }
      for (ic_chunk.inner: int32, 0, 16) "unroll" {
        for (oc_chunk: int32, 0, 2) "unroll" {
          for (oc_block: int32, 0, 4) "unroll" {
            compute[((oc_chunk*4) + oc_block)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((ic_chunk.inner*448) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*512) + (oc_chunk*256)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[((oc_chunk*4) + oc_block)], dtype=int32)
            compute[(((oc_chunk*4) + oc_block) + 16)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((ic_chunk.inner*448) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp((((((threadIdx.y*512) + (oc_chunk*256)) + (ic_chunk.inner*16)) + (oc_block*4)) + 2048), 1, 4)], (int32*)compute[(((oc_chunk*4) + oc_block) + 16)], dtype=int32)
            compute[(((oc_chunk*4) + oc_block) + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*448) + (threadIdx.x*4)) + 224), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*512) + (oc_chunk*256)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(((oc_chunk*4) + oc_block) + 8)], dtype=int32)
            compute[(((oc_chunk*4) + oc_block) + 24)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*448) + (threadIdx.x*4)) + 224), 1, 4)], (int8x4*)placeholder.shared[ramp((((((threadIdx.y*512) + (oc_chunk*256)) + (ic_chunk.inner*16)) + (oc_block*4)) + 2048), 1, 4)], (int32*)compute[(((oc_chunk*4) + oc_block) + 24)], dtype=int32)
          }
        }
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 5) "unroll" {
      attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 4;
      attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 56;
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.y_2*14)) + floordiv(threadIdx.x_2, 4)) < 256) {
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*224) + (threadIdx.y_2*56)) + threadIdx.x_2) < 1024) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*4) + threadIdx.y_2) < 19) {
            placeholder.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*896) + (threadIdx.y_2*224)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_14[ramp((((((blockIdx.y*8192) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.y_2*14)) + floordiv(threadIdx.x_2, 4)), 16)*512)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.y_2*14)) + floordiv(threadIdx.x_2, 4)), 16)*16)) + (floormod(threadIdx.x_2, 4)*4)) + 256), 1, 4)]
          }
        }
      }
    }
    for (ic_chunk.inner_1: int32, 0, 16) "unroll" {
      for (oc_chunk_1: int32, 0, 2) "unroll" {
        for (oc_block_1: int32, 0, 4) "unroll" {
          compute[((oc_chunk_1*4) + oc_block_1)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner_1*448) + (threadIdx.x*4)) + 7168), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*512) + (oc_chunk_1*256)) + (ic_chunk.inner_1*16)) + (oc_block_1*4)), 1, 4)], (int32*)compute[((oc_chunk_1*4) + oc_block_1)], dtype=int32)
          compute[(((oc_chunk_1*4) + oc_block_1) + 16)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner_1*448) + (threadIdx.x*4)) + 7168), 1, 4)], (int8x4*)placeholder.shared[ramp((((((threadIdx.y*512) + (oc_chunk_1*256)) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 2048), 1, 4)], (int32*)compute[(((oc_chunk_1*4) + oc_block_1) + 16)], dtype=int32)
          compute[(((oc_chunk_1*4) + oc_block_1) + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner_1*448) + (threadIdx.x*4)) + 7392), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*512) + (oc_chunk_1*256)) + (ic_chunk.inner_1*16)) + (oc_block_1*4)), 1, 4)], (int32*)compute[(((oc_chunk_1*4) + oc_block_1) + 8)], dtype=int32)
          compute[(((oc_chunk_1*4) + oc_block_1) + 24)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner_1*448) + (threadIdx.x*4)) + 7392), 1, 4)], (int8x4*)placeholder.shared[ramp((((((threadIdx.y*512) + (oc_chunk_1*256)) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 2048), 1, 4)], (int32*)compute[(((oc_chunk_1*4) + oc_block_1) + 24)], dtype=int32)
        }
      }
    }
    for (ax1.inner.inner.inner: int32, 0, 2) "unroll" {
      for (ax4: int32, 0, 4) "unroll" {
        T_relu_2[(((((((blockIdx.z*401408) + (blockIdx.y*50176)) + (threadIdx.y*6272)) + (ax1.inner.inner.inner*3136)) + (blockIdx.x*448)) + (threadIdx.x*4)) + ax4)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[((ax1.inner.inner.inner*4) + ax4)], 1342381011, 31, 18, dtype=int32) + (int32*)placeholder_11[((((blockIdx.y*64) + (threadIdx.y*8)) + (ax1.inner.inner.inner*4)) + ax4)]), 2147423160, 31, 0, dtype=int32) + (int32*)placeholder_10[((((blockIdx.y*64) + (threadIdx.y*8)) + (ax1.inner.inner.inner*4)) + ax4)]), 1646512227, 31, 0, dtype=int32) + @tir.q_multiply_shift((int32*)placeholder_13[(((((((blockIdx.z*401408) + (blockIdx.y*50176)) + (threadIdx.y*6272)) + (ax1.inner.inner.inner*3136)) + (blockIdx.x*448)) + (threadIdx.x*4)) + ax4)], 1993989853, 31, 0, dtype=int32)), 0)
        T_relu_2[((((((((blockIdx.z*401408) + (blockIdx.y*50176)) + (threadIdx.y*6272)) + (ax1.inner.inner.inner*3136)) + (blockIdx.x*448)) + (threadIdx.x*4)) + ax4) + 25088)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(((ax1.inner.inner.inner*4) + ax4) + 16)], 1342381011, 31, 18, dtype=int32) + (int32*)placeholder_11[(((((blockIdx.y*64) + (threadIdx.y*8)) + (ax1.inner.inner.inner*4)) + ax4) + 32)]), 2147423160, 31, 0, dtype=int32) + (int32*)placeholder_10[(((((blockIdx.y*64) + (threadIdx.y*8)) + (ax1.inner.inner.inner*4)) + ax4) + 32)]), 1646512227, 31, 0, dtype=int32) + @tir.q_multiply_shift((int32*)placeholder_13[((((((((blockIdx.z*401408) + (blockIdx.y*50176)) + (threadIdx.y*6272)) + (ax1.inner.inner.inner*3136)) + (blockIdx.x*448)) + (threadIdx.x*4)) + ax4) + 25088)], 1993989853, 31, 0, dtype=int32)), 0)
        T_relu_2[((((((((blockIdx.z*401408) + (blockIdx.y*50176)) + (threadIdx.y*6272)) + (ax1.inner.inner.inner*3136)) + (blockIdx.x*448)) + (threadIdx.x*4)) + ax4) + 224)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(((ax1.inner.inner.inner*4) + ax4) + 8)], 1342381011, 31, 18, dtype=int32) + (int32*)placeholder_11[((((blockIdx.y*64) + (threadIdx.y*8)) + (ax1.inner.inner.inner*4)) + ax4)]), 2147423160, 31, 0, dtype=int32) + (int32*)placeholder_10[((((blockIdx.y*64) + (threadIdx.y*8)) + (ax1.inner.inner.inner*4)) + ax4)]), 1646512227, 31, 0, dtype=int32) + @tir.q_multiply_shift((int32*)placeholder_13[((((((((blockIdx.z*401408) + (blockIdx.y*50176)) + (threadIdx.y*6272)) + (ax1.inner.inner.inner*3136)) + (blockIdx.x*448)) + (threadIdx.x*4)) + ax4) + 224)], 1993989853, 31, 0, dtype=int32)), 0)
        T_relu_2[((((((((blockIdx.z*401408) + (blockIdx.y*50176)) + (threadIdx.y*6272)) + (ax1.inner.inner.inner*3136)) + (blockIdx.x*448)) + (threadIdx.x*4)) + ax4) + 25312)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(((ax1.inner.inner.inner*4) + ax4) + 24)], 1342381011, 31, 18, dtype=int32) + (int32*)placeholder_11[(((((blockIdx.y*64) + (threadIdx.y*8)) + (ax1.inner.inner.inner*4)) + ax4) + 32)]), 2147423160, 31, 0, dtype=int32) + (int32*)placeholder_10[(((((blockIdx.y*64) + (threadIdx.y*8)) + (ax1.inner.inner.inner*4)) + ax4) + 32)]), 1646512227, 31, 0, dtype=int32) + @tir.q_multiply_shift((int32*)placeholder_13[((((((((blockIdx.z*401408) + (blockIdx.y*50176)) + (threadIdx.y*6272)) + (ax1.inner.inner.inner*3136)) + (blockIdx.x*448)) + (threadIdx.x*4)) + ax4) + 25312)], 1993989853, 31, 0, dtype=int32)), 0)
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_nn_relu_cast_fixed_point_mult_18399029763786111876__9", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [32, 32, 28, 28, 4], []),
             placeholder_2: Buffer(placeholder_6: handle, int32, [1, 32, 1, 1, 4], []),
             placeholder: Buffer(placeholder_7: handle, int8, [32, 32, 28, 28, 4], []),
             placeholder_1: Buffer(placeholder_8: handle, int8, [32, 32, 3, 3, 4, 4], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 16;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [16]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [288]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [2304]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 2;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 49;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4 {
    for (oh.init: int32, 0, 2) "unroll" {
      for (oc_block.init: int32, 0, 4) "unroll" {
        compute[((oh.init*4) + oc_block.init)] = 0
        compute[(((oh.init*4) + oc_block.init) + 8)] = 0
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 2) "unroll" {
      attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
      attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
      if (((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1) < 144) {
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*32) + (threadIdx.z_1*16)) + threadIdx.y_1) < 36) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*2) + threadIdx.z_1) < 3) {
            pad_data.shared[ramp(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*512) + (threadIdx.z_1*256)) + (threadIdx.y_1*16)) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((1 <= ((floordiv(blockIdx.x, 7)*4) + floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 36), 6))) && (((floordiv(blockIdx.x, 7)*4) + floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 36), 6)) < 29)) && (1 <= ((floormod(blockIdx.x, 7)*4) + floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 6)))) && (((floormod(blockIdx.x, 7)*4) + floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 6)) < 29)), (int8x4*)placeholder_7[ramp(((((((((blockIdx.z*200704) + (floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 72)*100352)) + (floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 72), 36)*3136)) + (floordiv(blockIdx.x, 7)*448)) + (floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 36), 6)*112)) + (floormod(blockIdx.x, 7)*16)) + (floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 6)*4)) - 116), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
          }
        }
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 9) "unroll" {
      attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
      attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
      attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
      placeholder.shared[ramp(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*512) + (threadIdx.z_2*256)) + (threadIdx.y_2*16)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp(((((blockIdx.y*73728) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.z_2*16)) + threadIdx.y_2), 18)*4608)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.z_2*16)) + threadIdx.y_2), 18)*16)) + (threadIdx.x_2*4)), 1, 4)]
    }
    for (ic_chunk.outer.outer: int32, 0, 15) {
      attr [pad_data.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1: int32, 0, 2) "unroll" {
        attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
        attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
        attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
        if (((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1) < 144) {
          if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*32) + (threadIdx.z_1*16)) + threadIdx.y_1) < 36) {
            if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*2) + threadIdx.z_1) < 3) {
              pad_data.shared[ramp((((((floormod((ic_chunk.outer.outer + 1), 2)*576) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*512)) + (threadIdx.z_1*256)) + (threadIdx.y_1*16)) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((1 <= ((floordiv(blockIdx.x, 7)*4) + floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 36), 6))) && (((floordiv(blockIdx.x, 7)*4) + floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 36), 6)) < 29)) && (1 <= ((floormod(blockIdx.x, 7)*4) + floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 6)))) && (((floormod(blockIdx.x, 7)*4) + floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 6)) < 29)), (int8x4*)placeholder_7[ramp((((((((((blockIdx.z*200704) + (floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 72)*100352)) + (ic_chunk.outer.outer*6272)) + (floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 72), 36)*3136)) + (floordiv(blockIdx.x, 7)*448)) + (floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 36), 6)*112)) + (floormod(blockIdx.x, 7)*16)) + (floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 6)*4)) + 6156), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
            }
          }
        }
      }
      attr [placeholder.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 9) "unroll" {
        attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
        attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
        attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
        placeholder.shared[ramp((((((floormod((ic_chunk.outer.outer + 1), 2)*4608) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*512)) + (threadIdx.z_2*256)) + (threadIdx.y_2*16)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp(((((((blockIdx.y*73728) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.z_2*16)) + threadIdx.y_2), 18)*4608)) + (ic_chunk.outer.outer*288)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.z_2*16)) + threadIdx.y_2), 18)*16)) + (threadIdx.x_2*4)) + 288), 1, 4)]
      }
      for (kw.inner: int32, 0, 3) "unroll" {
        for (ic_chunk.inner: int32, 0, 2) "unroll" {
          for (kh.inner: int32, 0, 3) "unroll" {
            for (oh: int32, 0, 2) "unroll" {
              for (oc_block: int32, 0, 4) "unroll" {
                compute[((oh*4) + oc_block)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((((floormod(ic_chunk.outer.outer, 2)*576) + (threadIdx.z*288)) + (ic_chunk.inner*144)) + (oh*24)) + (kh.inner*24)) + (threadIdx.x*4)) + (kw.inner*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((((floormod(ic_chunk.outer.outer, 2)*4608) + (threadIdx.y*288)) + (ic_chunk.inner*144)) + (kh.inner*48)) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[((oh*4) + oc_block)], dtype=int32)
                compute[(((oh*4) + oc_block) + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((((((floormod(ic_chunk.outer.outer, 2)*576) + (threadIdx.z*288)) + (ic_chunk.inner*144)) + (oh*24)) + (kh.inner*24)) + (threadIdx.x*4)) + (kw.inner*4)) + 48), 1, 4)], (int8x4*)placeholder.shared[ramp(((((((floormod(ic_chunk.outer.outer, 2)*4608) + (threadIdx.y*288)) + (ic_chunk.inner*144)) + (kh.inner*48)) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(((oh*4) + oc_block) + 8)], dtype=int32)
              }
            }
          }
        }
      }
    }
    for (kw.inner_1: int32, 0, 3) "unroll" {
      for (ic_chunk.inner_1: int32, 0, 2) "unroll" {
        for (kh.inner_1: int32, 0, 3) "unroll" {
          for (oh_1: int32, 0, 2) "unroll" {
            for (oc_block_1: int32, 0, 4) "unroll" {
              compute[((oh_1*4) + oc_block_1)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((((threadIdx.z*288) + (ic_chunk.inner_1*144)) + (oh_1*24)) + (kh.inner_1*24)) + (threadIdx.x*4)) + (kw.inner_1*4)) + 576), 1, 4)], (int8x4*)placeholder.shared[ramp(((((((threadIdx.y*288) + (ic_chunk.inner_1*144)) + (kh.inner_1*48)) + (kw.inner_1*16)) + (oc_block_1*4)) + 4608), 1, 4)], (int32*)compute[((oh_1*4) + oc_block_1)], dtype=int32)
              compute[(((oh_1*4) + oc_block_1) + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((((threadIdx.z*288) + (ic_chunk.inner_1*144)) + (oh_1*24)) + (kh.inner_1*24)) + (threadIdx.x*4)) + (kw.inner_1*4)) + 624), 1, 4)], (int8x4*)placeholder.shared[ramp(((((((threadIdx.y*288) + (ic_chunk.inner_1*144)) + (kh.inner_1*48)) + (kw.inner_1*16)) + (oc_block_1*4)) + 4608), 1, 4)], (int32*)compute[(((oh_1*4) + oc_block_1) + 8)], dtype=int32)
            }
          }
        }
      }
    }
    for (ax2.inner.inner.inner: int32, 0, 2) "unroll" {
      for (ax4: int32, 0, 4) "unroll" {
        T_cast_2[(((((((((blockIdx.z*200704) + (threadIdx.z*100352)) + (blockIdx.y*50176)) + (threadIdx.y*3136)) + (floordiv(blockIdx.x, 7)*448)) + (ax2.inner.inner.inner*112)) + (floormod(blockIdx.x, 7)*16)) + (threadIdx.x*4)) + ax4)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((int32*)compute[((ax2.inner.inner.inner*4) + ax4)], 1366742087, 31, 17, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 0), 2126681667, 31, -24, dtype=int32), 127), -128))
        T_cast_2[((((((((((blockIdx.z*200704) + (threadIdx.z*100352)) + (blockIdx.y*50176)) + (threadIdx.y*3136)) + (floordiv(blockIdx.x, 7)*448)) + (ax2.inner.inner.inner*112)) + (floormod(blockIdx.x, 7)*16)) + (threadIdx.x*4)) + ax4) + 224)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((int32*)compute[(((ax2.inner.inner.inner*4) + ax4) + 8)], 1366742087, 31, 17, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 0), 2126681667, 31, -24, dtype=int32), 127), -128))
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_fixed_point_multiply_add_cast_16086763325481941859__8", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [32, 32, 28, 28, 4], []),
             placeholder_3: Buffer(placeholder_8: handle, int32, [1, 32, 1, 1, 4], []),
             placeholder_2: Buffer(placeholder_9: handle, int8, [32, 128, 1, 1, 4, 4], []),
             placeholder: Buffer(placeholder_10: handle, int32, [1, 32, 1, 1, 4], []),
             placeholder_1: Buffer(placeholder_11: handle, int8, [32, 128, 28, 28, 4], [])}
  buffer_map = {placeholder_7: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, placeholder_6: placeholder_3, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 32;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [28]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [896]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [1024]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 2;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 14;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 16;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 2;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4 {
    for (oc_block.init: int32, 0, 4) "unroll" {
      compute[oc_block.init] = 0
      compute[(oc_block.init + 4)] = 0
      compute[(oc_block.init + 8)] = 0
      compute[(oc_block.init + 12)] = 0
      compute[(oc_block.init + 16)] = 0
      compute[(oc_block.init + 20)] = 0
      compute[(oc_block.init + 24)] = 0
    }
    for (ic_chunk.outer: int32, 0, 8) {
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 7) "unroll" {
        attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 16;
        attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 2;
        attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
        pad_data.shared[ramp(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*512) + (threadIdx.z_1*32)) + (threadIdx.y_1*16)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_11[ramp((((((blockIdx.z*401408) + (ic_chunk.outer*50176)) + (floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*8)) + (threadIdx.y_1*4)) + threadIdx.x_1), 56)*3136)) + (blockIdx.x*224)) + (floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*8)) + (threadIdx.y_1*4)) + threadIdx.x_1), 56)*4)), 1, 4)]
      }
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 8) "unroll" {
        attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 16;
        attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 2;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
        placeholder.shared[ramp(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*512) + (threadIdx.z_2*32)) + (threadIdx.y_2*16)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_9[ramp(((((((blockIdx.y*32768) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*4096)) + (floordiv(((threadIdx.z_2*2) + threadIdx.y_2), 16)*2048)) + (ic_chunk.outer*256)) + (floormod(((threadIdx.z_2*2) + threadIdx.y_2), 16)*16)) + (threadIdx.x_2*4)), 1, 4)]
      }
      for (ic_chunk.inner: int32, 0, 16) "unroll" {
        for (oc_block: int32, 0, 4) "unroll" {
          compute[oc_block] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*224) + (threadIdx.y*112)) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*256) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[oc_block], dtype=int32)
          compute[(oc_block + 4)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((ic_chunk.inner*224) + (threadIdx.y*112)) + (threadIdx.x*4)) + 16), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*256) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 4)], dtype=int32)
          compute[(oc_block + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((ic_chunk.inner*224) + (threadIdx.y*112)) + (threadIdx.x*4)) + 32), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*256) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 8)], dtype=int32)
          compute[(oc_block + 12)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((ic_chunk.inner*224) + (threadIdx.y*112)) + (threadIdx.x*4)) + 48), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*256) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 12)], dtype=int32)
          compute[(oc_block + 16)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((ic_chunk.inner*224) + (threadIdx.y*112)) + (threadIdx.x*4)) + 64), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*256) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 16)], dtype=int32)
          compute[(oc_block + 20)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((ic_chunk.inner*224) + (threadIdx.y*112)) + (threadIdx.x*4)) + 80), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*256) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 20)], dtype=int32)
          compute[(oc_block + 24)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((ic_chunk.inner*224) + (threadIdx.y*112)) + (threadIdx.x*4)) + 96), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*256) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 24)], dtype=int32)
        }
      }
    }
    for (ax4: int32, 0, 4) "unroll" {
      T_cast_2[(((((((blockIdx.z*100352) + (blockIdx.y*50176)) + (threadIdx.z*3136)) + (blockIdx.x*224)) + (threadIdx.y*112)) + (threadIdx.x*4)) + ax4)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[ax4], 1684117788, 31, 16, dtype=int32) + (int32*)placeholder_8[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 2147475627, 31, 0, dtype=int32) + (int32*)placeholder_10[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 0), 1150021518, 31, -23, dtype=int32), 127), -128))
      T_cast_2[((((((((blockIdx.z*100352) + (blockIdx.y*50176)) + (threadIdx.z*3136)) + (blockIdx.x*224)) + (threadIdx.y*112)) + (threadIdx.x*4)) + ax4) + 16)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 4)], 1684117788, 31, 16, dtype=int32) + (int32*)placeholder_8[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 2147475627, 31, 0, dtype=int32) + (int32*)placeholder_10[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 0), 1150021518, 31, -23, dtype=int32), 127), -128))
      T_cast_2[((((((((blockIdx.z*100352) + (blockIdx.y*50176)) + (threadIdx.z*3136)) + (blockIdx.x*224)) + (threadIdx.y*112)) + (threadIdx.x*4)) + ax4) + 32)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 8)], 1684117788, 31, 16, dtype=int32) + (int32*)placeholder_8[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 2147475627, 31, 0, dtype=int32) + (int32*)placeholder_10[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 0), 1150021518, 31, -23, dtype=int32), 127), -128))
      T_cast_2[((((((((blockIdx.z*100352) + (blockIdx.y*50176)) + (threadIdx.z*3136)) + (blockIdx.x*224)) + (threadIdx.y*112)) + (threadIdx.x*4)) + ax4) + 48)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 12)], 1684117788, 31, 16, dtype=int32) + (int32*)placeholder_8[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 2147475627, 31, 0, dtype=int32) + (int32*)placeholder_10[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 0), 1150021518, 31, -23, dtype=int32), 127), -128))
      T_cast_2[((((((((blockIdx.z*100352) + (blockIdx.y*50176)) + (threadIdx.z*3136)) + (blockIdx.x*224)) + (threadIdx.y*112)) + (threadIdx.x*4)) + ax4) + 64)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 16)], 1684117788, 31, 16, dtype=int32) + (int32*)placeholder_8[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 2147475627, 31, 0, dtype=int32) + (int32*)placeholder_10[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 0), 1150021518, 31, -23, dtype=int32), 127), -128))
      T_cast_2[((((((((blockIdx.z*100352) + (blockIdx.y*50176)) + (threadIdx.z*3136)) + (blockIdx.x*224)) + (threadIdx.y*112)) + (threadIdx.x*4)) + ax4) + 80)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 20)], 1684117788, 31, 16, dtype=int32) + (int32*)placeholder_8[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 2147475627, 31, 0, dtype=int32) + (int32*)placeholder_10[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 0), 1150021518, 31, -23, dtype=int32), 127), -128))
      T_cast_2[((((((((blockIdx.z*100352) + (blockIdx.y*50176)) + (threadIdx.z*3136)) + (blockIdx.x*224)) + (threadIdx.y*112)) + (threadIdx.x*4)) + ax4) + 96)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 24)], 1684117788, 31, 16, dtype=int32) + (int32*)placeholder_8[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 2147475627, 31, 0, dtype=int32) + (int32*)placeholder_10[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 0), 1150021518, 31, -23, dtype=int32), 127), -128))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_fixed_point_multiply_clip_cast_9", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [32, 128, 28, 28, 4], []),
             placeholder: Buffer(placeholder_2: handle, int32, [32, 128, 28, 28, 4], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer: int32, 0, 49) {
    T_cast_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = cast(int8, max(min(@tir.q_multiply_shift((int32*)placeholder_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)], 1993989853, 31, -24, dtype=int32), 127), -128))
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
primfn(placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, placeholder_8: handle, placeholder_9: handle, T_relu_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_fixed_point_multiply_add_cast_15119380522063600768__7", "tir.noalias": True}
  buffers = {T_relu: Buffer(T_relu_2: handle, int32, [32, 128, 28, 28, 4], []),
             placeholder_1: Buffer(placeholder_10: handle, int8, [32, 32, 28, 28, 4], []),
             placeholder: Buffer(placeholder_11: handle, int32, [32, 128, 28, 28, 4], []),
             placeholder_3: Buffer(placeholder_12: handle, int32, [1, 128, 1, 1, 4], []),
             placeholder_4: Buffer(placeholder_13: handle, int32, [1, 128, 1, 1, 4], []),
             placeholder_2: Buffer(placeholder_14: handle, int8, [128, 32, 1, 1, 4, 4], [])}
  buffer_map = {placeholder_9: placeholder, placeholder_5: placeholder_1, placeholder_6: placeholder_2, placeholder_7: placeholder_3, placeholder_8: placeholder_4, T_relu_1: T_relu} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 32;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [32]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [3584]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [1024]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 8;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 7;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 4;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 56 {
    for (oc_chunk.init: int32, 0, 2) "unroll" {
      for (oc_block.init: int32, 0, 4) "unroll" {
        compute[((oc_chunk.init*4) + oc_block.init)] = 0
        compute[(((oc_chunk.init*4) + oc_block.init) + 16)] = 0
        compute[(((oc_chunk.init*4) + oc_block.init) + 8)] = 0
        compute[(((oc_chunk.init*4) + oc_block.init) + 24)] = 0
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 8) "unroll" {
      attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 4;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 56;
      pad_data.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*896) + (((threadIdx.y_1*2) + floordiv(threadIdx.x_1, 28))*112)) + (floormod(threadIdx.x_1, 28)*4)), 1, 4)] = (int8x4*)placeholder_10[ramp(((((((blockIdx.z*100352) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*6272)) + (floordiv(((threadIdx.y_1*2) + floordiv(threadIdx.x_1, 28)), 4)*3136)) + (blockIdx.x*448)) + (floormod(((threadIdx.y_1*2) + floordiv(threadIdx.x_1, 28)), 4)*112)) + (floormod(threadIdx.x_1, 28)*4)), 1, 4)]
    }
    for (ic_chunk.outer.outer: int32, 0, 1) "unroll" {
      attr [pad_data.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1: int32, 0, 8) "unroll" {
        attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 4;
        attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 56;
        pad_data.shared[ramp(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*896) + (((threadIdx.y_1*2) + floordiv(threadIdx.x_1, 28))*112)) + (floormod(threadIdx.x_1, 28)*4)) + 7168), 1, 4)] = (int8x4*)placeholder_10[ramp((((((((blockIdx.z*100352) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*6272)) + (floordiv(((threadIdx.y_1*2) + floordiv(threadIdx.x_1, 28)), 4)*3136)) + (blockIdx.x*448)) + (floormod(((threadIdx.y_1*2) + floordiv(threadIdx.x_1, 28)), 4)*112)) + (floormod(threadIdx.x_1, 28)*4)) + 50176), 1, 4)]
      }
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 5) "unroll" {
        attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 4;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 56;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.y_2*14)) + floordiv(threadIdx.x_2, 4)) < 256) {
          if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*224) + (threadIdx.y_2*56)) + threadIdx.x_2) < 1024) {
            if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*4) + threadIdx.y_2) < 19) {
              placeholder.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*896) + (threadIdx.y_2*224)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_14[ramp(((((blockIdx.y*8192) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.y_2*14)) + floordiv(threadIdx.x_2, 4)), 16)*512)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.y_2*14)) + floordiv(threadIdx.x_2, 4)), 16)*16)) + (floormod(threadIdx.x_2, 4)*4)), 1, 4)]
            }
          }
        }
      }
      for (ic_chunk.inner: int32, 0, 16) "unroll" {
        for (oc_chunk: int32, 0, 2) "unroll" {
          for (oc_block: int32, 0, 4) "unroll" {
            compute[((oc_chunk*4) + oc_block)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((ic_chunk.inner*448) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*512) + (oc_chunk*256)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[((oc_chunk*4) + oc_block)], dtype=int32)
            compute[(((oc_chunk*4) + oc_block) + 16)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((ic_chunk.inner*448) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp((((((threadIdx.y*512) + (oc_chunk*256)) + (ic_chunk.inner*16)) + (oc_block*4)) + 2048), 1, 4)], (int32*)compute[(((oc_chunk*4) + oc_block) + 16)], dtype=int32)
            compute[(((oc_chunk*4) + oc_block) + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*448) + (threadIdx.x*4)) + 224), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*512) + (oc_chunk*256)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(((oc_chunk*4) + oc_block) + 8)], dtype=int32)
            compute[(((oc_chunk*4) + oc_block) + 24)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*448) + (threadIdx.x*4)) + 224), 1, 4)], (int8x4*)placeholder.shared[ramp((((((threadIdx.y*512) + (oc_chunk*256)) + (ic_chunk.inner*16)) + (oc_block*4)) + 2048), 1, 4)], (int32*)compute[(((oc_chunk*4) + oc_block) + 24)], dtype=int32)
          }
        }
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 5) "unroll" {
      attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 4;
      attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 56;
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.y_2*14)) + floordiv(threadIdx.x_2, 4)) < 256) {
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*224) + (threadIdx.y_2*56)) + threadIdx.x_2) < 1024) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*4) + threadIdx.y_2) < 19) {
            placeholder.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*896) + (threadIdx.y_2*224)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_14[ramp((((((blockIdx.y*8192) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.y_2*14)) + floordiv(threadIdx.x_2, 4)), 16)*512)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.y_2*14)) + floordiv(threadIdx.x_2, 4)), 16)*16)) + (floormod(threadIdx.x_2, 4)*4)) + 256), 1, 4)]
          }
        }
      }
    }
    for (ic_chunk.inner_1: int32, 0, 16) "unroll" {
      for (oc_chunk_1: int32, 0, 2) "unroll" {
        for (oc_block_1: int32, 0, 4) "unroll" {
          compute[((oc_chunk_1*4) + oc_block_1)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner_1*448) + (threadIdx.x*4)) + 7168), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*512) + (oc_chunk_1*256)) + (ic_chunk.inner_1*16)) + (oc_block_1*4)), 1, 4)], (int32*)compute[((oc_chunk_1*4) + oc_block_1)], dtype=int32)
          compute[(((oc_chunk_1*4) + oc_block_1) + 16)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner_1*448) + (threadIdx.x*4)) + 7168), 1, 4)], (int8x4*)placeholder.shared[ramp((((((threadIdx.y*512) + (oc_chunk_1*256)) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 2048), 1, 4)], (int32*)compute[(((oc_chunk_1*4) + oc_block_1) + 16)], dtype=int32)
          compute[(((oc_chunk_1*4) + oc_block_1) + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner_1*448) + (threadIdx.x*4)) + 7392), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*512) + (oc_chunk_1*256)) + (ic_chunk.inner_1*16)) + (oc_block_1*4)), 1, 4)], (int32*)compute[(((oc_chunk_1*4) + oc_block_1) + 8)], dtype=int32)
          compute[(((oc_chunk_1*4) + oc_block_1) + 24)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner_1*448) + (threadIdx.x*4)) + 7392), 1, 4)], (int8x4*)placeholder.shared[ramp((((((threadIdx.y*512) + (oc_chunk_1*256)) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 2048), 1, 4)], (int32*)compute[(((oc_chunk_1*4) + oc_block_1) + 24)], dtype=int32)
        }
      }
    }
    for (ax1.inner.inner.inner: int32, 0, 2) "unroll" {
      for (ax4: int32, 0, 4) "unroll" {
        T_relu_2[(((((((blockIdx.z*401408) + (blockIdx.y*50176)) + (threadIdx.y*6272)) + (ax1.inner.inner.inner*3136)) + (blockIdx.x*448)) + (threadIdx.x*4)) + ax4)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[((ax1.inner.inner.inner*4) + ax4)], 1268844533, 31, 18, dtype=int32) + (int32*)placeholder_12[((((blockIdx.y*64) + (threadIdx.y*8)) + (ax1.inner.inner.inner*4)) + ax4)]), 2147416796, 31, 0, dtype=int32) + (int32*)placeholder_13[((((blockIdx.y*64) + (threadIdx.y*8)) + (ax1.inner.inner.inner*4)) + ax4)]), 1467685356, 31, 0, dtype=int32) + @tir.q_multiply_shift((int32*)placeholder_11[(((((((blockIdx.z*401408) + (blockIdx.y*50176)) + (threadIdx.y*6272)) + (ax1.inner.inner.inner*3136)) + (blockIdx.x*448)) + (threadIdx.x*4)) + ax4)], 2136391595, 31, 0, dtype=int32)), 0)
        T_relu_2[((((((((blockIdx.z*401408) + (blockIdx.y*50176)) + (threadIdx.y*6272)) + (ax1.inner.inner.inner*3136)) + (blockIdx.x*448)) + (threadIdx.x*4)) + ax4) + 25088)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(((ax1.inner.inner.inner*4) + ax4) + 16)], 1268844533, 31, 18, dtype=int32) + (int32*)placeholder_12[(((((blockIdx.y*64) + (threadIdx.y*8)) + (ax1.inner.inner.inner*4)) + ax4) + 32)]), 2147416796, 31, 0, dtype=int32) + (int32*)placeholder_13[(((((blockIdx.y*64) + (threadIdx.y*8)) + (ax1.inner.inner.inner*4)) + ax4) + 32)]), 1467685356, 31, 0, dtype=int32) + @tir.q_multiply_shift((int32*)placeholder_11[((((((((blockIdx.z*401408) + (blockIdx.y*50176)) + (threadIdx.y*6272)) + (ax1.inner.inner.inner*3136)) + (blockIdx.x*448)) + (threadIdx.x*4)) + ax4) + 25088)], 2136391595, 31, 0, dtype=int32)), 0)
        T_relu_2[((((((((blockIdx.z*401408) + (blockIdx.y*50176)) + (threadIdx.y*6272)) + (ax1.inner.inner.inner*3136)) + (blockIdx.x*448)) + (threadIdx.x*4)) + ax4) + 224)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(((ax1.inner.inner.inner*4) + ax4) + 8)], 1268844533, 31, 18, dtype=int32) + (int32*)placeholder_12[((((blockIdx.y*64) + (threadIdx.y*8)) + (ax1.inner.inner.inner*4)) + ax4)]), 2147416796, 31, 0, dtype=int32) + (int32*)placeholder_13[((((blockIdx.y*64) + (threadIdx.y*8)) + (ax1.inner.inner.inner*4)) + ax4)]), 1467685356, 31, 0, dtype=int32) + @tir.q_multiply_shift((int32*)placeholder_11[((((((((blockIdx.z*401408) + (blockIdx.y*50176)) + (threadIdx.y*6272)) + (ax1.inner.inner.inner*3136)) + (blockIdx.x*448)) + (threadIdx.x*4)) + ax4) + 224)], 2136391595, 31, 0, dtype=int32)), 0)
        T_relu_2[((((((((blockIdx.z*401408) + (blockIdx.y*50176)) + (threadIdx.y*6272)) + (ax1.inner.inner.inner*3136)) + (blockIdx.x*448)) + (threadIdx.x*4)) + ax4) + 25312)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(((ax1.inner.inner.inner*4) + ax4) + 24)], 1268844533, 31, 18, dtype=int32) + (int32*)placeholder_12[(((((blockIdx.y*64) + (threadIdx.y*8)) + (ax1.inner.inner.inner*4)) + ax4) + 32)]), 2147416796, 31, 0, dtype=int32) + (int32*)placeholder_13[(((((blockIdx.y*64) + (threadIdx.y*8)) + (ax1.inner.inner.inner*4)) + ax4) + 32)]), 1467685356, 31, 0, dtype=int32) + @tir.q_multiply_shift((int32*)placeholder_11[((((((((blockIdx.z*401408) + (blockIdx.y*50176)) + (threadIdx.y*6272)) + (ax1.inner.inner.inner*3136)) + (blockIdx.x*448)) + (threadIdx.x*4)) + ax4) + 25312)], 2136391595, 31, 0, dtype=int32)), 0)
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_nn_relu_cast_fixed_point_mult_18399029763786111876__10", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [32, 32, 28, 28, 4], []),
             placeholder_2: Buffer(placeholder_6: handle, int32, [1, 32, 1, 1, 4], []),
             placeholder: Buffer(placeholder_7: handle, int8, [32, 32, 28, 28, 4], []),
             placeholder_1: Buffer(placeholder_8: handle, int8, [32, 32, 3, 3, 4, 4], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 16;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [16]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [288]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [2304]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 2;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 49;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4 {
    for (oh.init: int32, 0, 2) "unroll" {
      for (oc_block.init: int32, 0, 4) "unroll" {
        compute[((oh.init*4) + oc_block.init)] = 0
        compute[(((oh.init*4) + oc_block.init) + 8)] = 0
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 2) "unroll" {
      attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
      attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
      if (((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1) < 144) {
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*32) + (threadIdx.z_1*16)) + threadIdx.y_1) < 36) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*2) + threadIdx.z_1) < 3) {
            pad_data.shared[ramp(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*512) + (threadIdx.z_1*256)) + (threadIdx.y_1*16)) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((1 <= ((floordiv(blockIdx.x, 7)*4) + floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 36), 6))) && (((floordiv(blockIdx.x, 7)*4) + floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 36), 6)) < 29)) && (1 <= ((floormod(blockIdx.x, 7)*4) + floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 6)))) && (((floormod(blockIdx.x, 7)*4) + floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 6)) < 29)), (int8x4*)placeholder_7[ramp(((((((((blockIdx.z*200704) + (floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 72)*100352)) + (floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 72), 36)*3136)) + (floordiv(blockIdx.x, 7)*448)) + (floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 36), 6)*112)) + (floormod(blockIdx.x, 7)*16)) + (floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 6)*4)) - 116), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
          }
        }
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 9) "unroll" {
      attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
      attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
      attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
      placeholder.shared[ramp(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*512) + (threadIdx.z_2*256)) + (threadIdx.y_2*16)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp(((((blockIdx.y*73728) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.z_2*16)) + threadIdx.y_2), 18)*4608)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.z_2*16)) + threadIdx.y_2), 18)*16)) + (threadIdx.x_2*4)), 1, 4)]
    }
    for (ic_chunk.outer.outer: int32, 0, 15) {
      attr [pad_data.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1: int32, 0, 2) "unroll" {
        attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
        attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
        attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
        if (((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1) < 144) {
          if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*32) + (threadIdx.z_1*16)) + threadIdx.y_1) < 36) {
            if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*2) + threadIdx.z_1) < 3) {
              pad_data.shared[ramp((((((floormod((ic_chunk.outer.outer + 1), 2)*576) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*512)) + (threadIdx.z_1*256)) + (threadIdx.y_1*16)) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((1 <= ((floordiv(blockIdx.x, 7)*4) + floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 36), 6))) && (((floordiv(blockIdx.x, 7)*4) + floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 36), 6)) < 29)) && (1 <= ((floormod(blockIdx.x, 7)*4) + floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 6)))) && (((floormod(blockIdx.x, 7)*4) + floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 6)) < 29)), (int8x4*)placeholder_7[ramp((((((((((blockIdx.z*200704) + (floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 72)*100352)) + (ic_chunk.outer.outer*6272)) + (floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 72), 36)*3136)) + (floordiv(blockIdx.x, 7)*448)) + (floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 36), 6)*112)) + (floormod(blockIdx.x, 7)*16)) + (floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 6)*4)) + 6156), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
            }
          }
        }
      }
      attr [placeholder.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 9) "unroll" {
        attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
        attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
        attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
        placeholder.shared[ramp((((((floormod((ic_chunk.outer.outer + 1), 2)*4608) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*512)) + (threadIdx.z_2*256)) + (threadIdx.y_2*16)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp(((((((blockIdx.y*73728) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.z_2*16)) + threadIdx.y_2), 18)*4608)) + (ic_chunk.outer.outer*288)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.z_2*16)) + threadIdx.y_2), 18)*16)) + (threadIdx.x_2*4)) + 288), 1, 4)]
      }
      for (kw.inner: int32, 0, 3) "unroll" {
        for (ic_chunk.inner: int32, 0, 2) "unroll" {
          for (kh.inner: int32, 0, 3) "unroll" {
            for (oh: int32, 0, 2) "unroll" {
              for (oc_block: int32, 0, 4) "unroll" {
                compute[((oh*4) + oc_block)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((((floormod(ic_chunk.outer.outer, 2)*576) + (threadIdx.z*288)) + (ic_chunk.inner*144)) + (oh*24)) + (kh.inner*24)) + (threadIdx.x*4)) + (kw.inner*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((((floormod(ic_chunk.outer.outer, 2)*4608) + (threadIdx.y*288)) + (ic_chunk.inner*144)) + (kh.inner*48)) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[((oh*4) + oc_block)], dtype=int32)
                compute[(((oh*4) + oc_block) + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((((((floormod(ic_chunk.outer.outer, 2)*576) + (threadIdx.z*288)) + (ic_chunk.inner*144)) + (oh*24)) + (kh.inner*24)) + (threadIdx.x*4)) + (kw.inner*4)) + 48), 1, 4)], (int8x4*)placeholder.shared[ramp(((((((floormod(ic_chunk.outer.outer, 2)*4608) + (threadIdx.y*288)) + (ic_chunk.inner*144)) + (kh.inner*48)) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(((oh*4) + oc_block) + 8)], dtype=int32)
              }
            }
          }
        }
      }
    }
    for (kw.inner_1: int32, 0, 3) "unroll" {
      for (ic_chunk.inner_1: int32, 0, 2) "unroll" {
        for (kh.inner_1: int32, 0, 3) "unroll" {
          for (oh_1: int32, 0, 2) "unroll" {
            for (oc_block_1: int32, 0, 4) "unroll" {
              compute[((oh_1*4) + oc_block_1)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((((threadIdx.z*288) + (ic_chunk.inner_1*144)) + (oh_1*24)) + (kh.inner_1*24)) + (threadIdx.x*4)) + (kw.inner_1*4)) + 576), 1, 4)], (int8x4*)placeholder.shared[ramp(((((((threadIdx.y*288) + (ic_chunk.inner_1*144)) + (kh.inner_1*48)) + (kw.inner_1*16)) + (oc_block_1*4)) + 4608), 1, 4)], (int32*)compute[((oh_1*4) + oc_block_1)], dtype=int32)
              compute[(((oh_1*4) + oc_block_1) + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((((threadIdx.z*288) + (ic_chunk.inner_1*144)) + (oh_1*24)) + (kh.inner_1*24)) + (threadIdx.x*4)) + (kw.inner_1*4)) + 624), 1, 4)], (int8x4*)placeholder.shared[ramp(((((((threadIdx.y*288) + (ic_chunk.inner_1*144)) + (kh.inner_1*48)) + (kw.inner_1*16)) + (oc_block_1*4)) + 4608), 1, 4)], (int32*)compute[(((oh_1*4) + oc_block_1) + 8)], dtype=int32)
            }
          }
        }
      }
    }
    for (ax2.inner.inner.inner: int32, 0, 2) "unroll" {
      for (ax4: int32, 0, 4) "unroll" {
        T_cast_2[(((((((((blockIdx.z*200704) + (threadIdx.z*100352)) + (blockIdx.y*50176)) + (threadIdx.y*3136)) + (floordiv(blockIdx.x, 7)*448)) + (ax2.inner.inner.inner*112)) + (floormod(blockIdx.x, 7)*16)) + (threadIdx.x*4)) + ax4)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((int32*)compute[((ax2.inner.inner.inner*4) + ax4)], 1205664363, 31, 17, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 0), 2117040281, 31, -24, dtype=int32), 127), -128))
        T_cast_2[((((((((((blockIdx.z*200704) + (threadIdx.z*100352)) + (blockIdx.y*50176)) + (threadIdx.y*3136)) + (floordiv(blockIdx.x, 7)*448)) + (ax2.inner.inner.inner*112)) + (floormod(blockIdx.x, 7)*16)) + (threadIdx.x*4)) + ax4) + 224)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((int32*)compute[(((ax2.inner.inner.inner*4) + ax4) + 8)], 1205664363, 31, 17, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 0), 2117040281, 31, -24, dtype=int32), 127), -128))
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_fixed_point_multiply_add_cast_16086763325481941859__9", "tir.noalias": True}
  buffers = {placeholder_3: Buffer(placeholder_8: handle, int32, [1, 32, 1, 1, 4], []),
             placeholder_2: Buffer(placeholder_9: handle, int8, [32, 128, 1, 1, 4, 4], []),
             T_cast: Buffer(T_cast_2: handle, int8, [32, 32, 28, 28, 4], []),
             placeholder: Buffer(placeholder_10: handle, int32, [1, 32, 1, 1, 4], []),
             placeholder_1: Buffer(placeholder_11: handle, int8, [32, 128, 28, 28, 4], [])}
  buffer_map = {placeholder_6: placeholder, placeholder_4: placeholder_1, T_cast_1: T_cast, placeholder_5: placeholder_2, placeholder_7: placeholder_3} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 32;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [28]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [896]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [1024]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 2;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 14;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 16;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 2;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4 {
    for (oc_block.init: int32, 0, 4) "unroll" {
      compute[oc_block.init] = 0
      compute[(oc_block.init + 4)] = 0
      compute[(oc_block.init + 8)] = 0
      compute[(oc_block.init + 12)] = 0
      compute[(oc_block.init + 16)] = 0
      compute[(oc_block.init + 20)] = 0
      compute[(oc_block.init + 24)] = 0
    }
    for (ic_chunk.outer: int32, 0, 8) {
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 7) "unroll" {
        attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 16;
        attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 2;
        attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
        pad_data.shared[ramp(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*512) + (threadIdx.z_1*32)) + (threadIdx.y_1*16)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_11[ramp((((((blockIdx.z*401408) + (ic_chunk.outer*50176)) + (floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*8)) + (threadIdx.y_1*4)) + threadIdx.x_1), 56)*3136)) + (blockIdx.x*224)) + (floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*8)) + (threadIdx.y_1*4)) + threadIdx.x_1), 56)*4)), 1, 4)]
      }
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 8) "unroll" {
        attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 16;
        attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 2;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
        placeholder.shared[ramp(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*512) + (threadIdx.z_2*32)) + (threadIdx.y_2*16)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_9[ramp(((((((blockIdx.y*32768) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*4096)) + (floordiv(((threadIdx.z_2*2) + threadIdx.y_2), 16)*2048)) + (ic_chunk.outer*256)) + (floormod(((threadIdx.z_2*2) + threadIdx.y_2), 16)*16)) + (threadIdx.x_2*4)), 1, 4)]
      }
      for (ic_chunk.inner: int32, 0, 16) "unroll" {
        for (oc_block: int32, 0, 4) "unroll" {
          compute[oc_block] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*224) + (threadIdx.y*112)) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*256) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[oc_block], dtype=int32)
          compute[(oc_block + 4)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((ic_chunk.inner*224) + (threadIdx.y*112)) + (threadIdx.x*4)) + 16), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*256) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 4)], dtype=int32)
          compute[(oc_block + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((ic_chunk.inner*224) + (threadIdx.y*112)) + (threadIdx.x*4)) + 32), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*256) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 8)], dtype=int32)
          compute[(oc_block + 12)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((ic_chunk.inner*224) + (threadIdx.y*112)) + (threadIdx.x*4)) + 48), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*256) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 12)], dtype=int32)
          compute[(oc_block + 16)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((ic_chunk.inner*224) + (threadIdx.y*112)) + (threadIdx.x*4)) + 64), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*256) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 16)], dtype=int32)
          compute[(oc_block + 20)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((ic_chunk.inner*224) + (threadIdx.y*112)) + (threadIdx.x*4)) + 80), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*256) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 20)], dtype=int32)
          compute[(oc_block + 24)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((ic_chunk.inner*224) + (threadIdx.y*112)) + (threadIdx.x*4)) + 96), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*256) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 24)], dtype=int32)
        }
      }
    }
    for (ax4: int32, 0, 4) "unroll" {
      T_cast_2[(((((((blockIdx.z*100352) + (blockIdx.y*50176)) + (threadIdx.z*3136)) + (blockIdx.x*224)) + (threadIdx.y*112)) + (threadIdx.x*4)) + ax4)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[ax4], 1442894291, 31, 17, dtype=int32) + (int32*)placeholder_10[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 2147471922, 31, 0, dtype=int32) + (int32*)placeholder_8[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 0), 1095017033, 31, -23, dtype=int32), 127), -128))
      T_cast_2[((((((((blockIdx.z*100352) + (blockIdx.y*50176)) + (threadIdx.z*3136)) + (blockIdx.x*224)) + (threadIdx.y*112)) + (threadIdx.x*4)) + ax4) + 16)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 4)], 1442894291, 31, 17, dtype=int32) + (int32*)placeholder_10[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 2147471922, 31, 0, dtype=int32) + (int32*)placeholder_8[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 0), 1095017033, 31, -23, dtype=int32), 127), -128))
      T_cast_2[((((((((blockIdx.z*100352) + (blockIdx.y*50176)) + (threadIdx.z*3136)) + (blockIdx.x*224)) + (threadIdx.y*112)) + (threadIdx.x*4)) + ax4) + 32)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 8)], 1442894291, 31, 17, dtype=int32) + (int32*)placeholder_10[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 2147471922, 31, 0, dtype=int32) + (int32*)placeholder_8[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 0), 1095017033, 31, -23, dtype=int32), 127), -128))
      T_cast_2[((((((((blockIdx.z*100352) + (blockIdx.y*50176)) + (threadIdx.z*3136)) + (blockIdx.x*224)) + (threadIdx.y*112)) + (threadIdx.x*4)) + ax4) + 48)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 12)], 1442894291, 31, 17, dtype=int32) + (int32*)placeholder_10[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 2147471922, 31, 0, dtype=int32) + (int32*)placeholder_8[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 0), 1095017033, 31, -23, dtype=int32), 127), -128))
      T_cast_2[((((((((blockIdx.z*100352) + (blockIdx.y*50176)) + (threadIdx.z*3136)) + (blockIdx.x*224)) + (threadIdx.y*112)) + (threadIdx.x*4)) + ax4) + 64)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 16)], 1442894291, 31, 17, dtype=int32) + (int32*)placeholder_10[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 2147471922, 31, 0, dtype=int32) + (int32*)placeholder_8[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 0), 1095017033, 31, -23, dtype=int32), 127), -128))
      T_cast_2[((((((((blockIdx.z*100352) + (blockIdx.y*50176)) + (threadIdx.z*3136)) + (blockIdx.x*224)) + (threadIdx.y*112)) + (threadIdx.x*4)) + ax4) + 80)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 20)], 1442894291, 31, 17, dtype=int32) + (int32*)placeholder_10[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 2147471922, 31, 0, dtype=int32) + (int32*)placeholder_8[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 0), 1095017033, 31, -23, dtype=int32), 127), -128))
      T_cast_2[((((((((blockIdx.z*100352) + (blockIdx.y*50176)) + (threadIdx.z*3136)) + (blockIdx.x*224)) + (threadIdx.y*112)) + (threadIdx.x*4)) + ax4) + 96)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 24)], 1442894291, 31, 17, dtype=int32) + (int32*)placeholder_10[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 2147471922, 31, 0, dtype=int32) + (int32*)placeholder_8[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 0), 1095017033, 31, -23, dtype=int32), 127), -128))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_fixed_point_multiply_clip_cast_10", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [32, 128, 28, 28, 4], []),
             placeholder: Buffer(placeholder_2: handle, int32, [32, 128, 28, 28, 4], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer: int32, 0, 49) {
    T_cast_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = cast(int8, max(min(@tir.q_multiply_shift((int32*)placeholder_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)], 2136391595, 31, -24, dtype=int32), 127), -128))
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
primfn(placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, placeholder_8: handle, placeholder_9: handle, T_relu_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_fixed_point_multiply_add_cast_15119380522063600768__8", "tir.noalias": True}
  buffers = {placeholder_4: Buffer(placeholder_10: handle, int8, [32, 32, 28, 28, 4], []),
             placeholder: Buffer(placeholder_11: handle, int32, [1, 128, 1, 1, 4], []),
             placeholder_1: Buffer(placeholder_12: handle, int32, [32, 128, 28, 28, 4], []),
             placeholder_2: Buffer(placeholder_13: handle, int8, [128, 32, 1, 1, 4, 4], []),
             T_relu: Buffer(T_relu_2: handle, int32, [32, 128, 28, 28, 4], []),
             placeholder_3: Buffer(placeholder_14: handle, int32, [1, 128, 1, 1, 4], [])}
  buffer_map = {T_relu_1: T_relu, placeholder_8: placeholder, placeholder_9: placeholder_1, placeholder_6: placeholder_2, placeholder_7: placeholder_3, placeholder_5: placeholder_4} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 32;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [32]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [3584]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [1024]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 8;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 7;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 4;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 56 {
    for (oc_chunk.init: int32, 0, 2) "unroll" {
      for (oc_block.init: int32, 0, 4) "unroll" {
        compute[((oc_chunk.init*4) + oc_block.init)] = 0
        compute[(((oc_chunk.init*4) + oc_block.init) + 16)] = 0
        compute[(((oc_chunk.init*4) + oc_block.init) + 8)] = 0
        compute[(((oc_chunk.init*4) + oc_block.init) + 24)] = 0
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 8) "unroll" {
      attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 4;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 56;
      pad_data.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*896) + (((threadIdx.y_1*2) + floordiv(threadIdx.x_1, 28))*112)) + (floormod(threadIdx.x_1, 28)*4)), 1, 4)] = (int8x4*)placeholder_10[ramp(((((((blockIdx.z*100352) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*6272)) + (floordiv(((threadIdx.y_1*2) + floordiv(threadIdx.x_1, 28)), 4)*3136)) + (blockIdx.x*448)) + (floormod(((threadIdx.y_1*2) + floordiv(threadIdx.x_1, 28)), 4)*112)) + (floormod(threadIdx.x_1, 28)*4)), 1, 4)]
    }
    for (ic_chunk.outer.outer: int32, 0, 1) "unroll" {
      attr [pad_data.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1: int32, 0, 8) "unroll" {
        attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 4;
        attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 56;
        pad_data.shared[ramp(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*896) + (((threadIdx.y_1*2) + floordiv(threadIdx.x_1, 28))*112)) + (floormod(threadIdx.x_1, 28)*4)) + 7168), 1, 4)] = (int8x4*)placeholder_10[ramp((((((((blockIdx.z*100352) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*6272)) + (floordiv(((threadIdx.y_1*2) + floordiv(threadIdx.x_1, 28)), 4)*3136)) + (blockIdx.x*448)) + (floormod(((threadIdx.y_1*2) + floordiv(threadIdx.x_1, 28)), 4)*112)) + (floormod(threadIdx.x_1, 28)*4)) + 50176), 1, 4)]
      }
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 5) "unroll" {
        attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 4;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 56;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.y_2*14)) + floordiv(threadIdx.x_2, 4)) < 256) {
          if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*224) + (threadIdx.y_2*56)) + threadIdx.x_2) < 1024) {
            if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*4) + threadIdx.y_2) < 19) {
              placeholder.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*896) + (threadIdx.y_2*224)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_13[ramp(((((blockIdx.y*8192) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.y_2*14)) + floordiv(threadIdx.x_2, 4)), 16)*512)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.y_2*14)) + floordiv(threadIdx.x_2, 4)), 16)*16)) + (floormod(threadIdx.x_2, 4)*4)), 1, 4)]
            }
          }
        }
      }
      for (ic_chunk.inner: int32, 0, 16) "unroll" {
        for (oc_chunk: int32, 0, 2) "unroll" {
          for (oc_block: int32, 0, 4) "unroll" {
            compute[((oc_chunk*4) + oc_block)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((ic_chunk.inner*448) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*512) + (oc_chunk*256)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[((oc_chunk*4) + oc_block)], dtype=int32)
            compute[(((oc_chunk*4) + oc_block) + 16)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((ic_chunk.inner*448) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp((((((threadIdx.y*512) + (oc_chunk*256)) + (ic_chunk.inner*16)) + (oc_block*4)) + 2048), 1, 4)], (int32*)compute[(((oc_chunk*4) + oc_block) + 16)], dtype=int32)
            compute[(((oc_chunk*4) + oc_block) + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*448) + (threadIdx.x*4)) + 224), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*512) + (oc_chunk*256)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(((oc_chunk*4) + oc_block) + 8)], dtype=int32)
            compute[(((oc_chunk*4) + oc_block) + 24)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*448) + (threadIdx.x*4)) + 224), 1, 4)], (int8x4*)placeholder.shared[ramp((((((threadIdx.y*512) + (oc_chunk*256)) + (ic_chunk.inner*16)) + (oc_block*4)) + 2048), 1, 4)], (int32*)compute[(((oc_chunk*4) + oc_block) + 24)], dtype=int32)
          }
        }
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 5) "unroll" {
      attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 4;
      attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 56;
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.y_2*14)) + floordiv(threadIdx.x_2, 4)) < 256) {
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*224) + (threadIdx.y_2*56)) + threadIdx.x_2) < 1024) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*4) + threadIdx.y_2) < 19) {
            placeholder.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*896) + (threadIdx.y_2*224)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_13[ramp((((((blockIdx.y*8192) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.y_2*14)) + floordiv(threadIdx.x_2, 4)), 16)*512)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.y_2*14)) + floordiv(threadIdx.x_2, 4)), 16)*16)) + (floormod(threadIdx.x_2, 4)*4)) + 256), 1, 4)]
          }
        }
      }
    }
    for (ic_chunk.inner_1: int32, 0, 16) "unroll" {
      for (oc_chunk_1: int32, 0, 2) "unroll" {
        for (oc_block_1: int32, 0, 4) "unroll" {
          compute[((oc_chunk_1*4) + oc_block_1)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner_1*448) + (threadIdx.x*4)) + 7168), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*512) + (oc_chunk_1*256)) + (ic_chunk.inner_1*16)) + (oc_block_1*4)), 1, 4)], (int32*)compute[((oc_chunk_1*4) + oc_block_1)], dtype=int32)
          compute[(((oc_chunk_1*4) + oc_block_1) + 16)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner_1*448) + (threadIdx.x*4)) + 7168), 1, 4)], (int8x4*)placeholder.shared[ramp((((((threadIdx.y*512) + (oc_chunk_1*256)) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 2048), 1, 4)], (int32*)compute[(((oc_chunk_1*4) + oc_block_1) + 16)], dtype=int32)
          compute[(((oc_chunk_1*4) + oc_block_1) + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner_1*448) + (threadIdx.x*4)) + 7392), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*512) + (oc_chunk_1*256)) + (ic_chunk.inner_1*16)) + (oc_block_1*4)), 1, 4)], (int32*)compute[(((oc_chunk_1*4) + oc_block_1) + 8)], dtype=int32)
          compute[(((oc_chunk_1*4) + oc_block_1) + 24)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner_1*448) + (threadIdx.x*4)) + 7392), 1, 4)], (int8x4*)placeholder.shared[ramp((((((threadIdx.y*512) + (oc_chunk_1*256)) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 2048), 1, 4)], (int32*)compute[(((oc_chunk_1*4) + oc_block_1) + 24)], dtype=int32)
        }
      }
    }
    for (ax1.inner.inner.inner: int32, 0, 2) "unroll" {
      for (ax4: int32, 0, 4) "unroll" {
        T_relu_2[(((((((blockIdx.z*401408) + (blockIdx.y*50176)) + (threadIdx.y*6272)) + (ax1.inner.inner.inner*3136)) + (blockIdx.x*448)) + (threadIdx.x*4)) + ax4)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[((ax1.inner.inner.inner*4) + ax4)], 1779395009, 31, 17, dtype=int32) + (int32*)placeholder_14[((((blockIdx.y*64) + (threadIdx.y*8)) + (ax1.inner.inner.inner*4)) + ax4)]), 2147386978, 31, 0, dtype=int32) + (int32*)placeholder_11[((((blockIdx.y*64) + (threadIdx.y*8)) + (ax1.inner.inner.inner*4)) + ax4)]), 1440775746, 31, 0, dtype=int32) + @tir.q_multiply_shift((int32*)placeholder_12[(((((((blockIdx.z*401408) + (blockIdx.y*50176)) + (threadIdx.y*6272)) + (ax1.inner.inner.inner*3136)) + (blockIdx.x*448)) + (threadIdx.x*4)) + ax4)], 2059568007, 31, 0, dtype=int32)), 0)
        T_relu_2[((((((((blockIdx.z*401408) + (blockIdx.y*50176)) + (threadIdx.y*6272)) + (ax1.inner.inner.inner*3136)) + (blockIdx.x*448)) + (threadIdx.x*4)) + ax4) + 25088)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(((ax1.inner.inner.inner*4) + ax4) + 16)], 1779395009, 31, 17, dtype=int32) + (int32*)placeholder_14[(((((blockIdx.y*64) + (threadIdx.y*8)) + (ax1.inner.inner.inner*4)) + ax4) + 32)]), 2147386978, 31, 0, dtype=int32) + (int32*)placeholder_11[(((((blockIdx.y*64) + (threadIdx.y*8)) + (ax1.inner.inner.inner*4)) + ax4) + 32)]), 1440775746, 31, 0, dtype=int32) + @tir.q_multiply_shift((int32*)placeholder_12[((((((((blockIdx.z*401408) + (blockIdx.y*50176)) + (threadIdx.y*6272)) + (ax1.inner.inner.inner*3136)) + (blockIdx.x*448)) + (threadIdx.x*4)) + ax4) + 25088)], 2059568007, 31, 0, dtype=int32)), 0)
        T_relu_2[((((((((blockIdx.z*401408) + (blockIdx.y*50176)) + (threadIdx.y*6272)) + (ax1.inner.inner.inner*3136)) + (blockIdx.x*448)) + (threadIdx.x*4)) + ax4) + 224)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(((ax1.inner.inner.inner*4) + ax4) + 8)], 1779395009, 31, 17, dtype=int32) + (int32*)placeholder_14[((((blockIdx.y*64) + (threadIdx.y*8)) + (ax1.inner.inner.inner*4)) + ax4)]), 2147386978, 31, 0, dtype=int32) + (int32*)placeholder_11[((((blockIdx.y*64) + (threadIdx.y*8)) + (ax1.inner.inner.inner*4)) + ax4)]), 1440775746, 31, 0, dtype=int32) + @tir.q_multiply_shift((int32*)placeholder_12[((((((((blockIdx.z*401408) + (blockIdx.y*50176)) + (threadIdx.y*6272)) + (ax1.inner.inner.inner*3136)) + (blockIdx.x*448)) + (threadIdx.x*4)) + ax4) + 224)], 2059568007, 31, 0, dtype=int32)), 0)
        T_relu_2[((((((((blockIdx.z*401408) + (blockIdx.y*50176)) + (threadIdx.y*6272)) + (ax1.inner.inner.inner*3136)) + (blockIdx.x*448)) + (threadIdx.x*4)) + ax4) + 25312)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(((ax1.inner.inner.inner*4) + ax4) + 24)], 1779395009, 31, 17, dtype=int32) + (int32*)placeholder_14[(((((blockIdx.y*64) + (threadIdx.y*8)) + (ax1.inner.inner.inner*4)) + ax4) + 32)]), 2147386978, 31, 0, dtype=int32) + (int32*)placeholder_11[(((((blockIdx.y*64) + (threadIdx.y*8)) + (ax1.inner.inner.inner*4)) + ax4) + 32)]), 1440775746, 31, 0, dtype=int32) + @tir.q_multiply_shift((int32*)placeholder_12[((((((((blockIdx.z*401408) + (blockIdx.y*50176)) + (threadIdx.y*6272)) + (ax1.inner.inner.inner*3136)) + (blockIdx.x*448)) + (threadIdx.x*4)) + ax4) + 25312)], 2059568007, 31, 0, dtype=int32)), 0)
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_nn_relu_cast_fixed_point_mult_18399029763786111876__11", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [32, 32, 28, 28, 4], []),
             placeholder_2: Buffer(placeholder_6: handle, int32, [1, 32, 1, 1, 4], []),
             placeholder: Buffer(placeholder_7: handle, int8, [32, 32, 28, 28, 4], []),
             placeholder_1: Buffer(placeholder_8: handle, int8, [32, 32, 3, 3, 4, 4], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 16;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [16]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [288]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [2304]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 2;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 49;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4 {
    for (oh.init: int32, 0, 2) "unroll" {
      for (oc_block.init: int32, 0, 4) "unroll" {
        compute[((oh.init*4) + oc_block.init)] = 0
        compute[(((oh.init*4) + oc_block.init) + 8)] = 0
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 2) "unroll" {
      attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
      attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
      if (((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1) < 144) {
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*32) + (threadIdx.z_1*16)) + threadIdx.y_1) < 36) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*2) + threadIdx.z_1) < 3) {
            pad_data.shared[ramp(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*512) + (threadIdx.z_1*256)) + (threadIdx.y_1*16)) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((1 <= ((floordiv(blockIdx.x, 7)*4) + floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 36), 6))) && (((floordiv(blockIdx.x, 7)*4) + floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 36), 6)) < 29)) && (1 <= ((floormod(blockIdx.x, 7)*4) + floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 6)))) && (((floormod(blockIdx.x, 7)*4) + floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 6)) < 29)), (int8x4*)placeholder_7[ramp(((((((((blockIdx.z*200704) + (floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 72)*100352)) + (floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 72), 36)*3136)) + (floordiv(blockIdx.x, 7)*448)) + (floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 36), 6)*112)) + (floormod(blockIdx.x, 7)*16)) + (floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 6)*4)) - 116), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
          }
        }
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 9) "unroll" {
      attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
      attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
      attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
      placeholder.shared[ramp(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*512) + (threadIdx.z_2*256)) + (threadIdx.y_2*16)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp(((((blockIdx.y*73728) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.z_2*16)) + threadIdx.y_2), 18)*4608)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.z_2*16)) + threadIdx.y_2), 18)*16)) + (threadIdx.x_2*4)), 1, 4)]
    }
    for (ic_chunk.outer.outer: int32, 0, 15) {
      attr [pad_data.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1: int32, 0, 2) "unroll" {
        attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
        attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
        attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
        if (((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1) < 144) {
          if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*32) + (threadIdx.z_1*16)) + threadIdx.y_1) < 36) {
            if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*2) + threadIdx.z_1) < 3) {
              pad_data.shared[ramp((((((floormod((ic_chunk.outer.outer + 1), 2)*576) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*512)) + (threadIdx.z_1*256)) + (threadIdx.y_1*16)) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((1 <= ((floordiv(blockIdx.x, 7)*4) + floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 36), 6))) && (((floordiv(blockIdx.x, 7)*4) + floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 36), 6)) < 29)) && (1 <= ((floormod(blockIdx.x, 7)*4) + floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 6)))) && (((floormod(blockIdx.x, 7)*4) + floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 6)) < 29)), (int8x4*)placeholder_7[ramp((((((((((blockIdx.z*200704) + (floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 72)*100352)) + (ic_chunk.outer.outer*6272)) + (floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 72), 36)*3136)) + (floordiv(blockIdx.x, 7)*448)) + (floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 36), 6)*112)) + (floormod(blockIdx.x, 7)*16)) + (floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 6)*4)) + 6156), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
            }
          }
        }
      }
      attr [placeholder.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 9) "unroll" {
        attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
        attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
        attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
        placeholder.shared[ramp((((((floormod((ic_chunk.outer.outer + 1), 2)*4608) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*512)) + (threadIdx.z_2*256)) + (threadIdx.y_2*16)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp(((((((blockIdx.y*73728) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.z_2*16)) + threadIdx.y_2), 18)*4608)) + (ic_chunk.outer.outer*288)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.z_2*16)) + threadIdx.y_2), 18)*16)) + (threadIdx.x_2*4)) + 288), 1, 4)]
      }
      for (kw.inner: int32, 0, 3) "unroll" {
        for (ic_chunk.inner: int32, 0, 2) "unroll" {
          for (kh.inner: int32, 0, 3) "unroll" {
            for (oh: int32, 0, 2) "unroll" {
              for (oc_block: int32, 0, 4) "unroll" {
                compute[((oh*4) + oc_block)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((((floormod(ic_chunk.outer.outer, 2)*576) + (threadIdx.z*288)) + (ic_chunk.inner*144)) + (oh*24)) + (kh.inner*24)) + (threadIdx.x*4)) + (kw.inner*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((((floormod(ic_chunk.outer.outer, 2)*4608) + (threadIdx.y*288)) + (ic_chunk.inner*144)) + (kh.inner*48)) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[((oh*4) + oc_block)], dtype=int32)
                compute[(((oh*4) + oc_block) + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((((((floormod(ic_chunk.outer.outer, 2)*576) + (threadIdx.z*288)) + (ic_chunk.inner*144)) + (oh*24)) + (kh.inner*24)) + (threadIdx.x*4)) + (kw.inner*4)) + 48), 1, 4)], (int8x4*)placeholder.shared[ramp(((((((floormod(ic_chunk.outer.outer, 2)*4608) + (threadIdx.y*288)) + (ic_chunk.inner*144)) + (kh.inner*48)) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(((oh*4) + oc_block) + 8)], dtype=int32)
              }
            }
          }
        }
      }
    }
    for (kw.inner_1: int32, 0, 3) "unroll" {
      for (ic_chunk.inner_1: int32, 0, 2) "unroll" {
        for (kh.inner_1: int32, 0, 3) "unroll" {
          for (oh_1: int32, 0, 2) "unroll" {
            for (oc_block_1: int32, 0, 4) "unroll" {
              compute[((oh_1*4) + oc_block_1)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((((threadIdx.z*288) + (ic_chunk.inner_1*144)) + (oh_1*24)) + (kh.inner_1*24)) + (threadIdx.x*4)) + (kw.inner_1*4)) + 576), 1, 4)], (int8x4*)placeholder.shared[ramp(((((((threadIdx.y*288) + (ic_chunk.inner_1*144)) + (kh.inner_1*48)) + (kw.inner_1*16)) + (oc_block_1*4)) + 4608), 1, 4)], (int32*)compute[((oh_1*4) + oc_block_1)], dtype=int32)
              compute[(((oh_1*4) + oc_block_1) + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((((threadIdx.z*288) + (ic_chunk.inner_1*144)) + (oh_1*24)) + (kh.inner_1*24)) + (threadIdx.x*4)) + (kw.inner_1*4)) + 624), 1, 4)], (int8x4*)placeholder.shared[ramp(((((((threadIdx.y*288) + (ic_chunk.inner_1*144)) + (kh.inner_1*48)) + (kw.inner_1*16)) + (oc_block_1*4)) + 4608), 1, 4)], (int32*)compute[(((oh_1*4) + oc_block_1) + 8)], dtype=int32)
            }
          }
        }
      }
    }
    for (ax2.inner.inner.inner: int32, 0, 2) "unroll" {
      for (ax4: int32, 0, 4) "unroll" {
        T_cast_2[(((((((((blockIdx.z*200704) + (threadIdx.z*100352)) + (blockIdx.y*50176)) + (threadIdx.y*3136)) + (floordiv(blockIdx.x, 7)*448)) + (ax2.inner.inner.inner*112)) + (floormod(blockIdx.x, 7)*16)) + (threadIdx.x*4)) + ax4)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((int32*)compute[((ax2.inner.inner.inner*4) + ax4)], 1818067853, 31, 16, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 0), 1398390528, 31, -23, dtype=int32), 127), -128))
        T_cast_2[((((((((((blockIdx.z*200704) + (threadIdx.z*100352)) + (blockIdx.y*50176)) + (threadIdx.y*3136)) + (floordiv(blockIdx.x, 7)*448)) + (ax2.inner.inner.inner*112)) + (floormod(blockIdx.x, 7)*16)) + (threadIdx.x*4)) + ax4) + 224)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((int32*)compute[(((ax2.inner.inner.inner*4) + ax4) + 8)], 1818067853, 31, 16, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 0), 1398390528, 31, -23, dtype=int32), 127), -128))
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_fixed_point_multiply_add_cast_16086763325481941859__10", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [32, 32, 28, 28, 4], []),
             placeholder_2: Buffer(placeholder_8: handle, int32, [1, 32, 1, 1, 4], []),
             placeholder: Buffer(placeholder_9: handle, int8, [32, 128, 1, 1, 4, 4], []),
             placeholder_3: Buffer(placeholder_10: handle, int8, [32, 128, 28, 28, 4], []),
             placeholder_1: Buffer(placeholder_11: handle, int32, [1, 32, 1, 1, 4], [])}
  buffer_map = {placeholder_5: placeholder, placeholder_6: placeholder_1, placeholder_7: placeholder_2, T_cast_1: T_cast, placeholder_4: placeholder_3} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 32;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [28]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [896]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [1024]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 2;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 14;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 16;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 2;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4 {
    for (oc_block.init: int32, 0, 4) "unroll" {
      compute[oc_block.init] = 0
      compute[(oc_block.init + 4)] = 0
      compute[(oc_block.init + 8)] = 0
      compute[(oc_block.init + 12)] = 0
      compute[(oc_block.init + 16)] = 0
      compute[(oc_block.init + 20)] = 0
      compute[(oc_block.init + 24)] = 0
    }
    for (ic_chunk.outer: int32, 0, 8) {
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 7) "unroll" {
        attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 16;
        attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 2;
        attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
        pad_data.shared[ramp(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*512) + (threadIdx.z_1*32)) + (threadIdx.y_1*16)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_10[ramp((((((blockIdx.z*401408) + (ic_chunk.outer*50176)) + (floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*8)) + (threadIdx.y_1*4)) + threadIdx.x_1), 56)*3136)) + (blockIdx.x*224)) + (floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*8)) + (threadIdx.y_1*4)) + threadIdx.x_1), 56)*4)), 1, 4)]
      }
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 8) "unroll" {
        attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 16;
        attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 2;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
        placeholder.shared[ramp(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*512) + (threadIdx.z_2*32)) + (threadIdx.y_2*16)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_9[ramp(((((((blockIdx.y*32768) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*4096)) + (floordiv(((threadIdx.z_2*2) + threadIdx.y_2), 16)*2048)) + (ic_chunk.outer*256)) + (floormod(((threadIdx.z_2*2) + threadIdx.y_2), 16)*16)) + (threadIdx.x_2*4)), 1, 4)]
      }
      for (ic_chunk.inner: int32, 0, 16) "unroll" {
        for (oc_block: int32, 0, 4) "unroll" {
          compute[oc_block] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*224) + (threadIdx.y*112)) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*256) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[oc_block], dtype=int32)
          compute[(oc_block + 4)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((ic_chunk.inner*224) + (threadIdx.y*112)) + (threadIdx.x*4)) + 16), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*256) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 4)], dtype=int32)
          compute[(oc_block + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((ic_chunk.inner*224) + (threadIdx.y*112)) + (threadIdx.x*4)) + 32), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*256) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 8)], dtype=int32)
          compute[(oc_block + 12)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((ic_chunk.inner*224) + (threadIdx.y*112)) + (threadIdx.x*4)) + 48), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*256) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 12)], dtype=int32)
          compute[(oc_block + 16)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((ic_chunk.inner*224) + (threadIdx.y*112)) + (threadIdx.x*4)) + 64), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*256) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 16)], dtype=int32)
          compute[(oc_block + 20)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((ic_chunk.inner*224) + (threadIdx.y*112)) + (threadIdx.x*4)) + 80), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*256) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 20)], dtype=int32)
          compute[(oc_block + 24)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((ic_chunk.inner*224) + (threadIdx.y*112)) + (threadIdx.x*4)) + 96), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*256) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 24)], dtype=int32)
        }
      }
    }
    for (ax4: int32, 0, 4) "unroll" {
      T_cast_2[(((((((blockIdx.z*100352) + (blockIdx.y*50176)) + (threadIdx.z*3136)) + (blockIdx.x*224)) + (threadIdx.y*112)) + (threadIdx.x*4)) + ax4)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[ax4], 1522931676, 31, 17, dtype=int32) + (int32*)placeholder_11[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 2147473483, 31, 0, dtype=int32) + (int32*)placeholder_8[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 0), 1532402649, 31, -23, dtype=int32), 127), -128))
      T_cast_2[((((((((blockIdx.z*100352) + (blockIdx.y*50176)) + (threadIdx.z*3136)) + (blockIdx.x*224)) + (threadIdx.y*112)) + (threadIdx.x*4)) + ax4) + 16)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 4)], 1522931676, 31, 17, dtype=int32) + (int32*)placeholder_11[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 2147473483, 31, 0, dtype=int32) + (int32*)placeholder_8[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 0), 1532402649, 31, -23, dtype=int32), 127), -128))
      T_cast_2[((((((((blockIdx.z*100352) + (blockIdx.y*50176)) + (threadIdx.z*3136)) + (blockIdx.x*224)) + (threadIdx.y*112)) + (threadIdx.x*4)) + ax4) + 32)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 8)], 1522931676, 31, 17, dtype=int32) + (int32*)placeholder_11[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 2147473483, 31, 0, dtype=int32) + (int32*)placeholder_8[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 0), 1532402649, 31, -23, dtype=int32), 127), -128))
      T_cast_2[((((((((blockIdx.z*100352) + (blockIdx.y*50176)) + (threadIdx.z*3136)) + (blockIdx.x*224)) + (threadIdx.y*112)) + (threadIdx.x*4)) + ax4) + 48)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 12)], 1522931676, 31, 17, dtype=int32) + (int32*)placeholder_11[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 2147473483, 31, 0, dtype=int32) + (int32*)placeholder_8[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 0), 1532402649, 31, -23, dtype=int32), 127), -128))
      T_cast_2[((((((((blockIdx.z*100352) + (blockIdx.y*50176)) + (threadIdx.z*3136)) + (blockIdx.x*224)) + (threadIdx.y*112)) + (threadIdx.x*4)) + ax4) + 64)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 16)], 1522931676, 31, 17, dtype=int32) + (int32*)placeholder_11[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 2147473483, 31, 0, dtype=int32) + (int32*)placeholder_8[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 0), 1532402649, 31, -23, dtype=int32), 127), -128))
      T_cast_2[((((((((blockIdx.z*100352) + (blockIdx.y*50176)) + (threadIdx.z*3136)) + (blockIdx.x*224)) + (threadIdx.y*112)) + (threadIdx.x*4)) + ax4) + 80)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 20)], 1522931676, 31, 17, dtype=int32) + (int32*)placeholder_11[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 2147473483, 31, 0, dtype=int32) + (int32*)placeholder_8[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 0), 1532402649, 31, -23, dtype=int32), 127), -128))
      T_cast_2[((((((((blockIdx.z*100352) + (blockIdx.y*50176)) + (threadIdx.z*3136)) + (blockIdx.x*224)) + (threadIdx.y*112)) + (threadIdx.x*4)) + ax4) + 96)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 24)], 1522931676, 31, 17, dtype=int32) + (int32*)placeholder_11[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 2147473483, 31, 0, dtype=int32) + (int32*)placeholder_8[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 0), 1532402649, 31, -23, dtype=int32), 127), -128))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_fixed_point_multiply_clip_cast_11", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [32, 128, 28, 28, 4], []),
             placeholder: Buffer(placeholder_2: handle, int32, [32, 128, 28, 28, 4], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer: int32, 0, 49) {
    T_cast_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = cast(int8, max(min(@tir.q_multiply_shift((int32*)placeholder_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)], 2059568007, 31, -24, dtype=int32), 127), -128))
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
primfn(placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, placeholder_8: handle, placeholder_9: handle, T_relu_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_fixed_point_multiply_add_cast_12402219635377536017__2", "tir.noalias": True}
  buffers = {T_relu: Buffer(T_relu_2: handle, int32, [32, 128, 28, 28, 4], []),
             placeholder_1: Buffer(placeholder_10: handle, int8, [32, 32, 28, 28, 4], []),
             placeholder: Buffer(placeholder_11: handle, int32, [32, 128, 28, 28, 4], []),
             placeholder_2: Buffer(placeholder_12: handle, int8, [128, 32, 1, 1, 4, 4], []),
             placeholder_4: Buffer(placeholder_13: handle, int32, [1, 128, 1, 1, 4], []),
             placeholder_3: Buffer(placeholder_14: handle, int32, [1, 128, 1, 1, 4], [])}
  buffer_map = {placeholder_9: placeholder, placeholder_5: placeholder_1, placeholder_6: placeholder_2, placeholder_7: placeholder_3, placeholder_8: placeholder_4, T_relu_1: T_relu} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 32;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [32]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [3584]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [1024]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 8;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 7;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 4;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 56 {
    for (oc_chunk.init: int32, 0, 2) "unroll" {
      for (oc_block.init: int32, 0, 4) "unroll" {
        compute[((oc_chunk.init*4) + oc_block.init)] = 0
        compute[(((oc_chunk.init*4) + oc_block.init) + 16)] = 0
        compute[(((oc_chunk.init*4) + oc_block.init) + 8)] = 0
        compute[(((oc_chunk.init*4) + oc_block.init) + 24)] = 0
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 8) "unroll" {
      attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 4;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 56;
      pad_data.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*896) + (((threadIdx.y_1*2) + floordiv(threadIdx.x_1, 28))*112)) + (floormod(threadIdx.x_1, 28)*4)), 1, 4)] = (int8x4*)placeholder_10[ramp(((((((blockIdx.z*100352) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*6272)) + (floordiv(((threadIdx.y_1*2) + floordiv(threadIdx.x_1, 28)), 4)*3136)) + (blockIdx.x*448)) + (floormod(((threadIdx.y_1*2) + floordiv(threadIdx.x_1, 28)), 4)*112)) + (floormod(threadIdx.x_1, 28)*4)), 1, 4)]
    }
    for (ic_chunk.outer.outer: int32, 0, 1) "unroll" {
      attr [pad_data.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1: int32, 0, 8) "unroll" {
        attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 4;
        attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 56;
        pad_data.shared[ramp(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*896) + (((threadIdx.y_1*2) + floordiv(threadIdx.x_1, 28))*112)) + (floormod(threadIdx.x_1, 28)*4)) + 7168), 1, 4)] = (int8x4*)placeholder_10[ramp((((((((blockIdx.z*100352) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*6272)) + (floordiv(((threadIdx.y_1*2) + floordiv(threadIdx.x_1, 28)), 4)*3136)) + (blockIdx.x*448)) + (floormod(((threadIdx.y_1*2) + floordiv(threadIdx.x_1, 28)), 4)*112)) + (floormod(threadIdx.x_1, 28)*4)) + 50176), 1, 4)]
      }
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 5) "unroll" {
        attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 4;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 56;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.y_2*14)) + floordiv(threadIdx.x_2, 4)) < 256) {
          if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*224) + (threadIdx.y_2*56)) + threadIdx.x_2) < 1024) {
            if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*4) + threadIdx.y_2) < 19) {
              placeholder.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*896) + (threadIdx.y_2*224)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_12[ramp(((((blockIdx.y*8192) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.y_2*14)) + floordiv(threadIdx.x_2, 4)), 16)*512)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.y_2*14)) + floordiv(threadIdx.x_2, 4)), 16)*16)) + (floormod(threadIdx.x_2, 4)*4)), 1, 4)]
            }
          }
        }
      }
      for (ic_chunk.inner: int32, 0, 16) "unroll" {
        for (oc_chunk: int32, 0, 2) "unroll" {
          for (oc_block: int32, 0, 4) "unroll" {
            compute[((oc_chunk*4) + oc_block)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((ic_chunk.inner*448) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*512) + (oc_chunk*256)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[((oc_chunk*4) + oc_block)], dtype=int32)
            compute[(((oc_chunk*4) + oc_block) + 16)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((ic_chunk.inner*448) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp((((((threadIdx.y*512) + (oc_chunk*256)) + (ic_chunk.inner*16)) + (oc_block*4)) + 2048), 1, 4)], (int32*)compute[(((oc_chunk*4) + oc_block) + 16)], dtype=int32)
            compute[(((oc_chunk*4) + oc_block) + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*448) + (threadIdx.x*4)) + 224), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*512) + (oc_chunk*256)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(((oc_chunk*4) + oc_block) + 8)], dtype=int32)
            compute[(((oc_chunk*4) + oc_block) + 24)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*448) + (threadIdx.x*4)) + 224), 1, 4)], (int8x4*)placeholder.shared[ramp((((((threadIdx.y*512) + (oc_chunk*256)) + (ic_chunk.inner*16)) + (oc_block*4)) + 2048), 1, 4)], (int32*)compute[(((oc_chunk*4) + oc_block) + 24)], dtype=int32)
          }
        }
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 5) "unroll" {
      attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 4;
      attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 56;
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.y_2*14)) + floordiv(threadIdx.x_2, 4)) < 256) {
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*224) + (threadIdx.y_2*56)) + threadIdx.x_2) < 1024) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*4) + threadIdx.y_2) < 19) {
            placeholder.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*896) + (threadIdx.y_2*224)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_12[ramp((((((blockIdx.y*8192) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.y_2*14)) + floordiv(threadIdx.x_2, 4)), 16)*512)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.y_2*14)) + floordiv(threadIdx.x_2, 4)), 16)*16)) + (floormod(threadIdx.x_2, 4)*4)) + 256), 1, 4)]
          }
        }
      }
    }
    for (ic_chunk.inner_1: int32, 0, 16) "unroll" {
      for (oc_chunk_1: int32, 0, 2) "unroll" {
        for (oc_block_1: int32, 0, 4) "unroll" {
          compute[((oc_chunk_1*4) + oc_block_1)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner_1*448) + (threadIdx.x*4)) + 7168), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*512) + (oc_chunk_1*256)) + (ic_chunk.inner_1*16)) + (oc_block_1*4)), 1, 4)], (int32*)compute[((oc_chunk_1*4) + oc_block_1)], dtype=int32)
          compute[(((oc_chunk_1*4) + oc_block_1) + 16)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner_1*448) + (threadIdx.x*4)) + 7168), 1, 4)], (int8x4*)placeholder.shared[ramp((((((threadIdx.y*512) + (oc_chunk_1*256)) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 2048), 1, 4)], (int32*)compute[(((oc_chunk_1*4) + oc_block_1) + 16)], dtype=int32)
          compute[(((oc_chunk_1*4) + oc_block_1) + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner_1*448) + (threadIdx.x*4)) + 7392), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*512) + (oc_chunk_1*256)) + (ic_chunk.inner_1*16)) + (oc_block_1*4)), 1, 4)], (int32*)compute[(((oc_chunk_1*4) + oc_block_1) + 8)], dtype=int32)
          compute[(((oc_chunk_1*4) + oc_block_1) + 24)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner_1*448) + (threadIdx.x*4)) + 7392), 1, 4)], (int8x4*)placeholder.shared[ramp((((((threadIdx.y*512) + (oc_chunk_1*256)) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 2048), 1, 4)], (int32*)compute[(((oc_chunk_1*4) + oc_block_1) + 24)], dtype=int32)
        }
      }
    }
    for (ax1.inner.inner.inner: int32, 0, 2) "unroll" {
      for (ax4: int32, 0, 4) "unroll" {
        T_relu_2[(((((((blockIdx.z*401408) + (blockIdx.y*50176)) + (threadIdx.y*6272)) + (ax1.inner.inner.inner*3136)) + (blockIdx.x*448)) + (threadIdx.x*4)) + ax4)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[((ax1.inner.inner.inner*4) + ax4)], 1970177043, 31, 17, dtype=int32) + (int32*)placeholder_14[((((blockIdx.y*64) + (threadIdx.y*8)) + (ax1.inner.inner.inner*4)) + ax4)]), 1073758499, 31, 1, dtype=int32) + (int32*)placeholder_13[((((blockIdx.y*64) + (threadIdx.y*8)) + (ax1.inner.inner.inner*4)) + ax4)]), 2000488945, 31, 0, dtype=int32) + (int32*)placeholder_11[(((((((blockIdx.z*401408) + (blockIdx.y*50176)) + (threadIdx.y*6272)) + (ax1.inner.inner.inner*3136)) + (blockIdx.x*448)) + (threadIdx.x*4)) + ax4)]), 0)
        T_relu_2[((((((((blockIdx.z*401408) + (blockIdx.y*50176)) + (threadIdx.y*6272)) + (ax1.inner.inner.inner*3136)) + (blockIdx.x*448)) + (threadIdx.x*4)) + ax4) + 25088)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(((ax1.inner.inner.inner*4) + ax4) + 16)], 1970177043, 31, 17, dtype=int32) + (int32*)placeholder_14[(((((blockIdx.y*64) + (threadIdx.y*8)) + (ax1.inner.inner.inner*4)) + ax4) + 32)]), 1073758499, 31, 1, dtype=int32) + (int32*)placeholder_13[(((((blockIdx.y*64) + (threadIdx.y*8)) + (ax1.inner.inner.inner*4)) + ax4) + 32)]), 2000488945, 31, 0, dtype=int32) + (int32*)placeholder_11[((((((((blockIdx.z*401408) + (blockIdx.y*50176)) + (threadIdx.y*6272)) + (ax1.inner.inner.inner*3136)) + (blockIdx.x*448)) + (threadIdx.x*4)) + ax4) + 25088)]), 0)
        T_relu_2[((((((((blockIdx.z*401408) + (blockIdx.y*50176)) + (threadIdx.y*6272)) + (ax1.inner.inner.inner*3136)) + (blockIdx.x*448)) + (threadIdx.x*4)) + ax4) + 224)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(((ax1.inner.inner.inner*4) + ax4) + 8)], 1970177043, 31, 17, dtype=int32) + (int32*)placeholder_14[((((blockIdx.y*64) + (threadIdx.y*8)) + (ax1.inner.inner.inner*4)) + ax4)]), 1073758499, 31, 1, dtype=int32) + (int32*)placeholder_13[((((blockIdx.y*64) + (threadIdx.y*8)) + (ax1.inner.inner.inner*4)) + ax4)]), 2000488945, 31, 0, dtype=int32) + (int32*)placeholder_11[((((((((blockIdx.z*401408) + (blockIdx.y*50176)) + (threadIdx.y*6272)) + (ax1.inner.inner.inner*3136)) + (blockIdx.x*448)) + (threadIdx.x*4)) + ax4) + 224)]), 0)
        T_relu_2[((((((((blockIdx.z*401408) + (blockIdx.y*50176)) + (threadIdx.y*6272)) + (ax1.inner.inner.inner*3136)) + (blockIdx.x*448)) + (threadIdx.x*4)) + ax4) + 25312)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(((ax1.inner.inner.inner*4) + ax4) + 24)], 1970177043, 31, 17, dtype=int32) + (int32*)placeholder_14[(((((blockIdx.y*64) + (threadIdx.y*8)) + (ax1.inner.inner.inner*4)) + ax4) + 32)]), 1073758499, 31, 1, dtype=int32) + (int32*)placeholder_13[(((((blockIdx.y*64) + (threadIdx.y*8)) + (ax1.inner.inner.inner*4)) + ax4) + 32)]), 2000488945, 31, 0, dtype=int32) + (int32*)placeholder_11[((((((((blockIdx.z*401408) + (blockIdx.y*50176)) + (threadIdx.y*6272)) + (ax1.inner.inner.inner*3136)) + (blockIdx.x*448)) + (threadIdx.x*4)) + ax4) + 25312)]), 0)
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_nn_relu_cast_fixed_point_mult_18399029763786111876__12", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [32, 32, 28, 28, 4], []),
             placeholder_2: Buffer(placeholder_6: handle, int32, [1, 32, 1, 1, 4], []),
             placeholder: Buffer(placeholder_7: handle, int8, [32, 32, 28, 28, 4], []),
             placeholder_1: Buffer(placeholder_8: handle, int8, [32, 32, 3, 3, 4, 4], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 16;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [16]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [288]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [2304]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 2;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 49;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4 {
    for (oh.init: int32, 0, 2) "unroll" {
      for (oc_block.init: int32, 0, 4) "unroll" {
        compute[((oh.init*4) + oc_block.init)] = 0
        compute[(((oh.init*4) + oc_block.init) + 8)] = 0
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 2) "unroll" {
      attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
      attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
      if (((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1) < 144) {
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*32) + (threadIdx.z_1*16)) + threadIdx.y_1) < 36) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*2) + threadIdx.z_1) < 3) {
            pad_data.shared[ramp(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*512) + (threadIdx.z_1*256)) + (threadIdx.y_1*16)) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((1 <= ((floordiv(blockIdx.x, 7)*4) + floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 36), 6))) && (((floordiv(blockIdx.x, 7)*4) + floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 36), 6)) < 29)) && (1 <= ((floormod(blockIdx.x, 7)*4) + floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 6)))) && (((floormod(blockIdx.x, 7)*4) + floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 6)) < 29)), (int8x4*)placeholder_7[ramp(((((((((blockIdx.z*200704) + (floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 72)*100352)) + (floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 72), 36)*3136)) + (floordiv(blockIdx.x, 7)*448)) + (floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 36), 6)*112)) + (floormod(blockIdx.x, 7)*16)) + (floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 6)*4)) - 116), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
          }
        }
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 9) "unroll" {
      attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
      attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
      attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
      placeholder.shared[ramp(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*512) + (threadIdx.z_2*256)) + (threadIdx.y_2*16)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp(((((blockIdx.y*73728) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.z_2*16)) + threadIdx.y_2), 18)*4608)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.z_2*16)) + threadIdx.y_2), 18)*16)) + (threadIdx.x_2*4)), 1, 4)]
    }
    for (ic_chunk.outer.outer: int32, 0, 15) {
      attr [pad_data.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1: int32, 0, 2) "unroll" {
        attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
        attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
        attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
        if (((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1) < 144) {
          if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*32) + (threadIdx.z_1*16)) + threadIdx.y_1) < 36) {
            if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*2) + threadIdx.z_1) < 3) {
              pad_data.shared[ramp((((((floormod((ic_chunk.outer.outer + 1), 2)*576) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*512)) + (threadIdx.z_1*256)) + (threadIdx.y_1*16)) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((1 <= ((floordiv(blockIdx.x, 7)*4) + floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 36), 6))) && (((floordiv(blockIdx.x, 7)*4) + floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 36), 6)) < 29)) && (1 <= ((floormod(blockIdx.x, 7)*4) + floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 6)))) && (((floormod(blockIdx.x, 7)*4) + floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 6)) < 29)), (int8x4*)placeholder_7[ramp((((((((((blockIdx.z*200704) + (floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 72)*100352)) + (ic_chunk.outer.outer*6272)) + (floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 72), 36)*3136)) + (floordiv(blockIdx.x, 7)*448)) + (floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 36), 6)*112)) + (floormod(blockIdx.x, 7)*16)) + (floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_1*64)) + (threadIdx.y_1*4)) + threadIdx.x_1), 6)*4)) + 6156), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
            }
          }
        }
      }
      attr [placeholder.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 9) "unroll" {
        attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
        attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
        attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
        placeholder.shared[ramp((((((floormod((ic_chunk.outer.outer + 1), 2)*4608) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*512)) + (threadIdx.z_2*256)) + (threadIdx.y_2*16)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp(((((((blockIdx.y*73728) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.z_2*16)) + threadIdx.y_2), 18)*4608)) + (ic_chunk.outer.outer*288)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.z_2*16)) + threadIdx.y_2), 18)*16)) + (threadIdx.x_2*4)) + 288), 1, 4)]
      }
      for (kw.inner: int32, 0, 3) "unroll" {
        for (ic_chunk.inner: int32, 0, 2) "unroll" {
          for (kh.inner: int32, 0, 3) "unroll" {
            for (oh: int32, 0, 2) "unroll" {
              for (oc_block: int32, 0, 4) "unroll" {
                compute[((oh*4) + oc_block)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((((floormod(ic_chunk.outer.outer, 2)*576) + (threadIdx.z*288)) + (ic_chunk.inner*144)) + (oh*24)) + (kh.inner*24)) + (threadIdx.x*4)) + (kw.inner*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((((floormod(ic_chunk.outer.outer, 2)*4608) + (threadIdx.y*288)) + (ic_chunk.inner*144)) + (kh.inner*48)) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[((oh*4) + oc_block)], dtype=int32)
                compute[(((oh*4) + oc_block) + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((((((floormod(ic_chunk.outer.outer, 2)*576) + (threadIdx.z*288)) + (ic_chunk.inner*144)) + (oh*24)) + (kh.inner*24)) + (threadIdx.x*4)) + (kw.inner*4)) + 48), 1, 4)], (int8x4*)placeholder.shared[ramp(((((((floormod(ic_chunk.outer.outer, 2)*4608) + (threadIdx.y*288)) + (ic_chunk.inner*144)) + (kh.inner*48)) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(((oh*4) + oc_block) + 8)], dtype=int32)
              }
            }
          }
        }
      }
    }
    for (kw.inner_1: int32, 0, 3) "unroll" {
      for (ic_chunk.inner_1: int32, 0, 2) "unroll" {
        for (kh.inner_1: int32, 0, 3) "unroll" {
          for (oh_1: int32, 0, 2) "unroll" {
            for (oc_block_1: int32, 0, 4) "unroll" {
              compute[((oh_1*4) + oc_block_1)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((((threadIdx.z*288) + (ic_chunk.inner_1*144)) + (oh_1*24)) + (kh.inner_1*24)) + (threadIdx.x*4)) + (kw.inner_1*4)) + 576), 1, 4)], (int8x4*)placeholder.shared[ramp(((((((threadIdx.y*288) + (ic_chunk.inner_1*144)) + (kh.inner_1*48)) + (kw.inner_1*16)) + (oc_block_1*4)) + 4608), 1, 4)], (int32*)compute[((oh_1*4) + oc_block_1)], dtype=int32)
              compute[(((oh_1*4) + oc_block_1) + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((((threadIdx.z*288) + (ic_chunk.inner_1*144)) + (oh_1*24)) + (kh.inner_1*24)) + (threadIdx.x*4)) + (kw.inner_1*4)) + 624), 1, 4)], (int8x4*)placeholder.shared[ramp(((((((threadIdx.y*288) + (ic_chunk.inner_1*144)) + (kh.inner_1*48)) + (kw.inner_1*16)) + (oc_block_1*4)) + 4608), 1, 4)], (int32*)compute[(((oh_1*4) + oc_block_1) + 8)], dtype=int32)
            }
          }
        }
      }
    }
    for (ax2.inner.inner.inner: int32, 0, 2) "unroll" {
      for (ax4: int32, 0, 4) "unroll" {
        T_cast_2[(((((((((blockIdx.z*200704) + (threadIdx.z*100352)) + (blockIdx.y*50176)) + (threadIdx.y*3136)) + (floordiv(blockIdx.x, 7)*448)) + (ax2.inner.inner.inner*112)) + (floormod(blockIdx.x, 7)*16)) + (threadIdx.x*4)) + ax4)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((int32*)compute[((ax2.inner.inner.inner*4) + ax4)], 1565194612, 31, 16, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 0), 1208910866, 31, -23, dtype=int32), 127), -128))
        T_cast_2[((((((((((blockIdx.z*200704) + (threadIdx.z*100352)) + (blockIdx.y*50176)) + (threadIdx.y*3136)) + (floordiv(blockIdx.x, 7)*448)) + (ax2.inner.inner.inner*112)) + (floormod(blockIdx.x, 7)*16)) + (threadIdx.x*4)) + ax4) + 224)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((int32*)compute[(((ax2.inner.inner.inner*4) + ax4) + 8)], 1565194612, 31, 16, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 0), 1208910866, 31, -23, dtype=int32), 127), -128))
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_fixed_point_multiply_add_cast_16086763325481941859__11", "tir.noalias": True}
  buffers = {placeholder_1: Buffer(placeholder_8: handle, int8, [32, 64, 1, 1, 4, 4], []),
             T_cast: Buffer(T_cast_2: handle, int8, [32, 32, 28, 28, 4], []),
             placeholder_3: Buffer(placeholder_9: handle, int32, [1, 32, 1, 1, 4], []),
             placeholder_2: Buffer(placeholder_10: handle, int8, [32, 64, 56, 56, 4], []),
             placeholder: Buffer(placeholder_11: handle, int32, [1, 32, 1, 1, 4], [])}
  buffer_map = {T_cast_1: T_cast, placeholder_6: placeholder, placeholder_5: placeholder_1, placeholder_4: placeholder_2, placeholder_7: placeholder_3} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 16;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [16]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [880]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [512]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 2;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 28;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 16;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 1;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 14 {
    for (oc_block.init: int32, 0, 4) "unroll" {
      compute[oc_block.init] = 0
      compute[(oc_block.init + 8)] = 0
      compute[(oc_block.init + 4)] = 0
      compute[(oc_block.init + 12)] = 0
    }
    for (ic_chunk.outer: int32, 0, 8) {
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 4) "unroll" {
        attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 16;
        attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 1;
        attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 14;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*224) + (threadIdx.z_1*14)) + threadIdx.x_1) < 880) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*16) + threadIdx.z_1) < 63) {
            pad_data.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*896) + (threadIdx.z_1*56)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_10[ramp(((((((blockIdx.z*1605632) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*224) + (threadIdx.z_1*14)) + threadIdx.x_1), 440)*802816)) + (ic_chunk.outer*100352)) + (floordiv(floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*224) + (threadIdx.z_1*14)) + threadIdx.x_1), 440), 55)*12544)) + (blockIdx.x*448)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*224) + (threadIdx.z_1*14)) + threadIdx.x_1), 55)*4)), 1, 4)]
          }
        }
      }
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 3) "unroll" {
        attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 16;
        attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 1;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 14;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*224) + (threadIdx.z_2*14)) + threadIdx.x_2) < 512) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*16) + threadIdx.z_2) < 37) {
            if ((((blockIdx.y*16) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*7)) + floordiv(((threadIdx.z_2*14) + threadIdx.x_2), 32)) < 32) {
              placeholder.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*896) + (threadIdx.z_2*56)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp((((((blockIdx.y*16384) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*7168)) + (floordiv(((threadIdx.z_2*14) + threadIdx.x_2), 32)*1024)) + (ic_chunk.outer*128)) + (floormod(((threadIdx.z_2*14) + threadIdx.x_2), 32)*4)), 1, 4)]
            }
          }
        }
      }
      for (ic_chunk.inner: int32, 0, 8) "unroll" {
        for (oc_block: int32, 0, 4) "unroll" {
          compute[oc_block] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((ic_chunk.inner*220) + (threadIdx.x*8)), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*128) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[oc_block], dtype=int32)
          compute[(oc_block + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*220) + (threadIdx.x*8)) + 1760), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*128) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 8)], dtype=int32)
          compute[(oc_block + 4)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*220) + (threadIdx.x*8)) + 112), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*128) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 4)], dtype=int32)
          compute[(oc_block + 12)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*220) + (threadIdx.x*8)) + 1872), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*128) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 12)], dtype=int32)
        }
      }
    }
    for (ax4: int32, 0, 4) "unroll" {
      T_cast_2[((((((blockIdx.z*200704) + (blockIdx.y*50176)) + (threadIdx.z*3136)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[ax4], 1255108819, 31, 17, dtype=int32) + (int32*)placeholder_11[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 2147466095, 31, 0, dtype=int32) + (int32*)placeholder_9[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 0), 1320312794, 31, -23, dtype=int32), 127), -128))
      T_cast_2[(((((((blockIdx.z*200704) + (blockIdx.y*50176)) + (threadIdx.z*3136)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4) + 100352)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 8)], 1255108819, 31, 17, dtype=int32) + (int32*)placeholder_11[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 2147466095, 31, 0, dtype=int32) + (int32*)placeholder_9[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 0), 1320312794, 31, -23, dtype=int32), 127), -128))
      T_cast_2[(((((((blockIdx.z*200704) + (blockIdx.y*50176)) + (threadIdx.z*3136)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4) + 56)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 4)], 1255108819, 31, 17, dtype=int32) + (int32*)placeholder_11[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 2147466095, 31, 0, dtype=int32) + (int32*)placeholder_9[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 0), 1320312794, 31, -23, dtype=int32), 127), -128))
      T_cast_2[(((((((blockIdx.z*200704) + (blockIdx.y*50176)) + (threadIdx.z*3136)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4) + 100408)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 12)], 1255108819, 31, 17, dtype=int32) + (int32*)placeholder_11[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 2147466095, 31, 0, dtype=int32) + (int32*)placeholder_9[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 0), 1320312794, 31, -23, dtype=int32), 127), -128))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_fixed_point_multiply_clip_cast_12", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [32, 64, 56, 56, 4], []),
             placeholder: Buffer(placeholder_2: handle, int32, [32, 64, 56, 56, 4], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer: int32, 0, 98) {
    T_cast_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = cast(int8, max(min(@tir.q_multiply_shift((int32*)placeholder_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)], 2127229536, 31, -24, dtype=int32), 127), -128))
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
primfn(placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, placeholder_8: handle, placeholder_9: handle, T_relu_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_fixed_point_multiply_add_cast_15119380522063600768__9", "tir.noalias": True}
  buffers = {T_relu: Buffer(T_relu_2: handle, int32, [32, 64, 56, 56, 4], []),
             placeholder_1: Buffer(placeholder_10: handle, int8, [32, 16, 56, 56, 4], []),
             placeholder_4: Buffer(placeholder_11: handle, int32, [1, 64, 1, 1, 4], []),
             placeholder: Buffer(placeholder_12: handle, int32, [1, 64, 1, 1, 4], []),
             placeholder_2: Buffer(placeholder_13: handle, int32, [32, 64, 56, 56, 4], []),
             placeholder_3: Buffer(placeholder_14: handle, int8, [64, 16, 1, 1, 4, 4], [])}
  buffer_map = {placeholder_7: placeholder, placeholder_5: placeholder_1, placeholder_9: placeholder_2, placeholder_6: placeholder_3, placeholder_8: placeholder_4, T_relu_1: T_relu} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 32;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [16]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [128]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [1024]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 2;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 196;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8 {
    for (oc_chunk.init: int32, 0, 2) "unroll" {
      for (oc_block.init: int32, 0, 4) "unroll" {
        compute[((oc_chunk.init*4) + oc_block.init)] = 0
        compute[(((oc_chunk.init*4) + oc_block.init) + 8)] = 0
      }
    }
    for (ic_chunk.outer: int32, 0, 2) "unroll" {
      attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8;
      pad_data.shared[ramp(((threadIdx.y_1*32) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_10[ramp((((((((blockIdx.z*200704) + (ic_chunk.outer*100352)) + (floordiv(threadIdx.y_1, 2)*12544)) + (floordiv(blockIdx.x, 7)*448)) + (floormod(threadIdx.y_1, 2)*224)) + (floormod(blockIdx.x, 7)*32)) + (threadIdx.x_1*4)), 1, 4)]
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 8) "unroll" {
        attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8;
        placeholder.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*512) + (threadIdx.y_2*32)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_14[ramp(((((((blockIdx.y*8192) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*1024)) + (floordiv(((threadIdx.y_2*2) + floordiv(threadIdx.x_2, 4)), 8)*256)) + (ic_chunk.outer*128)) + (floormod(((threadIdx.y_2*2) + floordiv(threadIdx.x_2, 4)), 8)*16)) + (floormod(threadIdx.x_2, 4)*4)), 1, 4)]
      }
      for (ic_chunk.inner: int32, 0, 8) "unroll" {
        for (oc_chunk: int32, 0, 2) "unroll" {
          for (oc_block: int32, 0, 4) "unroll" {
            compute[((oc_chunk*4) + oc_block)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((ic_chunk.inner*64) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*256) + (oc_chunk*128)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[((oc_chunk*4) + oc_block)], dtype=int32)
            compute[(((oc_chunk*4) + oc_block) + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*64) + (threadIdx.x*4)) + 32), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*256) + (oc_chunk*128)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(((oc_chunk*4) + oc_block) + 8)], dtype=int32)
          }
        }
      }
    }
    for (ax1.inner.inner.inner: int32, 0, 2) "unroll" {
      for (ax4: int32, 0, 4) "unroll" {
        T_relu_2[((((((((blockIdx.z*802816) + (blockIdx.y*401408)) + (threadIdx.y*25088)) + (ax1.inner.inner.inner*12544)) + (floordiv(blockIdx.x, 7)*448)) + (floormod(blockIdx.x, 7)*32)) + (threadIdx.x*4)) + ax4)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[((ax1.inner.inner.inner*4) + ax4)], 1237566260, 31, 18, dtype=int32) + (int32*)placeholder_12[((((blockIdx.y*128) + (threadIdx.y*8)) + (ax1.inner.inner.inner*4)) + ax4)]), 1073846162, 31, 1, dtype=int32) + (int32*)placeholder_11[((((blockIdx.y*128) + (threadIdx.y*8)) + (ax1.inner.inner.inner*4)) + ax4)]), 2009407807, 31, 0, dtype=int32) + @tir.q_multiply_shift((int32*)placeholder_13[((((((((blockIdx.z*802816) + (blockIdx.y*401408)) + (threadIdx.y*25088)) + (ax1.inner.inner.inner*12544)) + (floordiv(blockIdx.x, 7)*448)) + (floormod(blockIdx.x, 7)*32)) + (threadIdx.x*4)) + ax4)], 1117547056, 31, 1, dtype=int32)), 0)
        T_relu_2[(((((((((blockIdx.z*802816) + (blockIdx.y*401408)) + (threadIdx.y*25088)) + (ax1.inner.inner.inner*12544)) + (floordiv(blockIdx.x, 7)*448)) + (floormod(blockIdx.x, 7)*32)) + (threadIdx.x*4)) + ax4) + 224)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(((ax1.inner.inner.inner*4) + ax4) + 8)], 1237566260, 31, 18, dtype=int32) + (int32*)placeholder_12[((((blockIdx.y*128) + (threadIdx.y*8)) + (ax1.inner.inner.inner*4)) + ax4)]), 1073846162, 31, 1, dtype=int32) + (int32*)placeholder_11[((((blockIdx.y*128) + (threadIdx.y*8)) + (ax1.inner.inner.inner*4)) + ax4)]), 2009407807, 31, 0, dtype=int32) + @tir.q_multiply_shift((int32*)placeholder_13[(((((((((blockIdx.z*802816) + (blockIdx.y*401408)) + (threadIdx.y*25088)) + (ax1.inner.inner.inner*12544)) + (floordiv(blockIdx.x, 7)*448)) + (floormod(blockIdx.x, 7)*32)) + (threadIdx.x*4)) + ax4) + 224)], 1117547056, 31, 1, dtype=int32)), 0)
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_nn_relu_cast_fixed_point_mult_18399029763786111876__13", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [32, 16, 56, 56, 4], []),
             placeholder_2: Buffer(placeholder_6: handle, int32, [1, 16, 1, 1, 4], []),
             placeholder: Buffer(placeholder_7: handle, int8, [32, 16, 56, 56, 4], []),
             placeholder_1: Buffer(placeholder_8: handle, int8, [16, 16, 3, 3, 4, 4], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 32;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [16]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [120]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [288]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 2;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 98;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8 {
    for (oc_block.init: int32, 0, 4) "unroll" {
      compute[oc_block.init] = 0
      compute[(oc_block.init + 4)] = 0
      compute[(oc_block.init + 8)] = 0
      compute[(oc_block.init + 12)] = 0
    }
    attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
    attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
    attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8;
    if (((threadIdx.y_1*8) + threadIdx.x_1) < 60) {
      pad_data.shared[ramp(((threadIdx.y_1*32) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((1 <= ((floordiv(blockIdx.x, 7)*4) + floordiv(((threadIdx.y_1*8) + threadIdx.x_1), 10))) && (((floordiv(blockIdx.x, 7)*4) + floordiv(((threadIdx.y_1*8) + threadIdx.x_1), 10)) < 57)) && (1 <= ((floormod(blockIdx.x, 7)*8) + floormod(((threadIdx.y_1*8) + threadIdx.x_1), 10)))) && (((floormod(blockIdx.x, 7)*8) + floormod(((threadIdx.y_1*8) + threadIdx.x_1), 10)) < 57)), (int8x4*)placeholder_7[ramp(((((((blockIdx.z*200704) + (floordiv(blockIdx.x, 7)*896)) + (floordiv(((threadIdx.y_1*8) + threadIdx.x_1), 10)*224)) + (floormod(blockIdx.x, 7)*32)) + (floormod(((threadIdx.y_1*8) + threadIdx.x_1), 10)*4)) - 228), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
    }
    for (ic_chunk.outer.outer: int32, 0, 15) {
      attr [pad_data.shared] "double_buffer_write" = 1;
      attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
      attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8;
      if (((threadIdx.y_1*8) + threadIdx.x_1) < 60) {
        pad_data.shared[ramp((((floormod((ic_chunk.outer.outer + 1), 2)*240) + (threadIdx.y_1*32)) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((1 <= ((floordiv(blockIdx.x, 7)*4) + floordiv(((threadIdx.y_1*8) + threadIdx.x_1), 10))) && (((floordiv(blockIdx.x, 7)*4) + floordiv(((threadIdx.y_1*8) + threadIdx.x_1), 10)) < 57)) && (1 <= ((floormod(blockIdx.x, 7)*8) + floormod(((threadIdx.y_1*8) + threadIdx.x_1), 10)))) && (((floormod(blockIdx.x, 7)*8) + floormod(((threadIdx.y_1*8) + threadIdx.x_1), 10)) < 57)), (int8x4*)placeholder_7[ramp((((((((blockIdx.z*200704) + (ic_chunk.outer.outer*12544)) + (floordiv(blockIdx.x, 7)*896)) + (floordiv(((threadIdx.y_1*8) + threadIdx.x_1), 10)*224)) + (floormod(blockIdx.x, 7)*32)) + (floormod(((threadIdx.y_1*8) + threadIdx.x_1), 10)*4)) + 12316), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
      }
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 5) "unroll" {
        attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*16) + (threadIdx.y_2*2)) + floordiv(threadIdx.x_2, 4)) < 72) {
          if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*64) + (threadIdx.y_2*8)) + threadIdx.x_2) < 288) {
            if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*8) + threadIdx.y_2) < 36) {
              placeholder.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*256) + (threadIdx.y_2*32)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp((((((blockIdx.y*18432) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*16) + (threadIdx.y_2*2)) + floordiv(threadIdx.x_2, 4)), 9)*2304)) + (ic_chunk.outer.outer*144)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*16) + (threadIdx.y_2*2)) + floordiv(threadIdx.x_2, 4)), 9)*16)) + (floormod(threadIdx.x_2, 4)*4)), 1, 4)]
            }
          }
        }
      }
      for (kw.inner: int32, 0, 3) "unroll" {
        for (kh.inner: int32, 0, 3) "unroll" {
          for (oc_block: int32, 0, 4) "unroll" {
            compute[oc_block] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*240) + (kh.inner*40)) + (threadIdx.x*4)) + (kw.inner*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*144) + (kh.inner*48)) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[oc_block], dtype=int32)
            compute[(oc_block + 4)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*240) + (kh.inner*40)) + (threadIdx.x*4)) + (kw.inner*4)) + 40), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*144) + (kh.inner*48)) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 4)], dtype=int32)
            compute[(oc_block + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*240) + (kh.inner*40)) + (threadIdx.x*4)) + (kw.inner*4)) + 80), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*144) + (kh.inner*48)) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 8)], dtype=int32)
            compute[(oc_block + 12)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*240) + (kh.inner*40)) + (threadIdx.x*4)) + (kw.inner*4)) + 120), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*144) + (kh.inner*48)) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 12)], dtype=int32)
          }
        }
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 5) "unroll" {
      attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
      attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8;
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*16) + (threadIdx.y_2*2)) + floordiv(threadIdx.x_2, 4)) < 72) {
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*64) + (threadIdx.y_2*8)) + threadIdx.x_2) < 288) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*8) + threadIdx.y_2) < 36) {
            placeholder.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*256) + (threadIdx.y_2*32)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp((((((blockIdx.y*18432) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*16) + (threadIdx.y_2*2)) + floordiv(threadIdx.x_2, 4)), 9)*2304)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*16) + (threadIdx.y_2*2)) + floordiv(threadIdx.x_2, 4)), 9)*16)) + (floormod(threadIdx.x_2, 4)*4)) + 2160), 1, 4)]
          }
        }
      }
    }
    for (kw.inner_1: int32, 0, 3) "unroll" {
      for (kh.inner_1: int32, 0, 3) "unroll" {
        for (oc_block_1: int32, 0, 4) "unroll" {
          compute[oc_block_1] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((kh.inner_1*40) + (threadIdx.x*4)) + (kw.inner_1*4)) + 240), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*144) + (kh.inner_1*48)) + (kw.inner_1*16)) + (oc_block_1*4)), 1, 4)], (int32*)compute[oc_block_1], dtype=int32)
          compute[(oc_block_1 + 4)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((kh.inner_1*40) + (threadIdx.x*4)) + (kw.inner_1*4)) + 280), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*144) + (kh.inner_1*48)) + (kw.inner_1*16)) + (oc_block_1*4)), 1, 4)], (int32*)compute[(oc_block_1 + 4)], dtype=int32)
          compute[(oc_block_1 + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((kh.inner_1*40) + (threadIdx.x*4)) + (kw.inner_1*4)) + 320), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*144) + (kh.inner_1*48)) + (kw.inner_1*16)) + (oc_block_1*4)), 1, 4)], (int32*)compute[(oc_block_1 + 8)], dtype=int32)
          compute[(oc_block_1 + 12)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((kh.inner_1*40) + (threadIdx.x*4)) + (kw.inner_1*4)) + 360), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*144) + (kh.inner_1*48)) + (kw.inner_1*16)) + (oc_block_1*4)), 1, 4)], (int32*)compute[(oc_block_1 + 12)], dtype=int32)
        }
      }
    }
    for (ax4: int32, 0, 4) "unroll" {
      T_cast_2[(((((((blockIdx.z*200704) + (blockIdx.y*100352)) + (threadIdx.y*12544)) + (floordiv(blockIdx.x, 7)*896)) + (floormod(blockIdx.x, 7)*32)) + (threadIdx.x*4)) + ax4)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((int32*)compute[ax4], 2052399534, 31, 16, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*32) + (threadIdx.y*4)) + ax4)]), 0), 2044369894, 31, -24, dtype=int32), 127), -128))
      T_cast_2[((((((((blockIdx.z*200704) + (blockIdx.y*100352)) + (threadIdx.y*12544)) + (floordiv(blockIdx.x, 7)*896)) + (floormod(blockIdx.x, 7)*32)) + (threadIdx.x*4)) + ax4) + 224)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((int32*)compute[(ax4 + 4)], 2052399534, 31, 16, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*32) + (threadIdx.y*4)) + ax4)]), 0), 2044369894, 31, -24, dtype=int32), 127), -128))
      T_cast_2[((((((((blockIdx.z*200704) + (blockIdx.y*100352)) + (threadIdx.y*12544)) + (floordiv(blockIdx.x, 7)*896)) + (floormod(blockIdx.x, 7)*32)) + (threadIdx.x*4)) + ax4) + 448)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((int32*)compute[(ax4 + 8)], 2052399534, 31, 16, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*32) + (threadIdx.y*4)) + ax4)]), 0), 2044369894, 31, -24, dtype=int32), 127), -128))
      T_cast_2[((((((((blockIdx.z*200704) + (blockIdx.y*100352)) + (threadIdx.y*12544)) + (floordiv(blockIdx.x, 7)*896)) + (floormod(blockIdx.x, 7)*32)) + (threadIdx.x*4)) + ax4) + 672)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((int32*)compute[(ax4 + 12)], 2052399534, 31, 16, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*32) + (threadIdx.y*4)) + ax4)]), 0), 2044369894, 31, -24, dtype=int32), 127), -128))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_fixed_point_multiply_add_cast_16086763325481941859__12", "tir.noalias": True}
  buffers = {placeholder_3: Buffer(placeholder_8: handle, int32, [1, 16, 1, 1, 4], []),
             placeholder_2: Buffer(placeholder_9: handle, int8, [32, 64, 56, 56, 4], []),
             placeholder_1: Buffer(placeholder_10: handle, int8, [16, 64, 1, 1, 4, 4], []),
             placeholder: Buffer(placeholder_11: handle, int32, [1, 16, 1, 1, 4], []),
             T_cast: Buffer(T_cast_2: handle, int8, [32, 16, 56, 56, 4], [])}
  buffer_map = {placeholder_6: placeholder, T_cast_1: T_cast, placeholder_5: placeholder_1, placeholder_4: placeholder_2, placeholder_7: placeholder_3} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 16;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [16]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [512]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [1024]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 1;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 196;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 16 {
    for (oc_block.init: int32, 0, 4) {
      compute[oc_block.init] = 0
      compute[(oc_block.init + 8)] = 0
      compute[(oc_block.init + 4)] = 0
      compute[(oc_block.init + 12)] = 0
    }
    for (ic_chunk.outer: int32, 0, 4) {
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 4) {
        attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
        attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 16;
        pad_data.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*512) + (threadIdx.y_1*64)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_9[ramp(((((((((blockIdx.z*1605632) + (floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*8) + threadIdx.y_1), 16)*802816)) + (ic_chunk.outer*200704)) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*8) + threadIdx.y_1), 16)*12544)) + (floordiv(blockIdx.x, 7)*448)) + (floordiv(threadIdx.x_1, 8)*224)) + (floormod(blockIdx.x, 7)*32)) + (floormod(threadIdx.x_1, 8)*4)), 1, 4)]
      }
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 8) {
        attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 16;
        placeholder.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*512) + (threadIdx.y_2*64)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_10[ramp((((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*2048) + (floordiv(((threadIdx.y_2*4) + floordiv(threadIdx.x_2, 4)), 16)*1024)) + (ic_chunk.outer*256)) + (floormod(((threadIdx.y_2*4) + floordiv(threadIdx.x_2, 4)), 16)*16)) + (floormod(threadIdx.x_2, 4)*4)), 1, 4)]
      }
      for (ic_chunk.inner: int32, 0, 16) {
        for (oc_block: int32, 0, 4) {
          compute[oc_block] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((ic_chunk.inner*64) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.y*256) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[oc_block], dtype=int32)
          compute[(oc_block + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*64) + (threadIdx.x*4)) + 1024), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.y*256) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 8)], dtype=int32)
          compute[(oc_block + 4)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((ic_chunk.inner*64) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*256) + (ic_chunk.inner*16)) + (oc_block*4)) + 2048), 1, 4)], (int32*)compute[(oc_block + 4)], dtype=int32)
          compute[(oc_block + 12)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*64) + (threadIdx.x*4)) + 1024), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*256) + (ic_chunk.inner*16)) + (oc_block*4)) + 2048), 1, 4)], (int32*)compute[(oc_block + 12)], dtype=int32)
        }
      }
    }
    for (ax4: int32, 0, 4) {
      T_cast_2[(((((((blockIdx.z*401408) + (threadIdx.y*12544)) + (floordiv(blockIdx.x, 7)*448)) + (floordiv(threadIdx.x, 8)*224)) + (floormod(blockIdx.x, 7)*32)) + (floormod(threadIdx.x, 8)*4)) + ax4)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[ax4], 1523474988, 31, 17, dtype=int32) + (int32*)placeholder_11[((threadIdx.y*4) + ax4)]), 1073777777, 31, 1, dtype=int32) + (int32*)placeholder_8[((threadIdx.y*4) + ax4)]), 0), 2032294944, 31, -24, dtype=int32), 127), -128))
      T_cast_2[((((((((blockIdx.z*401408) + (threadIdx.y*12544)) + (floordiv(blockIdx.x, 7)*448)) + (floordiv(threadIdx.x, 8)*224)) + (floormod(blockIdx.x, 7)*32)) + (floormod(threadIdx.x, 8)*4)) + ax4) + 200704)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 8)], 1523474988, 31, 17, dtype=int32) + (int32*)placeholder_11[((threadIdx.y*4) + ax4)]), 1073777777, 31, 1, dtype=int32) + (int32*)placeholder_8[((threadIdx.y*4) + ax4)]), 0), 2032294944, 31, -24, dtype=int32), 127), -128))
      T_cast_2[((((((((blockIdx.z*401408) + (threadIdx.y*12544)) + (floordiv(blockIdx.x, 7)*448)) + (floordiv(threadIdx.x, 8)*224)) + (floormod(blockIdx.x, 7)*32)) + (floormod(threadIdx.x, 8)*4)) + ax4) + 100352)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 4)], 1523474988, 31, 17, dtype=int32) + (int32*)placeholder_11[(((threadIdx.y*4) + ax4) + 32)]), 1073777777, 31, 1, dtype=int32) + (int32*)placeholder_8[(((threadIdx.y*4) + ax4) + 32)]), 0), 2032294944, 31, -24, dtype=int32), 127), -128))
      T_cast_2[((((((((blockIdx.z*401408) + (threadIdx.y*12544)) + (floordiv(blockIdx.x, 7)*448)) + (floordiv(threadIdx.x, 8)*224)) + (floormod(blockIdx.x, 7)*32)) + (floormod(threadIdx.x, 8)*4)) + ax4) + 301056)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 12)], 1523474988, 31, 17, dtype=int32) + (int32*)placeholder_11[(((threadIdx.y*4) + ax4) + 32)]), 1073777777, 31, 1, dtype=int32) + (int32*)placeholder_8[(((threadIdx.y*4) + ax4) + 32)]), 0), 2032294944, 31, -24, dtype=int32), 127), -128))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_fixed_point_multiply_clip_cast_13", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [32, 64, 56, 56, 4], []),
             placeholder: Buffer(placeholder_2: handle, int32, [32, 64, 56, 56, 4], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer: int32, 0, 98) {
    T_cast_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = cast(int8, max(min(@tir.q_multiply_shift((int32*)placeholder_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)], 1117547056, 31, -23, dtype=int32), 127), -128))
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
primfn(placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, placeholder_8: handle, placeholder_9: handle, T_relu_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_fixed_point_multiply_add_cast_15119380522063600768__10", "tir.noalias": True}
  buffers = {T_relu: Buffer(T_relu_2: handle, int32, [32, 64, 56, 56, 4], []),
             placeholder_3: Buffer(placeholder_10: handle, int32, [32, 64, 56, 56, 4], []),
             placeholder: Buffer(placeholder_11: handle, int32, [1, 64, 1, 1, 4], []),
             placeholder_2: Buffer(placeholder_12: handle, int8, [32, 16, 56, 56, 4], []),
             placeholder_1: Buffer(placeholder_13: handle, int8, [64, 16, 1, 1, 4, 4], []),
             placeholder_4: Buffer(placeholder_14: handle, int32, [1, 64, 1, 1, 4], [])}
  buffer_map = {placeholder_7: placeholder, placeholder_6: placeholder_1, placeholder_5: placeholder_2, placeholder_9: placeholder_3, placeholder_8: placeholder_4, T_relu_1: T_relu} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 32;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [16]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [128]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [1024]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 2;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 196;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8 {
    for (oc_chunk.init: int32, 0, 2) "unroll" {
      for (oc_block.init: int32, 0, 4) "unroll" {
        compute[((oc_chunk.init*4) + oc_block.init)] = 0
        compute[(((oc_chunk.init*4) + oc_block.init) + 8)] = 0
      }
    }
    for (ic_chunk.outer: int32, 0, 2) "unroll" {
      attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8;
      pad_data.shared[ramp(((threadIdx.y_1*32) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_12[ramp((((((((blockIdx.z*200704) + (ic_chunk.outer*100352)) + (floordiv(threadIdx.y_1, 2)*12544)) + (floordiv(blockIdx.x, 7)*448)) + (floormod(threadIdx.y_1, 2)*224)) + (floormod(blockIdx.x, 7)*32)) + (threadIdx.x_1*4)), 1, 4)]
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 8) "unroll" {
        attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8;
        placeholder.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*512) + (threadIdx.y_2*32)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_13[ramp(((((((blockIdx.y*8192) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*1024)) + (floordiv(((threadIdx.y_2*2) + floordiv(threadIdx.x_2, 4)), 8)*256)) + (ic_chunk.outer*128)) + (floormod(((threadIdx.y_2*2) + floordiv(threadIdx.x_2, 4)), 8)*16)) + (floormod(threadIdx.x_2, 4)*4)), 1, 4)]
      }
      for (ic_chunk.inner: int32, 0, 8) "unroll" {
        for (oc_chunk: int32, 0, 2) "unroll" {
          for (oc_block: int32, 0, 4) "unroll" {
            compute[((oc_chunk*4) + oc_block)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((ic_chunk.inner*64) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*256) + (oc_chunk*128)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[((oc_chunk*4) + oc_block)], dtype=int32)
            compute[(((oc_chunk*4) + oc_block) + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*64) + (threadIdx.x*4)) + 32), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*256) + (oc_chunk*128)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(((oc_chunk*4) + oc_block) + 8)], dtype=int32)
          }
        }
      }
    }
    for (ax1.inner.inner.inner: int32, 0, 2) "unroll" {
      for (ax4: int32, 0, 4) "unroll" {
        T_relu_2[((((((((blockIdx.z*802816) + (blockIdx.y*401408)) + (threadIdx.y*25088)) + (ax1.inner.inner.inner*12544)) + (floordiv(blockIdx.x, 7)*448)) + (floormod(blockIdx.x, 7)*32)) + (threadIdx.x*4)) + ax4)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[((ax1.inner.inner.inner*4) + ax4)], 1481530374, 31, 18, dtype=int32) + (int32*)placeholder_11[((((blockIdx.y*128) + (threadIdx.y*8)) + (ax1.inner.inner.inner*4)) + ax4)]), 1073795082, 31, 1, dtype=int32) + (int32*)placeholder_14[((((blockIdx.y*128) + (threadIdx.y*8)) + (ax1.inner.inner.inner*4)) + ax4)]), 1134695180, 31, 1, dtype=int32) + @tir.q_multiply_shift((int32*)placeholder_10[((((((((blockIdx.z*802816) + (blockIdx.y*401408)) + (threadIdx.y*25088)) + (ax1.inner.inner.inner*12544)) + (floordiv(blockIdx.x, 7)*448)) + (floormod(blockIdx.x, 7)*32)) + (threadIdx.x*4)) + ax4)], 1288667344, 31, 1, dtype=int32)), 0)
        T_relu_2[(((((((((blockIdx.z*802816) + (blockIdx.y*401408)) + (threadIdx.y*25088)) + (ax1.inner.inner.inner*12544)) + (floordiv(blockIdx.x, 7)*448)) + (floormod(blockIdx.x, 7)*32)) + (threadIdx.x*4)) + ax4) + 224)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(((ax1.inner.inner.inner*4) + ax4) + 8)], 1481530374, 31, 18, dtype=int32) + (int32*)placeholder_11[((((blockIdx.y*128) + (threadIdx.y*8)) + (ax1.inner.inner.inner*4)) + ax4)]), 1073795082, 31, 1, dtype=int32) + (int32*)placeholder_14[((((blockIdx.y*128) + (threadIdx.y*8)) + (ax1.inner.inner.inner*4)) + ax4)]), 1134695180, 31, 1, dtype=int32) + @tir.q_multiply_shift((int32*)placeholder_10[(((((((((blockIdx.z*802816) + (blockIdx.y*401408)) + (threadIdx.y*25088)) + (ax1.inner.inner.inner*12544)) + (floordiv(blockIdx.x, 7)*448)) + (floormod(blockIdx.x, 7)*32)) + (threadIdx.x*4)) + ax4) + 224)], 1288667344, 31, 1, dtype=int32)), 0)
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_nn_relu_cast_fixed_point_mult_18399029763786111876__14", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [32, 16, 56, 56, 4], []),
             placeholder_2: Buffer(placeholder_6: handle, int32, [1, 16, 1, 1, 4], []),
             placeholder: Buffer(placeholder_7: handle, int8, [32, 16, 56, 56, 4], []),
             placeholder_1: Buffer(placeholder_8: handle, int8, [16, 16, 3, 3, 4, 4], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 32;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [16]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [120]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [288]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 2;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 98;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8 {
    for (oc_block.init: int32, 0, 4) "unroll" {
      compute[oc_block.init] = 0
      compute[(oc_block.init + 4)] = 0
      compute[(oc_block.init + 8)] = 0
      compute[(oc_block.init + 12)] = 0
    }
    attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
    attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
    attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8;
    if (((threadIdx.y_1*8) + threadIdx.x_1) < 60) {
      pad_data.shared[ramp(((threadIdx.y_1*32) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((1 <= ((floordiv(blockIdx.x, 7)*4) + floordiv(((threadIdx.y_1*8) + threadIdx.x_1), 10))) && (((floordiv(blockIdx.x, 7)*4) + floordiv(((threadIdx.y_1*8) + threadIdx.x_1), 10)) < 57)) && (1 <= ((floormod(blockIdx.x, 7)*8) + floormod(((threadIdx.y_1*8) + threadIdx.x_1), 10)))) && (((floormod(blockIdx.x, 7)*8) + floormod(((threadIdx.y_1*8) + threadIdx.x_1), 10)) < 57)), (int8x4*)placeholder_7[ramp(((((((blockIdx.z*200704) + (floordiv(blockIdx.x, 7)*896)) + (floordiv(((threadIdx.y_1*8) + threadIdx.x_1), 10)*224)) + (floormod(blockIdx.x, 7)*32)) + (floormod(((threadIdx.y_1*8) + threadIdx.x_1), 10)*4)) - 228), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
    }
    for (ic_chunk.outer.outer: int32, 0, 15) {
      attr [pad_data.shared] "double_buffer_write" = 1;
      attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
      attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8;
      if (((threadIdx.y_1*8) + threadIdx.x_1) < 60) {
        pad_data.shared[ramp((((floormod((ic_chunk.outer.outer + 1), 2)*240) + (threadIdx.y_1*32)) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((1 <= ((floordiv(blockIdx.x, 7)*4) + floordiv(((threadIdx.y_1*8) + threadIdx.x_1), 10))) && (((floordiv(blockIdx.x, 7)*4) + floordiv(((threadIdx.y_1*8) + threadIdx.x_1), 10)) < 57)) && (1 <= ((floormod(blockIdx.x, 7)*8) + floormod(((threadIdx.y_1*8) + threadIdx.x_1), 10)))) && (((floormod(blockIdx.x, 7)*8) + floormod(((threadIdx.y_1*8) + threadIdx.x_1), 10)) < 57)), (int8x4*)placeholder_7[ramp((((((((blockIdx.z*200704) + (ic_chunk.outer.outer*12544)) + (floordiv(blockIdx.x, 7)*896)) + (floordiv(((threadIdx.y_1*8) + threadIdx.x_1), 10)*224)) + (floormod(blockIdx.x, 7)*32)) + (floormod(((threadIdx.y_1*8) + threadIdx.x_1), 10)*4)) + 12316), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
      }
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 5) "unroll" {
        attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*16) + (threadIdx.y_2*2)) + floordiv(threadIdx.x_2, 4)) < 72) {
          if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*64) + (threadIdx.y_2*8)) + threadIdx.x_2) < 288) {
            if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*8) + threadIdx.y_2) < 36) {
              placeholder.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*256) + (threadIdx.y_2*32)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp((((((blockIdx.y*18432) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*16) + (threadIdx.y_2*2)) + floordiv(threadIdx.x_2, 4)), 9)*2304)) + (ic_chunk.outer.outer*144)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*16) + (threadIdx.y_2*2)) + floordiv(threadIdx.x_2, 4)), 9)*16)) + (floormod(threadIdx.x_2, 4)*4)), 1, 4)]
            }
          }
        }
      }
      for (kw.inner: int32, 0, 3) "unroll" {
        for (kh.inner: int32, 0, 3) "unroll" {
          for (oc_block: int32, 0, 4) "unroll" {
            compute[oc_block] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*240) + (kh.inner*40)) + (threadIdx.x*4)) + (kw.inner*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*144) + (kh.inner*48)) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[oc_block], dtype=int32)
            compute[(oc_block + 4)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*240) + (kh.inner*40)) + (threadIdx.x*4)) + (kw.inner*4)) + 40), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*144) + (kh.inner*48)) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 4)], dtype=int32)
            compute[(oc_block + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*240) + (kh.inner*40)) + (threadIdx.x*4)) + (kw.inner*4)) + 80), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*144) + (kh.inner*48)) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 8)], dtype=int32)
            compute[(oc_block + 12)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*240) + (kh.inner*40)) + (threadIdx.x*4)) + (kw.inner*4)) + 120), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*144) + (kh.inner*48)) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 12)], dtype=int32)
          }
        }
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 5) "unroll" {
      attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
      attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8;
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*16) + (threadIdx.y_2*2)) + floordiv(threadIdx.x_2, 4)) < 72) {
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*64) + (threadIdx.y_2*8)) + threadIdx.x_2) < 288) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*8) + threadIdx.y_2) < 36) {
            placeholder.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*256) + (threadIdx.y_2*32)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp((((((blockIdx.y*18432) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*16) + (threadIdx.y_2*2)) + floordiv(threadIdx.x_2, 4)), 9)*2304)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*16) + (threadIdx.y_2*2)) + floordiv(threadIdx.x_2, 4)), 9)*16)) + (floormod(threadIdx.x_2, 4)*4)) + 2160), 1, 4)]
          }
        }
      }
    }
    for (kw.inner_1: int32, 0, 3) "unroll" {
      for (kh.inner_1: int32, 0, 3) "unroll" {
        for (oc_block_1: int32, 0, 4) "unroll" {
          compute[oc_block_1] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((kh.inner_1*40) + (threadIdx.x*4)) + (kw.inner_1*4)) + 240), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*144) + (kh.inner_1*48)) + (kw.inner_1*16)) + (oc_block_1*4)), 1, 4)], (int32*)compute[oc_block_1], dtype=int32)
          compute[(oc_block_1 + 4)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((kh.inner_1*40) + (threadIdx.x*4)) + (kw.inner_1*4)) + 280), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*144) + (kh.inner_1*48)) + (kw.inner_1*16)) + (oc_block_1*4)), 1, 4)], (int32*)compute[(oc_block_1 + 4)], dtype=int32)
          compute[(oc_block_1 + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((kh.inner_1*40) + (threadIdx.x*4)) + (kw.inner_1*4)) + 320), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*144) + (kh.inner_1*48)) + (kw.inner_1*16)) + (oc_block_1*4)), 1, 4)], (int32*)compute[(oc_block_1 + 8)], dtype=int32)
          compute[(oc_block_1 + 12)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((kh.inner_1*40) + (threadIdx.x*4)) + (kw.inner_1*4)) + 360), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*144) + (kh.inner_1*48)) + (kw.inner_1*16)) + (oc_block_1*4)), 1, 4)], (int32*)compute[(oc_block_1 + 12)], dtype=int32)
        }
      }
    }
    for (ax4: int32, 0, 4) "unroll" {
      T_cast_2[(((((((blockIdx.z*200704) + (blockIdx.y*100352)) + (threadIdx.y*12544)) + (floordiv(blockIdx.x, 7)*896)) + (floormod(blockIdx.x, 7)*32)) + (threadIdx.x*4)) + ax4)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((int32*)compute[ax4], 1423657657, 31, 16, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*32) + (threadIdx.y*4)) + ax4)]), 0), 1105044667, 31, -23, dtype=int32), 127), -128))
      T_cast_2[((((((((blockIdx.z*200704) + (blockIdx.y*100352)) + (threadIdx.y*12544)) + (floordiv(blockIdx.x, 7)*896)) + (floormod(blockIdx.x, 7)*32)) + (threadIdx.x*4)) + ax4) + 224)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((int32*)compute[(ax4 + 4)], 1423657657, 31, 16, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*32) + (threadIdx.y*4)) + ax4)]), 0), 1105044667, 31, -23, dtype=int32), 127), -128))
      T_cast_2[((((((((blockIdx.z*200704) + (blockIdx.y*100352)) + (threadIdx.y*12544)) + (floordiv(blockIdx.x, 7)*896)) + (floormod(blockIdx.x, 7)*32)) + (threadIdx.x*4)) + ax4) + 448)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((int32*)compute[(ax4 + 8)], 1423657657, 31, 16, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*32) + (threadIdx.y*4)) + ax4)]), 0), 1105044667, 31, -23, dtype=int32), 127), -128))
      T_cast_2[((((((((blockIdx.z*200704) + (blockIdx.y*100352)) + (threadIdx.y*12544)) + (floordiv(blockIdx.x, 7)*896)) + (floormod(blockIdx.x, 7)*32)) + (threadIdx.x*4)) + ax4) + 672)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((int32*)compute[(ax4 + 12)], 1423657657, 31, 16, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*32) + (threadIdx.y*4)) + ax4)]), 0), 1105044667, 31, -23, dtype=int32), 127), -128))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_fixed_point_multiply_add_cast_16086763325481941859__13", "tir.noalias": True}
  buffers = {placeholder_3: Buffer(placeholder_8: handle, int8, [32, 64, 56, 56, 4], []),
             placeholder_1: Buffer(placeholder_9: handle, int32, [1, 16, 1, 1, 4], []),
             placeholder_2: Buffer(placeholder_10: handle, int8, [16, 64, 1, 1, 4, 4], []),
             placeholder: Buffer(placeholder_11: handle, int32, [1, 16, 1, 1, 4], []),
             T_cast: Buffer(T_cast_2: handle, int8, [32, 16, 56, 56, 4], [])}
  buffer_map = {placeholder_6: placeholder, T_cast_1: T_cast, placeholder_7: placeholder_1, placeholder_5: placeholder_2, placeholder_4: placeholder_3} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 16;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [16]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [512]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [1024]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 1;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 196;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 16 {
    for (oc_block.init: int32, 0, 4) {
      compute[oc_block.init] = 0
      compute[(oc_block.init + 8)] = 0
      compute[(oc_block.init + 4)] = 0
      compute[(oc_block.init + 12)] = 0
    }
    for (ic_chunk.outer: int32, 0, 4) {
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 4) {
        attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
        attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 16;
        pad_data.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*512) + (threadIdx.y_1*64)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_8[ramp(((((((((blockIdx.z*1605632) + (floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*8) + threadIdx.y_1), 16)*802816)) + (ic_chunk.outer*200704)) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*8) + threadIdx.y_1), 16)*12544)) + (floordiv(blockIdx.x, 7)*448)) + (floordiv(threadIdx.x_1, 8)*224)) + (floormod(blockIdx.x, 7)*32)) + (floormod(threadIdx.x_1, 8)*4)), 1, 4)]
      }
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 8) {
        attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 16;
        placeholder.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*512) + (threadIdx.y_2*64)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_10[ramp((((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*2048) + (floordiv(((threadIdx.y_2*4) + floordiv(threadIdx.x_2, 4)), 16)*1024)) + (ic_chunk.outer*256)) + (floormod(((threadIdx.y_2*4) + floordiv(threadIdx.x_2, 4)), 16)*16)) + (floormod(threadIdx.x_2, 4)*4)), 1, 4)]
      }
      for (ic_chunk.inner: int32, 0, 16) {
        for (oc_block: int32, 0, 4) {
          compute[oc_block] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((ic_chunk.inner*64) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.y*256) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[oc_block], dtype=int32)
          compute[(oc_block + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*64) + (threadIdx.x*4)) + 1024), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.y*256) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 8)], dtype=int32)
          compute[(oc_block + 4)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((ic_chunk.inner*64) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*256) + (ic_chunk.inner*16)) + (oc_block*4)) + 2048), 1, 4)], (int32*)compute[(oc_block + 4)], dtype=int32)
          compute[(oc_block + 12)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*64) + (threadIdx.x*4)) + 1024), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*256) + (ic_chunk.inner*16)) + (oc_block*4)) + 2048), 1, 4)], (int32*)compute[(oc_block + 12)], dtype=int32)
        }
      }
    }
    for (ax4: int32, 0, 4) {
      T_cast_2[(((((((blockIdx.z*401408) + (threadIdx.y*12544)) + (floordiv(blockIdx.x, 7)*448)) + (floordiv(threadIdx.x, 8)*224)) + (floormod(blockIdx.x, 7)*32)) + (floormod(threadIdx.x, 8)*4)) + ax4)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[ax4], 1538263139, 31, 17, dtype=int32) + (int32*)placeholder_11[((threadIdx.y*4) + ax4)]), 1073763532, 31, 1, dtype=int32) + (int32*)placeholder_9[((threadIdx.y*4) + ax4)]), 0), 1405843320, 31, -23, dtype=int32), 127), -128))
      T_cast_2[((((((((blockIdx.z*401408) + (threadIdx.y*12544)) + (floordiv(blockIdx.x, 7)*448)) + (floordiv(threadIdx.x, 8)*224)) + (floormod(blockIdx.x, 7)*32)) + (floormod(threadIdx.x, 8)*4)) + ax4) + 200704)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 8)], 1538263139, 31, 17, dtype=int32) + (int32*)placeholder_11[((threadIdx.y*4) + ax4)]), 1073763532, 31, 1, dtype=int32) + (int32*)placeholder_9[((threadIdx.y*4) + ax4)]), 0), 1405843320, 31, -23, dtype=int32), 127), -128))
      T_cast_2[((((((((blockIdx.z*401408) + (threadIdx.y*12544)) + (floordiv(blockIdx.x, 7)*448)) + (floordiv(threadIdx.x, 8)*224)) + (floormod(blockIdx.x, 7)*32)) + (floormod(threadIdx.x, 8)*4)) + ax4) + 100352)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 4)], 1538263139, 31, 17, dtype=int32) + (int32*)placeholder_11[(((threadIdx.y*4) + ax4) + 32)]), 1073763532, 31, 1, dtype=int32) + (int32*)placeholder_9[(((threadIdx.y*4) + ax4) + 32)]), 0), 1405843320, 31, -23, dtype=int32), 127), -128))
      T_cast_2[((((((((blockIdx.z*401408) + (threadIdx.y*12544)) + (floordiv(blockIdx.x, 7)*448)) + (floordiv(threadIdx.x, 8)*224)) + (floormod(blockIdx.x, 7)*32)) + (floormod(threadIdx.x, 8)*4)) + ax4) + 301056)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 12)], 1538263139, 31, 17, dtype=int32) + (int32*)placeholder_11[(((threadIdx.y*4) + ax4) + 32)]), 1073763532, 31, 1, dtype=int32) + (int32*)placeholder_9[(((threadIdx.y*4) + ax4) + 32)]), 0), 1405843320, 31, -23, dtype=int32), 127), -128))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_fixed_point_multiply_clip_cast_14", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [32, 64, 56, 56, 4], []),
             placeholder: Buffer(placeholder_2: handle, int32, [32, 64, 56, 56, 4], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer: int32, 0, 98) {
    T_cast_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = cast(int8, max(min(@tir.q_multiply_shift((int32*)placeholder_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)], 1460722492, 31, -23, dtype=int32), 127), -128))
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
primfn(placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, placeholder_8: handle, placeholder_9: handle, T_relu_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_fixed_point_multiply_add_cast_12402219635377536017__3", "tir.noalias": True}
  buffers = {placeholder_1: Buffer(placeholder_10: handle, int32, [1, 64, 1, 1, 4], []),
             placeholder_4: Buffer(placeholder_11: handle, int32, [1, 64, 1, 1, 4], []),
             placeholder: Buffer(placeholder_12: handle, int8, [32, 16, 56, 56, 4], []),
             T_relu: Buffer(T_relu_2: handle, int32, [32, 64, 56, 56, 4], []),
             placeholder_2: Buffer(placeholder_13: handle, int32, [32, 64, 56, 56, 4], []),
             placeholder_3: Buffer(placeholder_14: handle, int8, [64, 16, 1, 1, 4, 4], [])}
  buffer_map = {placeholder_5: placeholder, placeholder_8: placeholder_1, placeholder_9: placeholder_2, placeholder_6: placeholder_3, T_relu_1: T_relu, placeholder_7: placeholder_4} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 32;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [16]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [128]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [1024]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 2;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 196;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8 {
    for (oc_chunk.init: int32, 0, 2) "unroll" {
      for (oc_block.init: int32, 0, 4) "unroll" {
        compute[((oc_chunk.init*4) + oc_block.init)] = 0
        compute[(((oc_chunk.init*4) + oc_block.init) + 8)] = 0
      }
    }
    for (ic_chunk.outer: int32, 0, 2) "unroll" {
      attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8;
      pad_data.shared[ramp(((threadIdx.y_1*32) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_12[ramp((((((((blockIdx.z*200704) + (ic_chunk.outer*100352)) + (floordiv(threadIdx.y_1, 2)*12544)) + (floordiv(blockIdx.x, 7)*448)) + (floormod(threadIdx.y_1, 2)*224)) + (floormod(blockIdx.x, 7)*32)) + (threadIdx.x_1*4)), 1, 4)]
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 8) "unroll" {
        attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8;
        placeholder.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*512) + (threadIdx.y_2*32)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_14[ramp(((((((blockIdx.y*8192) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*1024)) + (floordiv(((threadIdx.y_2*2) + floordiv(threadIdx.x_2, 4)), 8)*256)) + (ic_chunk.outer*128)) + (floormod(((threadIdx.y_2*2) + floordiv(threadIdx.x_2, 4)), 8)*16)) + (floormod(threadIdx.x_2, 4)*4)), 1, 4)]
      }
      for (ic_chunk.inner: int32, 0, 8) "unroll" {
        for (oc_chunk: int32, 0, 2) "unroll" {
          for (oc_block: int32, 0, 4) "unroll" {
            compute[((oc_chunk*4) + oc_block)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((ic_chunk.inner*64) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*256) + (oc_chunk*128)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[((oc_chunk*4) + oc_block)], dtype=int32)
            compute[(((oc_chunk*4) + oc_block) + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*64) + (threadIdx.x*4)) + 32), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*256) + (oc_chunk*128)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(((oc_chunk*4) + oc_block) + 8)], dtype=int32)
          }
        }
      }
    }
    for (ax1.inner.inner.inner: int32, 0, 2) "unroll" {
      for (ax4: int32, 0, 4) "unroll" {
        T_relu_2[((((((((blockIdx.z*802816) + (blockIdx.y*401408)) + (threadIdx.y*25088)) + (ax1.inner.inner.inner*12544)) + (floordiv(blockIdx.x, 7)*448)) + (floormod(blockIdx.x, 7)*32)) + (threadIdx.x*4)) + ax4)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[((ax1.inner.inner.inner*4) + ax4)], 1439495920, 31, 18, dtype=int32) + (int32*)placeholder_11[((((blockIdx.y*128) + (threadIdx.y*8)) + (ax1.inner.inner.inner*4)) + ax4)]), 2147247346, 31, 0, dtype=int32) + (int32*)placeholder_10[((((blockIdx.y*128) + (threadIdx.y*8)) + (ax1.inner.inner.inner*4)) + ax4)]), 1919367107, 31, 0, dtype=int32) + (int32*)placeholder_13[((((((((blockIdx.z*802816) + (blockIdx.y*401408)) + (threadIdx.y*25088)) + (ax1.inner.inner.inner*12544)) + (floordiv(blockIdx.x, 7)*448)) + (floormod(blockIdx.x, 7)*32)) + (threadIdx.x*4)) + ax4)]), 0)
        T_relu_2[(((((((((blockIdx.z*802816) + (blockIdx.y*401408)) + (threadIdx.y*25088)) + (ax1.inner.inner.inner*12544)) + (floordiv(blockIdx.x, 7)*448)) + (floormod(blockIdx.x, 7)*32)) + (threadIdx.x*4)) + ax4) + 224)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(((ax1.inner.inner.inner*4) + ax4) + 8)], 1439495920, 31, 18, dtype=int32) + (int32*)placeholder_11[((((blockIdx.y*128) + (threadIdx.y*8)) + (ax1.inner.inner.inner*4)) + ax4)]), 2147247346, 31, 0, dtype=int32) + (int32*)placeholder_10[((((blockIdx.y*128) + (threadIdx.y*8)) + (ax1.inner.inner.inner*4)) + ax4)]), 1919367107, 31, 0, dtype=int32) + (int32*)placeholder_13[(((((((((blockIdx.z*802816) + (blockIdx.y*401408)) + (threadIdx.y*25088)) + (ax1.inner.inner.inner*12544)) + (floordiv(blockIdx.x, 7)*448)) + (floormod(blockIdx.x, 7)*32)) + (threadIdx.x*4)) + ax4) + 224)]), 0)
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_nn_relu_cast_fixed_point_mult_18399029763786111876__15", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [32, 16, 56, 56, 4], []),
             placeholder: Buffer(placeholder_6: handle, int8, [32, 16, 56, 56, 4], []),
             placeholder_2: Buffer(placeholder_7: handle, int32, [1, 16, 1, 1, 4], []),
             placeholder_1: Buffer(placeholder_8: handle, int8, [16, 16, 3, 3, 4, 4], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 32;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [16]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [120]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [288]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 2;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 98;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8 {
    for (oc_block.init: int32, 0, 4) "unroll" {
      compute[oc_block.init] = 0
      compute[(oc_block.init + 4)] = 0
      compute[(oc_block.init + 8)] = 0
      compute[(oc_block.init + 12)] = 0
    }
    attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
    attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
    attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8;
    if (((threadIdx.y_1*8) + threadIdx.x_1) < 60) {
      pad_data.shared[ramp(((threadIdx.y_1*32) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((1 <= ((floordiv(blockIdx.x, 7)*4) + floordiv(((threadIdx.y_1*8) + threadIdx.x_1), 10))) && (((floordiv(blockIdx.x, 7)*4) + floordiv(((threadIdx.y_1*8) + threadIdx.x_1), 10)) < 57)) && (1 <= ((floormod(blockIdx.x, 7)*8) + floormod(((threadIdx.y_1*8) + threadIdx.x_1), 10)))) && (((floormod(blockIdx.x, 7)*8) + floormod(((threadIdx.y_1*8) + threadIdx.x_1), 10)) < 57)), (int8x4*)placeholder_6[ramp(((((((blockIdx.z*200704) + (floordiv(blockIdx.x, 7)*896)) + (floordiv(((threadIdx.y_1*8) + threadIdx.x_1), 10)*224)) + (floormod(blockIdx.x, 7)*32)) + (floormod(((threadIdx.y_1*8) + threadIdx.x_1), 10)*4)) - 228), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
    }
    for (ic_chunk.outer.outer: int32, 0, 15) {
      attr [pad_data.shared] "double_buffer_write" = 1;
      attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
      attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8;
      if (((threadIdx.y_1*8) + threadIdx.x_1) < 60) {
        pad_data.shared[ramp((((floormod((ic_chunk.outer.outer + 1), 2)*240) + (threadIdx.y_1*32)) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((1 <= ((floordiv(blockIdx.x, 7)*4) + floordiv(((threadIdx.y_1*8) + threadIdx.x_1), 10))) && (((floordiv(blockIdx.x, 7)*4) + floordiv(((threadIdx.y_1*8) + threadIdx.x_1), 10)) < 57)) && (1 <= ((floormod(blockIdx.x, 7)*8) + floormod(((threadIdx.y_1*8) + threadIdx.x_1), 10)))) && (((floormod(blockIdx.x, 7)*8) + floormod(((threadIdx.y_1*8) + threadIdx.x_1), 10)) < 57)), (int8x4*)placeholder_6[ramp((((((((blockIdx.z*200704) + (ic_chunk.outer.outer*12544)) + (floordiv(blockIdx.x, 7)*896)) + (floordiv(((threadIdx.y_1*8) + threadIdx.x_1), 10)*224)) + (floormod(blockIdx.x, 7)*32)) + (floormod(((threadIdx.y_1*8) + threadIdx.x_1), 10)*4)) + 12316), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
      }
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 5) "unroll" {
        attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*16) + (threadIdx.y_2*2)) + floordiv(threadIdx.x_2, 4)) < 72) {
          if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*64) + (threadIdx.y_2*8)) + threadIdx.x_2) < 288) {
            if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*8) + threadIdx.y_2) < 36) {
              placeholder.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*256) + (threadIdx.y_2*32)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp((((((blockIdx.y*18432) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*16) + (threadIdx.y_2*2)) + floordiv(threadIdx.x_2, 4)), 9)*2304)) + (ic_chunk.outer.outer*144)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*16) + (threadIdx.y_2*2)) + floordiv(threadIdx.x_2, 4)), 9)*16)) + (floormod(threadIdx.x_2, 4)*4)), 1, 4)]
            }
          }
        }
      }
      for (kw.inner: int32, 0, 3) "unroll" {
        for (kh.inner: int32, 0, 3) "unroll" {
          for (oc_block: int32, 0, 4) "unroll" {
            compute[oc_block] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*240) + (kh.inner*40)) + (threadIdx.x*4)) + (kw.inner*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*144) + (kh.inner*48)) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[oc_block], dtype=int32)
            compute[(oc_block + 4)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*240) + (kh.inner*40)) + (threadIdx.x*4)) + (kw.inner*4)) + 40), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*144) + (kh.inner*48)) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 4)], dtype=int32)
            compute[(oc_block + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*240) + (kh.inner*40)) + (threadIdx.x*4)) + (kw.inner*4)) + 80), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*144) + (kh.inner*48)) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 8)], dtype=int32)
            compute[(oc_block + 12)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*240) + (kh.inner*40)) + (threadIdx.x*4)) + (kw.inner*4)) + 120), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*144) + (kh.inner*48)) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 12)], dtype=int32)
          }
        }
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 5) "unroll" {
      attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
      attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8;
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*16) + (threadIdx.y_2*2)) + floordiv(threadIdx.x_2, 4)) < 72) {
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*64) + (threadIdx.y_2*8)) + threadIdx.x_2) < 288) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*8) + threadIdx.y_2) < 36) {
            placeholder.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*256) + (threadIdx.y_2*32)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp((((((blockIdx.y*18432) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*16) + (threadIdx.y_2*2)) + floordiv(threadIdx.x_2, 4)), 9)*2304)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*16) + (threadIdx.y_2*2)) + floordiv(threadIdx.x_2, 4)), 9)*16)) + (floormod(threadIdx.x_2, 4)*4)) + 2160), 1, 4)]
          }
        }
      }
    }
    for (kw.inner_1: int32, 0, 3) "unroll" {
      for (kh.inner_1: int32, 0, 3) "unroll" {
        for (oc_block_1: int32, 0, 4) "unroll" {
          compute[oc_block_1] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((kh.inner_1*40) + (threadIdx.x*4)) + (kw.inner_1*4)) + 240), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*144) + (kh.inner_1*48)) + (kw.inner_1*16)) + (oc_block_1*4)), 1, 4)], (int32*)compute[oc_block_1], dtype=int32)
          compute[(oc_block_1 + 4)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((kh.inner_1*40) + (threadIdx.x*4)) + (kw.inner_1*4)) + 280), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*144) + (kh.inner_1*48)) + (kw.inner_1*16)) + (oc_block_1*4)), 1, 4)], (int32*)compute[(oc_block_1 + 4)], dtype=int32)
          compute[(oc_block_1 + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((kh.inner_1*40) + (threadIdx.x*4)) + (kw.inner_1*4)) + 320), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*144) + (kh.inner_1*48)) + (kw.inner_1*16)) + (oc_block_1*4)), 1, 4)], (int32*)compute[(oc_block_1 + 8)], dtype=int32)
          compute[(oc_block_1 + 12)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((kh.inner_1*40) + (threadIdx.x*4)) + (kw.inner_1*4)) + 360), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*144) + (kh.inner_1*48)) + (kw.inner_1*16)) + (oc_block_1*4)), 1, 4)], (int32*)compute[(oc_block_1 + 12)], dtype=int32)
        }
      }
    }
    for (ax4: int32, 0, 4) "unroll" {
      T_cast_2[(((((((blockIdx.z*200704) + (blockIdx.y*100352)) + (threadIdx.y*12544)) + (floordiv(blockIdx.x, 7)*896)) + (floormod(blockIdx.x, 7)*32)) + (threadIdx.x*4)) + ax4)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((int32*)compute[ax4], 1347813883, 31, 16, dtype=int32) + (int32*)placeholder_7[(((blockIdx.y*32) + (threadIdx.y*4)) + ax4)]), 0), 1572057641, 31, -23, dtype=int32), 127), -128))
      T_cast_2[((((((((blockIdx.z*200704) + (blockIdx.y*100352)) + (threadIdx.y*12544)) + (floordiv(blockIdx.x, 7)*896)) + (floormod(blockIdx.x, 7)*32)) + (threadIdx.x*4)) + ax4) + 224)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((int32*)compute[(ax4 + 4)], 1347813883, 31, 16, dtype=int32) + (int32*)placeholder_7[(((blockIdx.y*32) + (threadIdx.y*4)) + ax4)]), 0), 1572057641, 31, -23, dtype=int32), 127), -128))
      T_cast_2[((((((((blockIdx.z*200704) + (blockIdx.y*100352)) + (threadIdx.y*12544)) + (floordiv(blockIdx.x, 7)*896)) + (floormod(blockIdx.x, 7)*32)) + (threadIdx.x*4)) + ax4) + 448)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((int32*)compute[(ax4 + 8)], 1347813883, 31, 16, dtype=int32) + (int32*)placeholder_7[(((blockIdx.y*32) + (threadIdx.y*4)) + ax4)]), 0), 1572057641, 31, -23, dtype=int32), 127), -128))
      T_cast_2[((((((((blockIdx.z*200704) + (blockIdx.y*100352)) + (threadIdx.y*12544)) + (floordiv(blockIdx.x, 7)*896)) + (floormod(blockIdx.x, 7)*32)) + (threadIdx.x*4)) + ax4) + 672)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((int32*)compute[(ax4 + 12)], 1347813883, 31, 16, dtype=int32) + (int32*)placeholder_7[(((blockIdx.y*32) + (threadIdx.y*4)) + ax4)]), 0), 1572057641, 31, -23, dtype=int32), 127), -128))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_fixed_point_multiply_add_cast_16086763325481941859__14", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [32, 16, 56, 56, 4], []),
             placeholder_3: Buffer(placeholder_8: handle, int8, [16, 16, 1, 1, 4, 4], []),
             placeholder: Buffer(placeholder_9: handle, int32, [1, 16, 1, 1, 4], []),
             placeholder_2: Buffer(placeholder_10: handle, int32, [1, 16, 1, 1, 4], []),
             placeholder_1: Buffer(placeholder_11: handle, int8, [32, 16, 56, 56, 4], [])}
  buffer_map = {placeholder_7: placeholder, placeholder_4: placeholder_1, placeholder_6: placeholder_2, T_cast_1: T_cast, placeholder_5: placeholder_3} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 32;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [28]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [224]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [256]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 1;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 56;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 16;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 1;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8 {
    for (oc_block.init: int32, 0, 4) "unroll" {
      compute[oc_block.init] = 0
      compute[(oc_block.init + 4)] = 0
      compute[(oc_block.init + 8)] = 0
      compute[(oc_block.init + 12)] = 0
      compute[(oc_block.init + 16)] = 0
      compute[(oc_block.init + 20)] = 0
      compute[(oc_block.init + 24)] = 0
    }
    for (ic_chunk.outer: int32, 0, 4) "unroll" {
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 2) "unroll" {
        attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 16;
        attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 1;
        attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*8)) + threadIdx.x_1) < 224) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*16) + threadIdx.z_1) < 28) {
            pad_data.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*512) + (threadIdx.z_1*32)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_11[ramp((((((blockIdx.z*200704) + (ic_chunk.outer*50176)) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*8)) + threadIdx.x_1), 56)*12544)) + (blockIdx.x*224)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*8)) + threadIdx.x_1), 56)*4)), 1, 4)]
          }
        }
      }
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 2) "unroll" {
        attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 16;
        attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 1;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8;
        placeholder.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*512) + (threadIdx.z_2*32)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp((((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*2048) + (floordiv(((threadIdx.z_2*2) + floordiv(threadIdx.x_2, 4)), 4)*256)) + (ic_chunk.outer*64)) + (floormod(((threadIdx.z_2*2) + floordiv(threadIdx.x_2, 4)), 4)*16)) + (floormod(threadIdx.x_2, 4)*4)), 1, 4)]
      }
      for (ic_chunk.inner: int32, 0, 4) "unroll" {
        for (oc_block: int32, 0, 4) "unroll" {
          compute[oc_block] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((ic_chunk.inner*224) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*64) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[oc_block], dtype=int32)
          compute[(oc_block + 4)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*224) + (threadIdx.x*4)) + 32), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*64) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 4)], dtype=int32)
          compute[(oc_block + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*224) + (threadIdx.x*4)) + 64), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*64) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 8)], dtype=int32)
          compute[(oc_block + 12)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*224) + (threadIdx.x*4)) + 96), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*64) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 12)], dtype=int32)
          compute[(oc_block + 16)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*224) + (threadIdx.x*4)) + 128), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*64) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 16)], dtype=int32)
          compute[(oc_block + 20)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*224) + (threadIdx.x*4)) + 160), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*64) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 20)], dtype=int32)
          compute[(oc_block + 24)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*224) + (threadIdx.x*4)) + 192), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*64) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 24)], dtype=int32)
        }
      }
    }
    for (ax4: int32, 0, 4) "unroll" {
      T_cast_2[(((((blockIdx.z*200704) + (threadIdx.z*12544)) + (blockIdx.x*224)) + (threadIdx.x*4)) + ax4)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[ax4], 1835168984, 31, 17, dtype=int32) + (int32*)placeholder_10[((threadIdx.z*4) + ax4)]), 1073745048, 31, 1, dtype=int32) + (int32*)placeholder_9[((threadIdx.z*4) + ax4)]), 0), 1459213935, 31, -22, dtype=int32), 127), -128))
      T_cast_2[((((((blockIdx.z*200704) + (threadIdx.z*12544)) + (blockIdx.x*224)) + (threadIdx.x*4)) + ax4) + 32)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 4)], 1835168984, 31, 17, dtype=int32) + (int32*)placeholder_10[((threadIdx.z*4) + ax4)]), 1073745048, 31, 1, dtype=int32) + (int32*)placeholder_9[((threadIdx.z*4) + ax4)]), 0), 1459213935, 31, -22, dtype=int32), 127), -128))
      T_cast_2[((((((blockIdx.z*200704) + (threadIdx.z*12544)) + (blockIdx.x*224)) + (threadIdx.x*4)) + ax4) + 64)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 8)], 1835168984, 31, 17, dtype=int32) + (int32*)placeholder_10[((threadIdx.z*4) + ax4)]), 1073745048, 31, 1, dtype=int32) + (int32*)placeholder_9[((threadIdx.z*4) + ax4)]), 0), 1459213935, 31, -22, dtype=int32), 127), -128))
      T_cast_2[((((((blockIdx.z*200704) + (threadIdx.z*12544)) + (blockIdx.x*224)) + (threadIdx.x*4)) + ax4) + 96)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 12)], 1835168984, 31, 17, dtype=int32) + (int32*)placeholder_10[((threadIdx.z*4) + ax4)]), 1073745048, 31, 1, dtype=int32) + (int32*)placeholder_9[((threadIdx.z*4) + ax4)]), 0), 1459213935, 31, -22, dtype=int32), 127), -128))
      T_cast_2[((((((blockIdx.z*200704) + (threadIdx.z*12544)) + (blockIdx.x*224)) + (threadIdx.x*4)) + ax4) + 128)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 16)], 1835168984, 31, 17, dtype=int32) + (int32*)placeholder_10[((threadIdx.z*4) + ax4)]), 1073745048, 31, 1, dtype=int32) + (int32*)placeholder_9[((threadIdx.z*4) + ax4)]), 0), 1459213935, 31, -22, dtype=int32), 127), -128))
      T_cast_2[((((((blockIdx.z*200704) + (threadIdx.z*12544)) + (blockIdx.x*224)) + (threadIdx.x*4)) + ax4) + 160)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 20)], 1835168984, 31, 17, dtype=int32) + (int32*)placeholder_10[((threadIdx.z*4) + ax4)]), 1073745048, 31, 1, dtype=int32) + (int32*)placeholder_9[((threadIdx.z*4) + ax4)]), 0), 1459213935, 31, -22, dtype=int32), 127), -128))
      T_cast_2[((((((blockIdx.z*200704) + (threadIdx.z*12544)) + (blockIdx.x*224)) + (threadIdx.x*4)) + ax4) + 192)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 24)], 1835168984, 31, 17, dtype=int32) + (int32*)placeholder_10[((threadIdx.z*4) + ax4)]), 1073745048, 31, 1, dtype=int32) + (int32*)placeholder_9[((threadIdx.z*4) + ax4)]), 0), 1459213935, 31, -22, dtype=int32), 127), -128))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op right_shift
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_add_right_shift_clip_cast", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [32, 16, 56, 56, 4], []),
             placeholder: Buffer(placeholder_2: handle, int32, [32, 16, 56, 56, 4], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer: int32, 0, 25) {
    if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*65536) + (blockIdx.x*256)) + floordiv(threadIdx.x, 4)) < 1605632) {
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x) < 6422528) {
        T_cast_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = cast(int8, min(@tir.shift_right(((int32*)placeholder_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] + 8388608), 24, dtype=int32), 127))
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation pool.cuda for op nn.max_pool2d
primfn(placeholder_1: handle, tensor_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_max_pool2d_1", "tir.noalias": True}
  buffers = {tensor: Buffer(tensor_2: handle, int32, [32, 16, 56, 56, 4], []),
             placeholder: Buffer(placeholder_2: handle, int32, [32, 16, 112, 112, 4], [])}
  buffer_map = {placeholder_1: placeholder, tensor_1: tensor} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 6272;
  attr [tensor.local: handle] "storage_scope" = "local";
  allocate(tensor.local, int32, [1]);
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
    tensor.local[0] = -2147483648
    for (rv: int32, 0, 3) {
      for (rv_1: int32, 0, 3) {
        tensor.local[0] = max((int32*)tensor.local[0], @tir.if_then_else(((1 <= ((floordiv(floormod(((blockIdx.x*256) + floordiv(threadIdx.x, 4)), 3136), 56)*2) + rv)) && (1 <= ((floormod(((blockIdx.x*256) + floordiv(threadIdx.x, 4)), 56)*2) + rv_1))), (int32*)placeholder_2[((((((floordiv(((blockIdx.x*256) + floordiv(threadIdx.x, 4)), 56)*896) + (rv*448)) + (floormod(((blockIdx.x*256) + floordiv(threadIdx.x, 4)), 56)*8)) + (rv_1*4)) + floormod(threadIdx.x, 4)) - 452)], -2147483648, dtype=int32))
      }
    }
    tensor_2[((blockIdx.x*1024) + threadIdx.x)] = (int32*)tensor.local[0]
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_nn_relu_cast_fixed_point_mult_6343854372805914660_", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [32, 16, 112, 112, 4], []),
             placeholder: Buffer(placeholder_6: handle, int8, [32, 1, 224, 224, 4], []),
             placeholder_2: Buffer(placeholder_7: handle, int32, [1, 16, 1, 1, 4], []),
             placeholder_1: Buffer(placeholder_8: handle, int8, [16, 1, 7, 7, 4, 4], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, compute_1: compute} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 32;
  attr [compute_3: handle] "storage_scope" = "local";
  allocate(compute_3, int32, [28]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [234]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [448]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 1;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 224;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 16;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 1;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8 {
    for (oc_block.init: int32, 0, 4) "unroll" {
      compute_3[oc_block.init] = 0
      compute_3[(oc_block.init + 4)] = 0
      compute_3[(oc_block.init + 8)] = 0
      compute_3[(oc_block.init + 12)] = 0
      compute_3[(oc_block.init + 16)] = 0
      compute_3[(oc_block.init + 20)] = 0
      compute_3[(oc_block.init + 24)] = 0
    }
    attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 16;
    attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 1;
    attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8;
    if (((threadIdx.z_1*8) + threadIdx.x_1) < 117) {
      if (threadIdx.z_1 < 15) {
        pad_data.shared[ramp(((threadIdx.z_1*32) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else((((4 <= blockIdx.x) && (3 <= (((floormod(blockIdx.x, 2)*112) + (threadIdx.z_1*8)) + threadIdx.x_1))) && ((((floormod(blockIdx.x, 2)*112) + (threadIdx.z_1*8)) + threadIdx.x_1) < 227)), (int8x4*)placeholder_6[ramp(((((((blockIdx.z*200704) + (floordiv(blockIdx.x, 2)*1792)) + (floormod(blockIdx.x, 2)*448)) + (threadIdx.z_1*32)) + (threadIdx.x_1*4)) - 2700), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
      }
    }
    for (kh.outer.outer: int32, 0, 6) {
      attr [pad_data.shared] "double_buffer_write" = 1;
      attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 16;
      attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 1;
      attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8;
      if (((threadIdx.z_1*8) + threadIdx.x_1) < 117) {
        if (threadIdx.z_1 < 15) {
          pad_data.shared[ramp((((floormod((kh.outer.outer + 1), 2)*468) + (threadIdx.z_1*32)) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((2 <= ((floordiv(blockIdx.x, 2)*2) + kh.outer.outer)) && (((floordiv(blockIdx.x, 2)*2) + kh.outer.outer) < 226)) && (3 <= (((floormod(blockIdx.x, 2)*112) + (threadIdx.z_1*8)) + threadIdx.x_1))) && ((((floormod(blockIdx.x, 2)*112) + (threadIdx.z_1*8)) + threadIdx.x_1) < 227)), (int8x4*)placeholder_6[ramp((((((((blockIdx.z*200704) + (floordiv(blockIdx.x, 2)*1792)) + (kh.outer.outer*896)) + (floormod(blockIdx.x, 2)*448)) + (threadIdx.z_1*32)) + (threadIdx.x_1*4)) - 1804), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
        }
      }
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 4) "unroll" {
        attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 16;
        attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 1;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.z_2*2)) + floordiv(threadIdx.x_2, 4)) < 112) {
          if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*128) + (threadIdx.z_2*8)) + threadIdx.x_2) < 448) {
            if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*16) + threadIdx.z_2) < 56) {
              placeholder.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*512) + (threadIdx.z_2*32)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp(((((floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.z_2*2)) + floordiv(threadIdx.x_2, 4)), 7)*784) + (kh.outer.outer*112)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.z_2*2)) + floordiv(threadIdx.x_2, 4)), 7)*16)) + (floormod(threadIdx.x_2, 4)*4)), 1, 4)]
            }
          }
        }
      }
      for (kw.inner: int32, 0, 7) "unroll" {
        for (oc_block: int32, 0, 4) "unroll" {
          compute_3[oc_block] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((floormod(kh.outer.outer, 2)*468) + (threadIdx.x*8)) + (kw.inner*4)), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*112) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute_3[oc_block], dtype=int32)
          compute_3[(oc_block + 4)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floormod(kh.outer.outer, 2)*468) + (threadIdx.x*8)) + (kw.inner*4)) + 64), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*112) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute_3[(oc_block + 4)], dtype=int32)
          compute_3[(oc_block + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floormod(kh.outer.outer, 2)*468) + (threadIdx.x*8)) + (kw.inner*4)) + 128), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*112) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute_3[(oc_block + 8)], dtype=int32)
          compute_3[(oc_block + 12)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floormod(kh.outer.outer, 2)*468) + (threadIdx.x*8)) + (kw.inner*4)) + 192), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*112) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute_3[(oc_block + 12)], dtype=int32)
          compute_3[(oc_block + 16)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floormod(kh.outer.outer, 2)*468) + (threadIdx.x*8)) + (kw.inner*4)) + 256), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*112) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute_3[(oc_block + 16)], dtype=int32)
          compute_3[(oc_block + 20)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floormod(kh.outer.outer, 2)*468) + (threadIdx.x*8)) + (kw.inner*4)) + 320), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*112) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute_3[(oc_block + 20)], dtype=int32)
          compute_3[(oc_block + 24)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floormod(kh.outer.outer, 2)*468) + (threadIdx.x*8)) + (kw.inner*4)) + 384), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*112) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute_3[(oc_block + 24)], dtype=int32)
        }
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 4) "unroll" {
      attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 16;
      attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 1;
      attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8;
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.z_2*2)) + floordiv(threadIdx.x_2, 4)) < 112) {
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_2*8)) + threadIdx.x_2) < 448) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*16) + threadIdx.z_2) < 56) {
            placeholder.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*512) + (threadIdx.z_2*32)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp(((((floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.z_2*2)) + floordiv(threadIdx.x_2, 4)), 7)*784) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.z_2*2)) + floordiv(threadIdx.x_2, 4)), 7)*16)) + (floormod(threadIdx.x_2, 4)*4)) + 672), 1, 4)]
          }
        }
      }
    }
    for (kw.inner_1: int32, 0, 7) "unroll" {
      for (oc_block_1: int32, 0, 4) "unroll" {
        compute_3[oc_block_1] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((threadIdx.x*8) + (kw.inner_1*4)), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*112) + (kw.inner_1*16)) + (oc_block_1*4)), 1, 4)], (int32*)compute_3[oc_block_1], dtype=int32)
        compute_3[(oc_block_1 + 4)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((threadIdx.x*8) + (kw.inner_1*4)) + 64), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*112) + (kw.inner_1*16)) + (oc_block_1*4)), 1, 4)], (int32*)compute_3[(oc_block_1 + 4)], dtype=int32)
        compute_3[(oc_block_1 + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((threadIdx.x*8) + (kw.inner_1*4)) + 128), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*112) + (kw.inner_1*16)) + (oc_block_1*4)), 1, 4)], (int32*)compute_3[(oc_block_1 + 8)], dtype=int32)
        compute_3[(oc_block_1 + 12)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((threadIdx.x*8) + (kw.inner_1*4)) + 192), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*112) + (kw.inner_1*16)) + (oc_block_1*4)), 1, 4)], (int32*)compute_3[(oc_block_1 + 12)], dtype=int32)
        compute_3[(oc_block_1 + 16)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((threadIdx.x*8) + (kw.inner_1*4)) + 256), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*112) + (kw.inner_1*16)) + (oc_block_1*4)), 1, 4)], (int32*)compute_3[(oc_block_1 + 16)], dtype=int32)
        compute_3[(oc_block_1 + 20)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((threadIdx.x*8) + (kw.inner_1*4)) + 320), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*112) + (kw.inner_1*16)) + (oc_block_1*4)), 1, 4)], (int32*)compute_3[(oc_block_1 + 20)], dtype=int32)
        compute_3[(oc_block_1 + 24)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((threadIdx.x*8) + (kw.inner_1*4)) + 384), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*112) + (kw.inner_1*16)) + (oc_block_1*4)), 1, 4)], (int32*)compute_3[(oc_block_1 + 24)], dtype=int32)
      }
    }
    for (i4: int32, 0, 4) "unroll" {
      compute_2[(((((blockIdx.z*802816) + (threadIdx.z*50176)) + (blockIdx.x*224)) + (threadIdx.x*4)) + i4)] = @tir.q_multiply_shift(max((@tir.q_multiply_shift((int32*)compute_3[i4], 1398627452, 31, 15, dtype=int32) + (int32*)placeholder_7[((threadIdx.z*4) + i4)]), 0), 2073482884, 31, 0, dtype=int32)
      compute_2[((((((blockIdx.z*802816) + (threadIdx.z*50176)) + (blockIdx.x*224)) + (threadIdx.x*4)) + i4) + 32)] = @tir.q_multiply_shift(max((@tir.q_multiply_shift((int32*)compute_3[(i4 + 4)], 1398627452, 31, 15, dtype=int32) + (int32*)placeholder_7[((threadIdx.z*4) + i4)]), 0), 2073482884, 31, 0, dtype=int32)
      compute_2[((((((blockIdx.z*802816) + (threadIdx.z*50176)) + (blockIdx.x*224)) + (threadIdx.x*4)) + i4) + 64)] = @tir.q_multiply_shift(max((@tir.q_multiply_shift((int32*)compute_3[(i4 + 8)], 1398627452, 31, 15, dtype=int32) + (int32*)placeholder_7[((threadIdx.z*4) + i4)]), 0), 2073482884, 31, 0, dtype=int32)
      compute_2[((((((blockIdx.z*802816) + (threadIdx.z*50176)) + (blockIdx.x*224)) + (threadIdx.x*4)) + i4) + 96)] = @tir.q_multiply_shift(max((@tir.q_multiply_shift((int32*)compute_3[(i4 + 12)], 1398627452, 31, 15, dtype=int32) + (int32*)placeholder_7[((threadIdx.z*4) + i4)]), 0), 2073482884, 31, 0, dtype=int32)
      compute_2[((((((blockIdx.z*802816) + (threadIdx.z*50176)) + (blockIdx.x*224)) + (threadIdx.x*4)) + i4) + 128)] = @tir.q_multiply_shift(max((@tir.q_multiply_shift((int32*)compute_3[(i4 + 16)], 1398627452, 31, 15, dtype=int32) + (int32*)placeholder_7[((threadIdx.z*4) + i4)]), 0), 2073482884, 31, 0, dtype=int32)
      compute_2[((((((blockIdx.z*802816) + (threadIdx.z*50176)) + (blockIdx.x*224)) + (threadIdx.x*4)) + i4) + 160)] = @tir.q_multiply_shift(max((@tir.q_multiply_shift((int32*)compute_3[(i4 + 20)], 1398627452, 31, 15, dtype=int32) + (int32*)placeholder_7[((threadIdx.z*4) + i4)]), 0), 2073482884, 31, 0, dtype=int32)
      compute_2[((((((blockIdx.z*802816) + (threadIdx.z*50176)) + (blockIdx.x*224)) + (threadIdx.x*4)) + i4) + 192)] = @tir.q_multiply_shift(max((@tir.q_multiply_shift((int32*)compute_3[(i4 + 24)], 1398627452, 31, 15, dtype=int32) + (int32*)placeholder_7[((threadIdx.z*4) + i4)]), 0), 2073482884, 31, 0, dtype=int32)
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cuda for op divide
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op round
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.pad
INFO:compile_engine:Use implementation injective.cuda for op layout_transform
primfn(placeholder_1: handle, T_layout_trans_1: handle) -> ()
  attr = {"global_symbol": "fused_divide_add_round_cast_clip_cast_nn_pad_layout_transform", "tir.noalias": True}
  buffers = {T_layout_trans: Buffer(T_layout_trans_2: handle, int8, [32, 1, 224, 224, 4], []),
             placeholder: Buffer(placeholder_2: handle, float32, [32, 3, 224, 224], [])}
  buffer_map = {placeholder_1: placeholder, T_layout_trans_1: T_layout_trans} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer: int32, 0, 25) {
    if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*65536) + (blockIdx.x*256)) + floordiv(threadIdx.x, 4)) < 1605632) {
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x) < 6422528) {
        T_layout_trans_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = @tir.if_then_else((floormod(threadIdx.x, 4) < 3), cast(int8, max(min(cast(int32, @tir.round(((float32*)placeholder_2[(((floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*65536) + (blockIdx.x*256)) + floordiv(threadIdx.x, 4)), 50176)*150528) + (floormod(threadIdx.x, 4)*50176)) + floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*65536) + (blockIdx.x*256)) + floordiv(threadIdx.x, 4)), 50176))]*48.6161f32), dtype=float32)), 127), -128)), 0i8, dtype=int8)
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_fixed_point_multiply", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [32, 64, 56, 56, 4], []),
             placeholder_2: Buffer(placeholder_6: handle, int32, [1, 64, 1, 1, 4], []),
             placeholder: Buffer(placeholder_7: handle, int8, [32, 16, 56, 56, 4], []),
             placeholder_1: Buffer(placeholder_8: handle, int8, [64, 16, 1, 1, 4, 4], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, compute_1: compute} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 32;
  attr [compute_3: handle] "storage_scope" = "local";
  allocate(compute_3, int32, [16]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [128]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [1024]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 2;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 196;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8 {
    for (oc_chunk.init: int32, 0, 2) "unroll" {
      for (oc_block.init: int32, 0, 4) "unroll" {
        compute_3[((oc_chunk.init*4) + oc_block.init)] = 0
        compute_3[(((oc_chunk.init*4) + oc_block.init) + 8)] = 0
      }
    }
    for (ic_chunk.outer: int32, 0, 2) "unroll" {
      attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8;
      pad_data.shared[ramp(((threadIdx.y_1*32) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_7[ramp((((((((blockIdx.z*200704) + (ic_chunk.outer*100352)) + (floordiv(threadIdx.y_1, 2)*12544)) + (floordiv(blockIdx.x, 7)*448)) + (floormod(threadIdx.y_1, 2)*224)) + (floormod(blockIdx.x, 7)*32)) + (threadIdx.x_1*4)), 1, 4)]
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 8) "unroll" {
        attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8;
        placeholder.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*512) + (threadIdx.y_2*32)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp(((((((blockIdx.y*8192) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*1024)) + (floordiv(((threadIdx.y_2*2) + floordiv(threadIdx.x_2, 4)), 8)*256)) + (ic_chunk.outer*128)) + (floormod(((threadIdx.y_2*2) + floordiv(threadIdx.x_2, 4)), 8)*16)) + (floormod(threadIdx.x_2, 4)*4)), 1, 4)]
      }
      for (ic_chunk.inner: int32, 0, 8) "unroll" {
        for (oc_chunk: int32, 0, 2) "unroll" {
          for (oc_block: int32, 0, 4) "unroll" {
            compute_3[((oc_chunk*4) + oc_block)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((ic_chunk.inner*64) + (threadIdx.x*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*256) + (oc_chunk*128)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute_3[((oc_chunk*4) + oc_block)], dtype=int32)
            compute_3[(((oc_chunk*4) + oc_block) + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*64) + (threadIdx.x*4)) + 32), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*256) + (oc_chunk*128)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute_3[(((oc_chunk*4) + oc_block) + 8)], dtype=int32)
          }
        }
      }
    }
    for (i1.inner.inner.inner: int32, 0, 2) "unroll" {
      for (i4: int32, 0, 4) "unroll" {
        compute_2[((((((((blockIdx.z*802816) + (blockIdx.y*401408)) + (threadIdx.y*25088)) + (i1.inner.inner.inner*12544)) + (floordiv(blockIdx.x, 7)*448)) + (floormod(blockIdx.x, 7)*32)) + (threadIdx.x*4)) + i4)] = @tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute_3[((i1.inner.inner.inner*4) + i4)], 1601687472, 31, 18, dtype=int32) + (int32*)placeholder_6[((((blockIdx.y*128) + (threadIdx.y*8)) + (i1.inner.inner.inner*4)) + i4)]), 1144303500, 31, 1, dtype=int32)
        compute_2[(((((((((blockIdx.z*802816) + (blockIdx.y*401408)) + (threadIdx.y*25088)) + (i1.inner.inner.inner*12544)) + (floordiv(blockIdx.x, 7)*448)) + (floormod(blockIdx.x, 7)*32)) + (threadIdx.x*4)) + i4) + 224)] = @tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute_3[(((i1.inner.inner.inner*4) + i4) + 8)], 1601687472, 31, 18, dtype=int32) + (int32*)placeholder_6[((((blockIdx.y*128) + (threadIdx.y*8)) + (i1.inner.inner.inner*4)) + i4)]), 1144303500, 31, 1, dtype=int32)
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_fixed_point_multiply_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [32, 128, 28, 28, 4], []),
             placeholder_2: Buffer(placeholder_6: handle, int32, [1, 128, 1, 1, 4], []),
             placeholder: Buffer(placeholder_7: handle, int8, [32, 64, 56, 56, 4], []),
             placeholder_1: Buffer(placeholder_8: handle, int8, [128, 64, 1, 1, 4, 4], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, compute_1: compute} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 32;
  attr [compute_3: handle] "storage_scope" = "local";
  allocate(compute_3, int32, [28]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [440]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [1024]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 4;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 28;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 32;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 1;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4 {
    for (oc_block.init: int32, 0, 4) "unroll" {
      compute_3[oc_block.init] = 0
      compute_3[(oc_block.init + 4)] = 0
      compute_3[(oc_block.init + 8)] = 0
      compute_3[(oc_block.init + 12)] = 0
      compute_3[(oc_block.init + 16)] = 0
      compute_3[(oc_block.init + 20)] = 0
      compute_3[(oc_block.init + 24)] = 0
    }
    for (ic_chunk.outer: int32, 0, 8) {
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 4) "unroll" {
        attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 32;
        attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 1;
        attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*4)) + threadIdx.x_1) < 440) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*32) + threadIdx.z_1) < 110) {
            pad_data.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*512) + (threadIdx.z_1*16)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_7[ramp((((((blockIdx.z*802816) + (ic_chunk.outer*100352)) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*4)) + threadIdx.x_1), 55)*12544)) + (blockIdx.x*448)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*4)) + threadIdx.x_1), 55)*4)), 1, 4)]
          }
        }
      }
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 8) "unroll" {
        attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 32;
        attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 1;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
        placeholder.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*512) + (threadIdx.z_2*16)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp(((((((blockIdx.y*32768) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*4096)) + (floordiv(threadIdx.z_2, 8)*1024)) + (ic_chunk.outer*128)) + (floormod(threadIdx.z_2, 8)*16)) + (threadIdx.x_2*4)), 1, 4)]
      }
      for (ic_chunk.inner: int32, 0, 8) "unroll" {
        for (oc_block: int32, 0, 4) "unroll" {
          compute_3[oc_block] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((ic_chunk.inner*220) + (threadIdx.x*8)), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*128) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute_3[oc_block], dtype=int32)
          compute_3[(oc_block + 4)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*220) + (threadIdx.x*8)) + 32), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*128) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute_3[(oc_block + 4)], dtype=int32)
          compute_3[(oc_block + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*220) + (threadIdx.x*8)) + 64), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*128) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute_3[(oc_block + 8)], dtype=int32)
          compute_3[(oc_block + 12)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*220) + (threadIdx.x*8)) + 96), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*128) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute_3[(oc_block + 12)], dtype=int32)
          compute_3[(oc_block + 16)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*220) + (threadIdx.x*8)) + 128), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*128) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute_3[(oc_block + 16)], dtype=int32)
          compute_3[(oc_block + 20)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*220) + (threadIdx.x*8)) + 160), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*128) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute_3[(oc_block + 20)], dtype=int32)
          compute_3[(oc_block + 24)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*220) + (threadIdx.x*8)) + 192), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*128) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute_3[(oc_block + 24)], dtype=int32)
        }
      }
    }
    for (i4: int32, 0, 4) "unroll" {
      compute_2[((((((blockIdx.z*401408) + (blockIdx.y*100352)) + (threadIdx.z*3136)) + (blockIdx.x*112)) + (threadIdx.x*4)) + i4)] = @tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute_3[i4], 1187934683, 31, 18, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*128) + (threadIdx.z*4)) + i4)]), 1142567522, 31, 1, dtype=int32)
      compute_2[(((((((blockIdx.z*401408) + (blockIdx.y*100352)) + (threadIdx.z*3136)) + (blockIdx.x*112)) + (threadIdx.x*4)) + i4) + 16)] = @tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute_3[(i4 + 4)], 1187934683, 31, 18, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*128) + (threadIdx.z*4)) + i4)]), 1142567522, 31, 1, dtype=int32)
      compute_2[(((((((blockIdx.z*401408) + (blockIdx.y*100352)) + (threadIdx.z*3136)) + (blockIdx.x*112)) + (threadIdx.x*4)) + i4) + 32)] = @tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute_3[(i4 + 8)], 1187934683, 31, 18, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*128) + (threadIdx.z*4)) + i4)]), 1142567522, 31, 1, dtype=int32)
      compute_2[(((((((blockIdx.z*401408) + (blockIdx.y*100352)) + (threadIdx.z*3136)) + (blockIdx.x*112)) + (threadIdx.x*4)) + i4) + 48)] = @tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute_3[(i4 + 12)], 1187934683, 31, 18, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*128) + (threadIdx.z*4)) + i4)]), 1142567522, 31, 1, dtype=int32)
      compute_2[(((((((blockIdx.z*401408) + (blockIdx.y*100352)) + (threadIdx.z*3136)) + (blockIdx.x*112)) + (threadIdx.x*4)) + i4) + 64)] = @tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute_3[(i4 + 16)], 1187934683, 31, 18, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*128) + (threadIdx.z*4)) + i4)]), 1142567522, 31, 1, dtype=int32)
      compute_2[(((((((blockIdx.z*401408) + (blockIdx.y*100352)) + (threadIdx.z*3136)) + (blockIdx.x*112)) + (threadIdx.x*4)) + i4) + 80)] = @tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute_3[(i4 + 20)], 1187934683, 31, 18, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*128) + (threadIdx.z*4)) + i4)]), 1142567522, 31, 1, dtype=int32)
      compute_2[(((((((blockIdx.z*401408) + (blockIdx.y*100352)) + (threadIdx.z*3136)) + (blockIdx.x*112)) + (threadIdx.x*4)) + i4) + 96)] = @tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute_3[(i4 + 24)], 1187934683, 31, 18, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*128) + (threadIdx.z*4)) + i4)]), 1142567522, 31, 1, dtype=int32)
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_fixed_point_multiply_2", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [32, 256, 14, 14, 4], []),
             placeholder_2: Buffer(placeholder_6: handle, int32, [1, 256, 1, 1, 4], []),
             placeholder: Buffer(placeholder_7: handle, int8, [32, 128, 28, 28, 4], []),
             placeholder_1: Buffer(placeholder_8: handle, int8, [256, 128, 1, 1, 4, 4], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, compute_1: compute} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 32;
  attr [compute_3: handle] "storage_scope" = "local";
  allocate(compute_3, int32, [28]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [1296]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [2048]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 8;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 7;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 32;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4 {
    for (oc_block.init: int32, 0, 4) "unroll" {
      compute_3[oc_block.init] = 0
      compute_3[(oc_block.init + 4)] = 0
      compute_3[(oc_block.init + 8)] = 0
      compute_3[(oc_block.init + 12)] = 0
      compute_3[(oc_block.init + 16)] = 0
      compute_3[(oc_block.init + 20)] = 0
      compute_3[(oc_block.init + 24)] = 0
    }
    for (ic_chunk.outer: int32, 0, 8) {
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 11) "unroll" {
        attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 32;
        attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.y_1*4)) + threadIdx.x_1) < 1296) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*32) + threadIdx.y_1) < 324) {
            pad_data.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*512) + (threadIdx.y_1*16)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_7[ramp(((((((blockIdx.z*401408) + (ic_chunk.outer*50176)) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.y_1*4)) + threadIdx.x_1), 81)*3136)) + (blockIdx.x*448)) + (floordiv(floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.y_1*4)) + threadIdx.x_1), 81), 27)*112)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.y_1*4)) + threadIdx.x_1), 27)*4)), 1, 4)]
          }
        }
      }
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 16) "unroll" {
        attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 32;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
        placeholder.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*512) + (threadIdx.y_2*16)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp(((((((blockIdx.y*65536) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*4096)) + (floordiv(threadIdx.y_2, 16)*2048)) + (ic_chunk.outer*256)) + (floormod(threadIdx.y_2, 16)*16)) + (threadIdx.x_2*4)), 1, 4)]
      }
      for (ic_chunk.inner: int32, 0, 16) "unroll" {
        for (oc_block: int32, 0, 4) "unroll" {
          compute_3[oc_block] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((ic_chunk.inner*324) + (floordiv(threadIdx.x, 2)*216)) + (floormod(threadIdx.x, 2)*8)), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.y*256) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute_3[oc_block], dtype=int32)
          compute_3[(oc_block + 4)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((ic_chunk.inner*324) + (floordiv(threadIdx.x, 2)*216)) + (floormod(threadIdx.x, 2)*8)) + 16), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.y*256) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute_3[(oc_block + 4)], dtype=int32)
          compute_3[(oc_block + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((ic_chunk.inner*324) + (floordiv(threadIdx.x, 2)*216)) + (floormod(threadIdx.x, 2)*8)) + 32), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.y*256) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute_3[(oc_block + 8)], dtype=int32)
          compute_3[(oc_block + 12)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((ic_chunk.inner*324) + (floordiv(threadIdx.x, 2)*216)) + (floormod(threadIdx.x, 2)*8)) + 48), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.y*256) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute_3[(oc_block + 12)], dtype=int32)
          compute_3[(oc_block + 16)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((ic_chunk.inner*324) + (floordiv(threadIdx.x, 2)*216)) + (floormod(threadIdx.x, 2)*8)) + 64), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.y*256) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute_3[(oc_block + 16)], dtype=int32)
          compute_3[(oc_block + 20)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((ic_chunk.inner*324) + (floordiv(threadIdx.x, 2)*216)) + (floormod(threadIdx.x, 2)*8)) + 80), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.y*256) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute_3[(oc_block + 20)], dtype=int32)
          compute_3[(oc_block + 24)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((ic_chunk.inner*324) + (floordiv(threadIdx.x, 2)*216)) + (floormod(threadIdx.x, 2)*8)) + 96), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.y*256) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute_3[(oc_block + 24)], dtype=int32)
        }
      }
    }
    for (i4: int32, 0, 4) "unroll" {
      compute_2[(((((((blockIdx.z*200704) + (blockIdx.y*25088)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (floordiv(threadIdx.x, 2)*56)) + (floormod(threadIdx.x, 2)*4)) + i4)] = @tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute_3[i4], 1952966745, 31, 17, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*128) + (threadIdx.y*4)) + i4)]), 1104238933, 31, 1, dtype=int32)
      compute_2[((((((((blockIdx.z*200704) + (blockIdx.y*25088)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (floordiv(threadIdx.x, 2)*56)) + (floormod(threadIdx.x, 2)*4)) + i4) + 8)] = @tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute_3[(i4 + 4)], 1952966745, 31, 17, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*128) + (threadIdx.y*4)) + i4)]), 1104238933, 31, 1, dtype=int32)
      compute_2[((((((((blockIdx.z*200704) + (blockIdx.y*25088)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (floordiv(threadIdx.x, 2)*56)) + (floormod(threadIdx.x, 2)*4)) + i4) + 16)] = @tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute_3[(i4 + 8)], 1952966745, 31, 17, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*128) + (threadIdx.y*4)) + i4)]), 1104238933, 31, 1, dtype=int32)
      compute_2[((((((((blockIdx.z*200704) + (blockIdx.y*25088)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (floordiv(threadIdx.x, 2)*56)) + (floormod(threadIdx.x, 2)*4)) + i4) + 24)] = @tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute_3[(i4 + 12)], 1952966745, 31, 17, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*128) + (threadIdx.y*4)) + i4)]), 1104238933, 31, 1, dtype=int32)
      compute_2[((((((((blockIdx.z*200704) + (blockIdx.y*25088)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (floordiv(threadIdx.x, 2)*56)) + (floormod(threadIdx.x, 2)*4)) + i4) + 32)] = @tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute_3[(i4 + 16)], 1952966745, 31, 17, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*128) + (threadIdx.y*4)) + i4)]), 1104238933, 31, 1, dtype=int32)
      compute_2[((((((((blockIdx.z*200704) + (blockIdx.y*25088)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (floordiv(threadIdx.x, 2)*56)) + (floormod(threadIdx.x, 2)*4)) + i4) + 40)] = @tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute_3[(i4 + 20)], 1952966745, 31, 17, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*128) + (threadIdx.y*4)) + i4)]), 1104238933, 31, 1, dtype=int32)
      compute_2[((((((((blockIdx.z*200704) + (blockIdx.y*25088)) + (threadIdx.y*784)) + (blockIdx.x*112)) + (floordiv(threadIdx.x, 2)*56)) + (floormod(threadIdx.x, 2)*4)) + i4) + 48)] = @tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute_3[(i4 + 24)], 1952966745, 31, 17, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*128) + (threadIdx.y*4)) + i4)]), 1104238933, 31, 1, dtype=int32)
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_fixed_point_multiply_3", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [32, 512, 7, 7, 4], []),
             placeholder_2: Buffer(placeholder_6: handle, int32, [1, 512, 1, 1, 4], []),
             placeholder: Buffer(placeholder_7: handle, int8, [32, 256, 14, 14, 4], []),
             placeholder_1: Buffer(placeholder_8: handle, int8, [512, 256, 1, 1, 4, 4], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, compute_1: compute} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 16;
  attr [compute_3: handle] "storage_scope" = "local";
  allocate(compute_3, int32, [112]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [104]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [1024]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 8;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 7;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 32;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 1;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1 {
    for (n.init: int32, 0, 2) "unroll" {
      for (oc_block.init: int32, 0, 4) "unroll" {
        compute_3[((n.init*4) + oc_block.init)] = 0
        compute_3[(((n.init*4) + oc_block.init) + 56)] = 0
        compute_3[(((n.init*4) + oc_block.init) + 8)] = 0
        compute_3[(((n.init*4) + oc_block.init) + 64)] = 0
        compute_3[(((n.init*4) + oc_block.init) + 16)] = 0
        compute_3[(((n.init*4) + oc_block.init) + 72)] = 0
        compute_3[(((n.init*4) + oc_block.init) + 24)] = 0
        compute_3[(((n.init*4) + oc_block.init) + 80)] = 0
        compute_3[(((n.init*4) + oc_block.init) + 32)] = 0
        compute_3[(((n.init*4) + oc_block.init) + 88)] = 0
        compute_3[(((n.init*4) + oc_block.init) + 40)] = 0
        compute_3[(((n.init*4) + oc_block.init) + 96)] = 0
        compute_3[(((n.init*4) + oc_block.init) + 48)] = 0
        compute_3[(((n.init*4) + oc_block.init) + 104)] = 0
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 2) "unroll" {
      attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 32;
      attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 1;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1;
      if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*32) + threadIdx.z_1) < 52) {
        pad_data.shared[ramp(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*4)), 1, 4)] = (int8x4*)placeholder_7[ramp((((((blockIdx.z*401408) + (floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*32) + threadIdx.z_1), 26)*200704)) + (floordiv(floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*32) + threadIdx.z_1), 26), 13)*784)) + (blockIdx.x*112)) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*32) + threadIdx.z_1), 13)*4)), 1, 4)]
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 16) "unroll" {
      attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 32;
      attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 1;
      attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1;
      placeholder.shared[ramp(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*128) + (threadIdx.z_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp(((((blockIdx.y*262144) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*16384)) + (floordiv(threadIdx.z_2, 8)*4096)) + (floormod(threadIdx.z_2, 8)*4)), 1, 4)]
    }
    for (ic_chunk.outer.outer: int32, 0, 127) {
      attr [pad_data.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1: int32, 0, 2) "unroll" {
        attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 32;
        attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 1;
        attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1;
        if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*32) + threadIdx.z_1) < 52) {
          pad_data.shared[ramp((((floormod((ic_chunk.outer.outer + 1), 2)*208) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*128)) + (threadIdx.z_1*4)), 1, 4)] = (int8x4*)placeholder_7[ramp((((((((blockIdx.z*401408) + (floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*32) + threadIdx.z_1), 26)*200704)) + (ic_chunk.outer.outer*1568)) + (floordiv(floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*32) + threadIdx.z_1), 26), 13)*784)) + (blockIdx.x*112)) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*32) + threadIdx.z_1), 13)*4)) + 1568), 1, 4)]
        }
      }
      attr [placeholder.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 16) "unroll" {
        attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 32;
        attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 1;
        attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1;
        placeholder.shared[ramp((((floormod((ic_chunk.outer.outer + 1), 2)*2048) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*128)) + (threadIdx.z_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp(((((((blockIdx.y*262144) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*16384)) + (floordiv(threadIdx.z_2, 8)*4096)) + (ic_chunk.outer.outer*32)) + (floormod(threadIdx.z_2, 8)*4)) + 32), 1, 4)]
      }
      for (ic_chunk.inner: int32, 0, 2) "unroll" {
        for (n: int32, 0, 2) "unroll" {
          for (oc_block: int32, 0, 4) "unroll" {
            compute_3[((n*4) + oc_block)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((floormod(ic_chunk.outer.outer, 2)*208) + (n*104)) + (ic_chunk.inner*52)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*2048) + (threadIdx.z*32)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute_3[((n*4) + oc_block)], dtype=int32)
            compute_3[(((n*4) + oc_block) + 56)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((floormod(ic_chunk.outer.outer, 2)*208) + (n*104)) + (ic_chunk.inner*52)), 1, 4)], (int8x4*)placeholder.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*2048) + (threadIdx.z*32)) + (ic_chunk.inner*16)) + (oc_block*4)) + 1024), 1, 4)], (int32*)compute_3[(((n*4) + oc_block) + 56)], dtype=int32)
            compute_3[(((n*4) + oc_block) + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*208) + (n*104)) + (ic_chunk.inner*52)) + 8), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*2048) + (threadIdx.z*32)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute_3[(((n*4) + oc_block) + 8)], dtype=int32)
            compute_3[(((n*4) + oc_block) + 64)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*208) + (n*104)) + (ic_chunk.inner*52)) + 8), 1, 4)], (int8x4*)placeholder.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*2048) + (threadIdx.z*32)) + (ic_chunk.inner*16)) + (oc_block*4)) + 1024), 1, 4)], (int32*)compute_3[(((n*4) + oc_block) + 64)], dtype=int32)
            compute_3[(((n*4) + oc_block) + 16)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*208) + (n*104)) + (ic_chunk.inner*52)) + 16), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*2048) + (threadIdx.z*32)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute_3[(((n*4) + oc_block) + 16)], dtype=int32)
            compute_3[(((n*4) + oc_block) + 72)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*208) + (n*104)) + (ic_chunk.inner*52)) + 16), 1, 4)], (int8x4*)placeholder.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*2048) + (threadIdx.z*32)) + (ic_chunk.inner*16)) + (oc_block*4)) + 1024), 1, 4)], (int32*)compute_3[(((n*4) + oc_block) + 72)], dtype=int32)
            compute_3[(((n*4) + oc_block) + 24)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*208) + (n*104)) + (ic_chunk.inner*52)) + 24), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*2048) + (threadIdx.z*32)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute_3[(((n*4) + oc_block) + 24)], dtype=int32)
            compute_3[(((n*4) + oc_block) + 80)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*208) + (n*104)) + (ic_chunk.inner*52)) + 24), 1, 4)], (int8x4*)placeholder.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*2048) + (threadIdx.z*32)) + (ic_chunk.inner*16)) + (oc_block*4)) + 1024), 1, 4)], (int32*)compute_3[(((n*4) + oc_block) + 80)], dtype=int32)
            compute_3[(((n*4) + oc_block) + 32)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*208) + (n*104)) + (ic_chunk.inner*52)) + 32), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*2048) + (threadIdx.z*32)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute_3[(((n*4) + oc_block) + 32)], dtype=int32)
            compute_3[(((n*4) + oc_block) + 88)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*208) + (n*104)) + (ic_chunk.inner*52)) + 32), 1, 4)], (int8x4*)placeholder.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*2048) + (threadIdx.z*32)) + (ic_chunk.inner*16)) + (oc_block*4)) + 1024), 1, 4)], (int32*)compute_3[(((n*4) + oc_block) + 88)], dtype=int32)
            compute_3[(((n*4) + oc_block) + 40)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*208) + (n*104)) + (ic_chunk.inner*52)) + 40), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*2048) + (threadIdx.z*32)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute_3[(((n*4) + oc_block) + 40)], dtype=int32)
            compute_3[(((n*4) + oc_block) + 96)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*208) + (n*104)) + (ic_chunk.inner*52)) + 40), 1, 4)], (int8x4*)placeholder.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*2048) + (threadIdx.z*32)) + (ic_chunk.inner*16)) + (oc_block*4)) + 1024), 1, 4)], (int32*)compute_3[(((n*4) + oc_block) + 96)], dtype=int32)
            compute_3[(((n*4) + oc_block) + 48)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*208) + (n*104)) + (ic_chunk.inner*52)) + 48), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*2048) + (threadIdx.z*32)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute_3[(((n*4) + oc_block) + 48)], dtype=int32)
            compute_3[(((n*4) + oc_block) + 104)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*208) + (n*104)) + (ic_chunk.inner*52)) + 48), 1, 4)], (int8x4*)placeholder.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*2048) + (threadIdx.z*32)) + (ic_chunk.inner*16)) + (oc_block*4)) + 1024), 1, 4)], (int32*)compute_3[(((n*4) + oc_block) + 104)], dtype=int32)
          }
        }
      }
    }
    for (ic_chunk.inner_1: int32, 0, 2) "unroll" {
      for (n_1: int32, 0, 2) "unroll" {
        for (oc_block_1: int32, 0, 4) "unroll" {
          compute_3[((n_1*4) + oc_block_1)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((n_1*104) + (ic_chunk.inner_1*52)) + 208), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.z*32) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 2048), 1, 4)], (int32*)compute_3[((n_1*4) + oc_block_1)], dtype=int32)
          compute_3[(((n_1*4) + oc_block_1) + 56)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((n_1*104) + (ic_chunk.inner_1*52)) + 208), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.z*32) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 3072), 1, 4)], (int32*)compute_3[(((n_1*4) + oc_block_1) + 56)], dtype=int32)
          compute_3[(((n_1*4) + oc_block_1) + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((n_1*104) + (ic_chunk.inner_1*52)) + 216), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.z*32) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 2048), 1, 4)], (int32*)compute_3[(((n_1*4) + oc_block_1) + 8)], dtype=int32)
          compute_3[(((n_1*4) + oc_block_1) + 64)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((n_1*104) + (ic_chunk.inner_1*52)) + 216), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.z*32) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 3072), 1, 4)], (int32*)compute_3[(((n_1*4) + oc_block_1) + 64)], dtype=int32)
          compute_3[(((n_1*4) + oc_block_1) + 16)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((n_1*104) + (ic_chunk.inner_1*52)) + 224), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.z*32) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 2048), 1, 4)], (int32*)compute_3[(((n_1*4) + oc_block_1) + 16)], dtype=int32)
          compute_3[(((n_1*4) + oc_block_1) + 72)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((n_1*104) + (ic_chunk.inner_1*52)) + 224), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.z*32) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 3072), 1, 4)], (int32*)compute_3[(((n_1*4) + oc_block_1) + 72)], dtype=int32)
          compute_3[(((n_1*4) + oc_block_1) + 24)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((n_1*104) + (ic_chunk.inner_1*52)) + 232), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.z*32) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 2048), 1, 4)], (int32*)compute_3[(((n_1*4) + oc_block_1) + 24)], dtype=int32)
          compute_3[(((n_1*4) + oc_block_1) + 80)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((n_1*104) + (ic_chunk.inner_1*52)) + 232), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.z*32) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 3072), 1, 4)], (int32*)compute_3[(((n_1*4) + oc_block_1) + 80)], dtype=int32)
          compute_3[(((n_1*4) + oc_block_1) + 32)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((n_1*104) + (ic_chunk.inner_1*52)) + 240), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.z*32) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 2048), 1, 4)], (int32*)compute_3[(((n_1*4) + oc_block_1) + 32)], dtype=int32)
          compute_3[(((n_1*4) + oc_block_1) + 88)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((n_1*104) + (ic_chunk.inner_1*52)) + 240), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.z*32) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 3072), 1, 4)], (int32*)compute_3[(((n_1*4) + oc_block_1) + 88)], dtype=int32)
          compute_3[(((n_1*4) + oc_block_1) + 40)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((n_1*104) + (ic_chunk.inner_1*52)) + 248), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.z*32) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 2048), 1, 4)], (int32*)compute_3[(((n_1*4) + oc_block_1) + 40)], dtype=int32)
          compute_3[(((n_1*4) + oc_block_1) + 96)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((n_1*104) + (ic_chunk.inner_1*52)) + 248), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.z*32) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 3072), 1, 4)], (int32*)compute_3[(((n_1*4) + oc_block_1) + 96)], dtype=int32)
          compute_3[(((n_1*4) + oc_block_1) + 48)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((n_1*104) + (ic_chunk.inner_1*52)) + 256), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.z*32) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 2048), 1, 4)], (int32*)compute_3[(((n_1*4) + oc_block_1) + 48)], dtype=int32)
          compute_3[(((n_1*4) + oc_block_1) + 104)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((n_1*104) + (ic_chunk.inner_1*52)) + 256), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.z*32) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 3072), 1, 4)], (int32*)compute_3[(((n_1*4) + oc_block_1) + 104)], dtype=int32)
        }
      }
    }
    for (i0.inner.inner.inner.inner: int32, 0, 2) "unroll" {
      for (i4: int32, 0, 4) "unroll" {
        compute_2[((((((blockIdx.z*200704) + (i0.inner.inner.inner.inner*100352)) + (blockIdx.y*12544)) + (threadIdx.z*196)) + (blockIdx.x*28)) + i4)] = @tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute_3[((i0.inner.inner.inner.inner*4) + i4)], 1168676628, 31, 18, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*256) + (threadIdx.z*4)) + i4)]), 1145619329, 31, 1, dtype=int32)
        compute_2[(((((((blockIdx.z*200704) + (i0.inner.inner.inner.inner*100352)) + (blockIdx.y*12544)) + (threadIdx.z*196)) + (blockIdx.x*28)) + i4) + 6272)] = @tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute_3[(((i0.inner.inner.inner.inner*4) + i4) + 56)], 1168676628, 31, 18, dtype=int32) + (int32*)placeholder_6[((((blockIdx.y*256) + (threadIdx.z*4)) + i4) + 128)]), 1145619329, 31, 1, dtype=int32)
        compute_2[(((((((blockIdx.z*200704) + (i0.inner.inner.inner.inner*100352)) + (blockIdx.y*12544)) + (threadIdx.z*196)) + (blockIdx.x*28)) + i4) + 4)] = @tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute_3[(((i0.inner.inner.inner.inner*4) + i4) + 8)], 1168676628, 31, 18, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*256) + (threadIdx.z*4)) + i4)]), 1145619329, 31, 1, dtype=int32)
        compute_2[(((((((blockIdx.z*200704) + (i0.inner.inner.inner.inner*100352)) + (blockIdx.y*12544)) + (threadIdx.z*196)) + (blockIdx.x*28)) + i4) + 6276)] = @tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute_3[(((i0.inner.inner.inner.inner*4) + i4) + 64)], 1168676628, 31, 18, dtype=int32) + (int32*)placeholder_6[((((blockIdx.y*256) + (threadIdx.z*4)) + i4) + 128)]), 1145619329, 31, 1, dtype=int32)
        compute_2[(((((((blockIdx.z*200704) + (i0.inner.inner.inner.inner*100352)) + (blockIdx.y*12544)) + (threadIdx.z*196)) + (blockIdx.x*28)) + i4) + 8)] = @tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute_3[(((i0.inner.inner.inner.inner*4) + i4) + 16)], 1168676628, 31, 18, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*256) + (threadIdx.z*4)) + i4)]), 1145619329, 31, 1, dtype=int32)
        compute_2[(((((((blockIdx.z*200704) + (i0.inner.inner.inner.inner*100352)) + (blockIdx.y*12544)) + (threadIdx.z*196)) + (blockIdx.x*28)) + i4) + 6280)] = @tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute_3[(((i0.inner.inner.inner.inner*4) + i4) + 72)], 1168676628, 31, 18, dtype=int32) + (int32*)placeholder_6[((((blockIdx.y*256) + (threadIdx.z*4)) + i4) + 128)]), 1145619329, 31, 1, dtype=int32)
        compute_2[(((((((blockIdx.z*200704) + (i0.inner.inner.inner.inner*100352)) + (blockIdx.y*12544)) + (threadIdx.z*196)) + (blockIdx.x*28)) + i4) + 12)] = @tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute_3[(((i0.inner.inner.inner.inner*4) + i4) + 24)], 1168676628, 31, 18, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*256) + (threadIdx.z*4)) + i4)]), 1145619329, 31, 1, dtype=int32)
        compute_2[(((((((blockIdx.z*200704) + (i0.inner.inner.inner.inner*100352)) + (blockIdx.y*12544)) + (threadIdx.z*196)) + (blockIdx.x*28)) + i4) + 6284)] = @tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute_3[(((i0.inner.inner.inner.inner*4) + i4) + 80)], 1168676628, 31, 18, dtype=int32) + (int32*)placeholder_6[((((blockIdx.y*256) + (threadIdx.z*4)) + i4) + 128)]), 1145619329, 31, 1, dtype=int32)
        compute_2[(((((((blockIdx.z*200704) + (i0.inner.inner.inner.inner*100352)) + (blockIdx.y*12544)) + (threadIdx.z*196)) + (blockIdx.x*28)) + i4) + 16)] = @tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute_3[(((i0.inner.inner.inner.inner*4) + i4) + 32)], 1168676628, 31, 18, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*256) + (threadIdx.z*4)) + i4)]), 1145619329, 31, 1, dtype=int32)
        compute_2[(((((((blockIdx.z*200704) + (i0.inner.inner.inner.inner*100352)) + (blockIdx.y*12544)) + (threadIdx.z*196)) + (blockIdx.x*28)) + i4) + 6288)] = @tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute_3[(((i0.inner.inner.inner.inner*4) + i4) + 88)], 1168676628, 31, 18, dtype=int32) + (int32*)placeholder_6[((((blockIdx.y*256) + (threadIdx.z*4)) + i4) + 128)]), 1145619329, 31, 1, dtype=int32)
        compute_2[(((((((blockIdx.z*200704) + (i0.inner.inner.inner.inner*100352)) + (blockIdx.y*12544)) + (threadIdx.z*196)) + (blockIdx.x*28)) + i4) + 20)] = @tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute_3[(((i0.inner.inner.inner.inner*4) + i4) + 40)], 1168676628, 31, 18, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*256) + (threadIdx.z*4)) + i4)]), 1145619329, 31, 1, dtype=int32)
        compute_2[(((((((blockIdx.z*200704) + (i0.inner.inner.inner.inner*100352)) + (blockIdx.y*12544)) + (threadIdx.z*196)) + (blockIdx.x*28)) + i4) + 6292)] = @tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute_3[(((i0.inner.inner.inner.inner*4) + i4) + 96)], 1168676628, 31, 18, dtype=int32) + (int32*)placeholder_6[((((blockIdx.y*256) + (threadIdx.z*4)) + i4) + 128)]), 1145619329, 31, 1, dtype=int32)
        compute_2[(((((((blockIdx.z*200704) + (i0.inner.inner.inner.inner*100352)) + (blockIdx.y*12544)) + (threadIdx.z*196)) + (blockIdx.x*28)) + i4) + 24)] = @tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute_3[(((i0.inner.inner.inner.inner*4) + i4) + 48)], 1168676628, 31, 18, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*256) + (threadIdx.z*4)) + i4)]), 1145619329, 31, 1, dtype=int32)
        compute_2[(((((((blockIdx.z*200704) + (i0.inner.inner.inner.inner*100352)) + (blockIdx.y*12544)) + (threadIdx.z*196)) + (blockIdx.x*28)) + i4) + 6296)] = @tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute_3[(((i0.inner.inner.inner.inner*4) + i4) + 104)], 1168676628, 31, 18, dtype=int32) + (int32*)placeholder_6[((((blockIdx.y*256) + (threadIdx.z*4)) + i4) + 128)]), 1145619329, 31, 1, dtype=int32)
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data

