Compile...
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, float32, [], []),
             placeholder: Buffer(placeholder_2: handle, int32, [], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  T_cast_2[0] = cast(float32, (int32*)placeholder_2[0])
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op divide
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide_4", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_4: handle, float32, [64, 3, 7, 7], []),
             T_divide: Buffer(T_divide_2: handle, float32, [64, 3, 7, 7], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  for (ax0.ax1.fused: int32, 0, 192) "parallel" {
    for (ax2: int32, 0, 7) {
      T_divide_2[ramp(((ax0.ax1.fused*49) + (ax2*7)), 1, 7)] = ((float32x7*)placeholder_4[ramp(((ax0.ax1.fused*49) + (ax2*7)), 1, 7)] / broadcast((float32*)placeholder_5[0], 7))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op add
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add_18", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: handle, float32, [64, 3, 7, 7], []),
             placeholder: Buffer(placeholder_4: handle, float32, [64, 3, 7, 7], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  for (ax0.ax1.fused: int32, 0, 192) "parallel" {
    for (ax2: int32, 0, 7) {
      T_add_2[ramp(((ax0.ax1.fused*49) + (ax2*7)), 1, 7)] = ((float32x7*)placeholder_4[ramp(((ax0.ax1.fused*49) + (ax2*7)), 1, 7)] + broadcast((float32*)placeholder_5[0], 7))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op round
primfn(placeholder_1: handle, T_round_1: handle) -> ()
  attr = {"global_symbol": "fused_round", "tir.noalias": True}
  buffers = {T_round: Buffer(T_round_2: handle, float32, [64, 3, 7, 7], []),
             placeholder: Buffer(placeholder_2: handle, float32, [64, 3, 7, 7], [])}
  buffer_map = {placeholder_1: placeholder, T_round_1: T_round} {
  for (ax0.ax1.fused: int32, 0, 192) "parallel" {
    for (ax2: int32, 0, 7) {
      T_round_2[ramp(((ax0.ax1.fused*49) + (ax2*7)), 1, 7)] = @tir.round((float32x7*)placeholder_2[ramp(((ax0.ax1.fused*49) + (ax2*7)), 1, 7)], dtype=float32x7)
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_1", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [64, 3, 7, 7], []),
             placeholder: Buffer(placeholder_2: handle, float32, [64, 3, 7, 7], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 192) "parallel" {
    for (ax2: int32, 0, 7) {
      T_cast_2[ramp(((ax0.ax1.fused*49) + (ax2*7)), 1, 7)] = cast(int32x7, (float32x7*)placeholder_2[ramp(((ax0.ax1.fused*49) + (ax2*7)), 1, 7)])
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op clip
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_clip", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [64, 3, 7, 7], []),
             placeholder: Buffer(placeholder_2: handle, int32, [64, 3, 7, 7], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0.i1.fused: int32, 0, 192) "parallel" {
    for (i2: int32, 0, 7) {
      compute_2[ramp(((i0.i1.fused*49) + (i2*7)), 1, 7)] = max(min((int32x7*)placeholder_2[ramp(((i0.i1.fused*49) + (i2*7)), 1, 7)], broadcast(127, 7)), broadcast(-128, 7))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_2", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [64, 3, 7, 7], []),
             placeholder: Buffer(placeholder_2: handle, int32, [64, 3, 7, 7], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 192) "parallel" {
    for (ax2: int32, 0, 7) {
      T_cast_2[ramp(((ax0.ax1.fused*49) + (ax2*7)), 1, 7)] = cast(int8x7, (int32x7*)placeholder_2[ramp(((ax0.ax1.fused*49) + (ax2*7)), 1, 7)])
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op nn.pad
primfn(placeholder_1: handle, T_pad_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_pad", "tir.noalias": True}
  buffers = {T_pad: Buffer(T_pad_2: handle, int8, [64, 4, 7, 7], []),
             placeholder: Buffer(placeholder_2: handle, int8, [64, 3, 7, 7], [])}
  buffer_map = {placeholder_1: placeholder, T_pad_1: T_pad} {
  for (ax0.ax1.fused: int32, 0, 256) "parallel" {
    for (ax2: int32, 0, 7) {
      T_pad_2[ramp(((ax0.ax1.fused*49) + (ax2*7)), 1, 7)] = @tir.if_then_else((floormod(ax0.ax1.fused, 4) < 3), (int8x7*)placeholder_2[ramp((((floordiv(ax0.ax1.fused, 4)*147) + (floormod(ax0.ax1.fused, 4)*49)) + (ax2*7)), 1, 7)], broadcast(0i8, 7), dtype=int8x7)
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op divide
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide_5", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: handle, float32, [64, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [64, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  for (ax0.ax1.fused: int32, 0, 64) "parallel" {
    T_divide_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] / (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op add
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add_19", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: handle, float32, [64, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [64, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  for (ax0.ax1.fused: int32, 0, 64) "parallel" {
    T_add_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] + (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op round
primfn(placeholder_1: handle, T_round_1: handle) -> ()
  attr = {"global_symbol": "fused_round_1", "tir.noalias": True}
  buffers = {T_round: Buffer(T_round_2: handle, float32, [64, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [64, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_round_1: T_round} {
  for (ax0.ax1.fused: int32, 0, 64) "parallel" {
    T_round_2[ax0.ax1.fused] = @tir.round((float32*)placeholder_2[ax0.ax1.fused], dtype=float32)
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_3", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [64, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [64, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 64) "parallel" {
    T_cast_2[ax0.ax1.fused] = cast(int32, (float32*)placeholder_2[ax0.ax1.fused])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op clip
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_clip_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [64, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [64, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0.i1.fused: int32, 0, 64) "parallel" {
    compute_2[i0.i1.fused] = (int32*)placeholder_2[i0.i1.fused]
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_4", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [64, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [64, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 64) "parallel" {
    T_cast_2[ax0.ax1.fused] = (int32*)placeholder_2[ax0.ax1.fused]
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op divide
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide_6", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: handle, float32, [64, 64, 3, 3], []),
             placeholder: Buffer(placeholder_4: handle, float32, [64, 64, 3, 3], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  for (ax0.ax1.fused: int32, 0, 4096) "parallel" {
    for (ax2: int32, 0, 3) {
      T_divide_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = ((float32x3*)placeholder_4[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] / broadcast((float32*)placeholder_5[0], 3))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op add
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add_20", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: handle, float32, [64, 64, 3, 3], []),
             placeholder: Buffer(placeholder_4: handle, float32, [64, 64, 3, 3], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  for (ax0.ax1.fused: int32, 0, 4096) "parallel" {
    for (ax2: int32, 0, 3) {
      T_add_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = ((float32x3*)placeholder_4[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] + broadcast((float32*)placeholder_5[0], 3))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op round
primfn(placeholder_1: handle, T_round_1: handle) -> ()
  attr = {"global_symbol": "fused_round_2", "tir.noalias": True}
  buffers = {T_round: Buffer(T_round_2: handle, float32, [64, 64, 3, 3], []),
             placeholder: Buffer(placeholder_2: handle, float32, [64, 64, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, T_round_1: T_round} {
  for (ax0.ax1.fused: int32, 0, 4096) "parallel" {
    for (ax2: int32, 0, 3) {
      T_round_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = @tir.round((float32x3*)placeholder_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)], dtype=float32x3)
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_5", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [64, 64, 3, 3], []),
             placeholder: Buffer(placeholder_2: handle, float32, [64, 64, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 4096) "parallel" {
    for (ax2: int32, 0, 3) {
      T_cast_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = cast(int32x3, (float32x3*)placeholder_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)])
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op clip
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_clip_2", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [64, 64, 3, 3], []),
             placeholder: Buffer(placeholder_2: handle, int32, [64, 64, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0.i1.fused: int32, 0, 4096) "parallel" {
    for (i2: int32, 0, 3) {
      compute_2[ramp(((i0.i1.fused*9) + (i2*3)), 1, 3)] = max(min((int32x3*)placeholder_2[ramp(((i0.i1.fused*9) + (i2*3)), 1, 3)], broadcast(127, 3)), broadcast(-128, 3))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_6", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [64, 64, 3, 3], []),
             placeholder: Buffer(placeholder_2: handle, int32, [64, 64, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 4096) "parallel" {
    for (ax2: int32, 0, 3) {
      T_cast_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = cast(int8x3, (int32x3*)placeholder_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)])
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op divide
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide_7", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_4: handle, float32, [128, 64, 1, 1], []),
             T_divide: Buffer(T_divide_2: handle, float32, [128, 64, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  for (ax0.ax1.fused: int32, 0, 8192) "parallel" {
    T_divide_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] / (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op add
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add_21", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: handle, float32, [128, 64, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [128, 64, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  for (ax0.ax1.fused: int32, 0, 8192) "parallel" {
    T_add_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] + (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op round
primfn(placeholder_1: handle, T_round_1: handle) -> ()
  attr = {"global_symbol": "fused_round_3", "tir.noalias": True}
  buffers = {T_round: Buffer(T_round_2: handle, float32, [128, 64, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [128, 64, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_round_1: T_round} {
  for (ax0.ax1.fused: int32, 0, 8192) "parallel" {
    T_round_2[ax0.ax1.fused] = @tir.round((float32*)placeholder_2[ax0.ax1.fused], dtype=float32)
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_7", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [128, 64, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [128, 64, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 8192) "parallel" {
    T_cast_2[ax0.ax1.fused] = cast(int32, (float32*)placeholder_2[ax0.ax1.fused])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op clip
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_clip_3", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [128, 64, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [128, 64, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0.i1.fused: int32, 0, 8192) "parallel" {
    compute_2[i0.i1.fused] = max(min((int32*)placeholder_2[i0.i1.fused], 127), -128)
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_8", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [128, 64, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [128, 64, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 8192) "parallel" {
    T_cast_2[ax0.ax1.fused] = cast(int8, (int32*)placeholder_2[ax0.ax1.fused])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op divide
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide_8", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: handle, float32, [128, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [128, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  for (ax0.ax1.fused: int32, 0, 128) "parallel" {
    T_divide_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] / (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op add
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add_22", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: handle, float32, [128, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [128, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  for (ax0.ax1.fused: int32, 0, 128) "parallel" {
    T_add_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] + (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op round
primfn(placeholder_1: handle, T_round_1: handle) -> ()
  attr = {"global_symbol": "fused_round_4", "tir.noalias": True}
  buffers = {T_round: Buffer(T_round_2: handle, float32, [128, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [128, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_round_1: T_round} {
  for (ax0.ax1.fused: int32, 0, 128) "parallel" {
    T_round_2[ax0.ax1.fused] = @tir.round((float32*)placeholder_2[ax0.ax1.fused], dtype=float32)
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_9", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [128, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [128, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 128) "parallel" {
    T_cast_2[ax0.ax1.fused] = cast(int32, (float32*)placeholder_2[ax0.ax1.fused])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op clip
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_clip_4", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [128, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [128, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0.i1.fused: int32, 0, 128) "parallel" {
    compute_2[i0.i1.fused] = (int32*)placeholder_2[i0.i1.fused]
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_10", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [128, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [128, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 128) "parallel" {
    T_cast_2[ax0.ax1.fused] = (int32*)placeholder_2[ax0.ax1.fused]
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op divide
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide_9", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: handle, float32, [128, 64, 3, 3], []),
             placeholder: Buffer(placeholder_4: handle, float32, [128, 64, 3, 3], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  for (ax0.ax1.fused: int32, 0, 8192) "parallel" {
    for (ax2: int32, 0, 3) {
      T_divide_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = ((float32x3*)placeholder_4[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] / broadcast((float32*)placeholder_5[0], 3))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op add
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add_23", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: handle, float32, [128, 64, 3, 3], []),
             placeholder: Buffer(placeholder_4: handle, float32, [128, 64, 3, 3], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  for (ax0.ax1.fused: int32, 0, 8192) "parallel" {
    for (ax2: int32, 0, 3) {
      T_add_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = ((float32x3*)placeholder_4[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] + broadcast((float32*)placeholder_5[0], 3))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op round
primfn(placeholder_1: handle, T_round_1: handle) -> ()
  attr = {"global_symbol": "fused_round_5", "tir.noalias": True}
  buffers = {T_round: Buffer(T_round_2: handle, float32, [128, 64, 3, 3], []),
             placeholder: Buffer(placeholder_2: handle, float32, [128, 64, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, T_round_1: T_round} {
  for (ax0.ax1.fused: int32, 0, 8192) "parallel" {
    for (ax2: int32, 0, 3) {
      T_round_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = @tir.round((float32x3*)placeholder_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)], dtype=float32x3)
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_11", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [128, 64, 3, 3], []),
             placeholder: Buffer(placeholder_2: handle, float32, [128, 64, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 8192) "parallel" {
    for (ax2: int32, 0, 3) {
      T_cast_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = cast(int32x3, (float32x3*)placeholder_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)])
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op clip
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_clip_5", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [128, 64, 3, 3], []),
             placeholder: Buffer(placeholder_2: handle, int32, [128, 64, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0.i1.fused: int32, 0, 8192) "parallel" {
    for (i2: int32, 0, 3) {
      compute_2[ramp(((i0.i1.fused*9) + (i2*3)), 1, 3)] = max(min((int32x3*)placeholder_2[ramp(((i0.i1.fused*9) + (i2*3)), 1, 3)], broadcast(127, 3)), broadcast(-128, 3))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_12", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [128, 64, 3, 3], []),
             placeholder: Buffer(placeholder_2: handle, int32, [128, 64, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 8192) "parallel" {
    for (ax2: int32, 0, 3) {
      T_cast_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = cast(int8x3, (int32x3*)placeholder_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)])
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op divide
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide_10", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: handle, float32, [128, 128, 3, 3], []),
             placeholder: Buffer(placeholder_4: handle, float32, [128, 128, 3, 3], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  for (ax0.ax1.fused: int32, 0, 16384) "parallel" {
    for (ax2: int32, 0, 3) {
      T_divide_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = ((float32x3*)placeholder_4[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] / broadcast((float32*)placeholder_5[0], 3))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op add
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add_24", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: handle, float32, [128, 128, 3, 3], []),
             placeholder: Buffer(placeholder_4: handle, float32, [128, 128, 3, 3], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  for (ax0.ax1.fused: int32, 0, 16384) "parallel" {
    for (ax2: int32, 0, 3) {
      T_add_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = ((float32x3*)placeholder_4[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] + broadcast((float32*)placeholder_5[0], 3))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op round
primfn(placeholder_1: handle, T_round_1: handle) -> ()
  attr = {"global_symbol": "fused_round_6", "tir.noalias": True}
  buffers = {T_round: Buffer(T_round_2: handle, float32, [128, 128, 3, 3], []),
             placeholder: Buffer(placeholder_2: handle, float32, [128, 128, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, T_round_1: T_round} {
  for (ax0.ax1.fused: int32, 0, 16384) "parallel" {
    for (ax2: int32, 0, 3) {
      T_round_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = @tir.round((float32x3*)placeholder_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)], dtype=float32x3)
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_13", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [128, 128, 3, 3], []),
             placeholder: Buffer(placeholder_2: handle, float32, [128, 128, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 16384) "parallel" {
    for (ax2: int32, 0, 3) {
      T_cast_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = cast(int32x3, (float32x3*)placeholder_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)])
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op clip
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_clip_6", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [128, 128, 3, 3], []),
             placeholder: Buffer(placeholder_2: handle, int32, [128, 128, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0.i1.fused: int32, 0, 16384) "parallel" {
    for (i2: int32, 0, 3) {
      compute_2[ramp(((i0.i1.fused*9) + (i2*3)), 1, 3)] = max(min((int32x3*)placeholder_2[ramp(((i0.i1.fused*9) + (i2*3)), 1, 3)], broadcast(127, 3)), broadcast(-128, 3))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_14", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [128, 128, 3, 3], []),
             placeholder: Buffer(placeholder_2: handle, int32, [128, 128, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 16384) "parallel" {
    for (ax2: int32, 0, 3) {
      T_cast_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = cast(int8x3, (int32x3*)placeholder_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)])
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op divide
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide_11", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: handle, float32, [256, 128, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [256, 128, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  for (ax0.ax1.fused: int32, 0, 32768) "parallel" {
    T_divide_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] / (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op add
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add_25", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: handle, float32, [256, 128, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [256, 128, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  for (ax0.ax1.fused: int32, 0, 32768) "parallel" {
    T_add_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] + (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op round
primfn(placeholder_1: handle, T_round_1: handle) -> ()
  attr = {"global_symbol": "fused_round_7", "tir.noalias": True}
  buffers = {T_round: Buffer(T_round_2: handle, float32, [256, 128, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [256, 128, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_round_1: T_round} {
  for (ax0.ax1.fused: int32, 0, 32768) "parallel" {
    T_round_2[ax0.ax1.fused] = @tir.round((float32*)placeholder_2[ax0.ax1.fused], dtype=float32)
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_15", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [256, 128, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [256, 128, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 32768) "parallel" {
    T_cast_2[ax0.ax1.fused] = cast(int32, (float32*)placeholder_2[ax0.ax1.fused])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op clip
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_clip_7", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [256, 128, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [256, 128, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0.i1.fused: int32, 0, 32768) "parallel" {
    compute_2[i0.i1.fused] = max(min((int32*)placeholder_2[i0.i1.fused], 127), -128)
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_16", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [256, 128, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [256, 128, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 32768) "parallel" {
    T_cast_2[ax0.ax1.fused] = cast(int8, (int32*)placeholder_2[ax0.ax1.fused])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op divide
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide_12", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: handle, float32, [256, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [256, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  for (ax0.ax1.fused: int32, 0, 256) "parallel" {
    T_divide_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] / (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op add
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add_26", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: handle, float32, [256, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [256, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  for (ax0.ax1.fused: int32, 0, 256) "parallel" {
    T_add_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] + (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op round
primfn(placeholder_1: handle, T_round_1: handle) -> ()
  attr = {"global_symbol": "fused_round_8", "tir.noalias": True}
  buffers = {T_round: Buffer(T_round_2: handle, float32, [256, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [256, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_round_1: T_round} {
  for (ax0.ax1.fused: int32, 0, 256) "parallel" {
    T_round_2[ax0.ax1.fused] = @tir.round((float32*)placeholder_2[ax0.ax1.fused], dtype=float32)
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_17", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [256, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [256, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 256) "parallel" {
    T_cast_2[ax0.ax1.fused] = cast(int32, (float32*)placeholder_2[ax0.ax1.fused])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op clip
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_clip_8", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [256, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [256, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0.i1.fused: int32, 0, 256) "parallel" {
    compute_2[i0.i1.fused] = (int32*)placeholder_2[i0.i1.fused]
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_18", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [256, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [256, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 256) "parallel" {
    T_cast_2[ax0.ax1.fused] = (int32*)placeholder_2[ax0.ax1.fused]
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op divide
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide_13", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: handle, float32, [256, 128, 3, 3], []),
             placeholder: Buffer(placeholder_4: handle, float32, [256, 128, 3, 3], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  for (ax0.ax1.fused: int32, 0, 32768) "parallel" {
    for (ax2: int32, 0, 3) {
      T_divide_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = ((float32x3*)placeholder_4[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] / broadcast((float32*)placeholder_5[0], 3))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op add
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add_27", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: handle, float32, [256, 128, 3, 3], []),
             placeholder: Buffer(placeholder_4: handle, float32, [256, 128, 3, 3], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  for (ax0.ax1.fused: int32, 0, 32768) "parallel" {
    for (ax2: int32, 0, 3) {
      T_add_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = ((float32x3*)placeholder_4[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] + broadcast((float32*)placeholder_5[0], 3))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op round
primfn(placeholder_1: handle, T_round_1: handle) -> ()
  attr = {"global_symbol": "fused_round_9", "tir.noalias": True}
  buffers = {T_round: Buffer(T_round_2: handle, float32, [256, 128, 3, 3], []),
             placeholder: Buffer(placeholder_2: handle, float32, [256, 128, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, T_round_1: T_round} {
  for (ax0.ax1.fused: int32, 0, 32768) "parallel" {
    for (ax2: int32, 0, 3) {
      T_round_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = @tir.round((float32x3*)placeholder_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)], dtype=float32x3)
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_19", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [256, 128, 3, 3], []),
             placeholder: Buffer(placeholder_2: handle, float32, [256, 128, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 32768) "parallel" {
    for (ax2: int32, 0, 3) {
      T_cast_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = cast(int32x3, (float32x3*)placeholder_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)])
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op clip
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_clip_9", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [256, 128, 3, 3], []),
             placeholder: Buffer(placeholder_2: handle, int32, [256, 128, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0.i1.fused: int32, 0, 32768) "parallel" {
    for (i2: int32, 0, 3) {
      compute_2[ramp(((i0.i1.fused*9) + (i2*3)), 1, 3)] = max(min((int32x3*)placeholder_2[ramp(((i0.i1.fused*9) + (i2*3)), 1, 3)], broadcast(127, 3)), broadcast(-128, 3))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_20", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [256, 128, 3, 3], []),
             placeholder: Buffer(placeholder_2: handle, int32, [256, 128, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 32768) "parallel" {
    for (ax2: int32, 0, 3) {
      T_cast_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = cast(int8x3, (int32x3*)placeholder_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)])
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op divide
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide_14", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: handle, float32, [256, 256, 3, 3], []),
             placeholder: Buffer(placeholder_4: handle, float32, [256, 256, 3, 3], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  for (ax0.ax1.fused: int32, 0, 65536) "parallel" {
    for (ax2: int32, 0, 3) {
      T_divide_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = ((float32x3*)placeholder_4[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] / broadcast((float32*)placeholder_5[0], 3))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op add
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add_28", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: handle, float32, [256, 256, 3, 3], []),
             placeholder: Buffer(placeholder_4: handle, float32, [256, 256, 3, 3], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  for (ax0.ax1.fused: int32, 0, 65536) "parallel" {
    for (ax2: int32, 0, 3) {
      T_add_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = ((float32x3*)placeholder_4[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] + broadcast((float32*)placeholder_5[0], 3))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op round
primfn(placeholder_1: handle, T_round_1: handle) -> ()
  attr = {"global_symbol": "fused_round_10", "tir.noalias": True}
  buffers = {T_round: Buffer(T_round_2: handle, float32, [256, 256, 3, 3], []),
             placeholder: Buffer(placeholder_2: handle, float32, [256, 256, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, T_round_1: T_round} {
  for (ax0.ax1.fused: int32, 0, 65536) "parallel" {
    for (ax2: int32, 0, 3) {
      T_round_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = @tir.round((float32x3*)placeholder_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)], dtype=float32x3)
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_21", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [256, 256, 3, 3], []),
             placeholder: Buffer(placeholder_2: handle, float32, [256, 256, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 65536) "parallel" {
    for (ax2: int32, 0, 3) {
      T_cast_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = cast(int32x3, (float32x3*)placeholder_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)])
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op clip
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_clip_10", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [256, 256, 3, 3], []),
             placeholder: Buffer(placeholder_2: handle, int32, [256, 256, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0.i1.fused: int32, 0, 65536) "parallel" {
    for (i2: int32, 0, 3) {
      compute_2[ramp(((i0.i1.fused*9) + (i2*3)), 1, 3)] = max(min((int32x3*)placeholder_2[ramp(((i0.i1.fused*9) + (i2*3)), 1, 3)], broadcast(127, 3)), broadcast(-128, 3))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_22", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [256, 256, 3, 3], []),
             placeholder: Buffer(placeholder_2: handle, int32, [256, 256, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 65536) "parallel" {
    for (ax2: int32, 0, 3) {
      T_cast_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = cast(int8x3, (int32x3*)placeholder_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)])
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op divide
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide_15", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: handle, float32, [512, 256, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [512, 256, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  for (ax0.ax1.fused: int32, 0, 131072) "parallel" {
    T_divide_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] / (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op add
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add_29", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: handle, float32, [512, 256, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [512, 256, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  for (ax0.ax1.fused: int32, 0, 131072) "parallel" {
    T_add_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] + (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op round
primfn(placeholder_1: handle, T_round_1: handle) -> ()
  attr = {"global_symbol": "fused_round_11", "tir.noalias": True}
  buffers = {T_round: Buffer(T_round_2: handle, float32, [512, 256, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [512, 256, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_round_1: T_round} {
  for (ax0.ax1.fused: int32, 0, 131072) "parallel" {
    T_round_2[ax0.ax1.fused] = @tir.round((float32*)placeholder_2[ax0.ax1.fused], dtype=float32)
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_23", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [512, 256, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [512, 256, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 131072) "parallel" {
    T_cast_2[ax0.ax1.fused] = cast(int32, (float32*)placeholder_2[ax0.ax1.fused])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op clip
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_clip_11", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [512, 256, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [512, 256, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0.i1.fused: int32, 0, 131072) "parallel" {
    compute_2[i0.i1.fused] = max(min((int32*)placeholder_2[i0.i1.fused], 127), -128)
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_24", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [512, 256, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [512, 256, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 131072) "parallel" {
    T_cast_2[ax0.ax1.fused] = cast(int8, (int32*)placeholder_2[ax0.ax1.fused])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op divide
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide_16", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: handle, float32, [512, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [512, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  for (ax0.ax1.fused: int32, 0, 512) "parallel" {
    T_divide_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] / (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op add
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add_30", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: handle, float32, [512, 1, 1], []),
             placeholder: Buffer(placeholder_4: handle, float32, [512, 1, 1], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  for (ax0.ax1.fused: int32, 0, 512) "parallel" {
    T_add_2[ax0.ax1.fused] = ((float32*)placeholder_4[ax0.ax1.fused] + (float32*)placeholder_5[0])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op round
primfn(placeholder_1: handle, T_round_1: handle) -> ()
  attr = {"global_symbol": "fused_round_12", "tir.noalias": True}
  buffers = {T_round: Buffer(T_round_2: handle, float32, [512, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [512, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_round_1: T_round} {
  for (ax0.ax1.fused: int32, 0, 512) "parallel" {
    T_round_2[ax0.ax1.fused] = @tir.round((float32*)placeholder_2[ax0.ax1.fused], dtype=float32)
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_25", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [512, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, float32, [512, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 512) "parallel" {
    T_cast_2[ax0.ax1.fused] = cast(int32, (float32*)placeholder_2[ax0.ax1.fused])
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op clip
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_clip_12", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [512, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [512, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0.i1.fused: int32, 0, 512) "parallel" {
    compute_2[i0.i1.fused] = (int32*)placeholder_2[i0.i1.fused]
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_26", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [512, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [512, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 512) "parallel" {
    T_cast_2[ax0.ax1.fused] = (int32*)placeholder_2[ax0.ax1.fused]
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op divide
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide_17", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_4: handle, float32, [512, 256, 3, 3], []),
             T_divide: Buffer(T_divide_2: handle, float32, [512, 256, 3, 3], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  for (ax0.ax1.fused: int32, 0, 131072) "parallel" {
    for (ax2: int32, 0, 3) {
      T_divide_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = ((float32x3*)placeholder_4[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] / broadcast((float32*)placeholder_5[0], 3))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op add
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add_31", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: handle, float32, [512, 256, 3, 3], []),
             placeholder: Buffer(placeholder_4: handle, float32, [512, 256, 3, 3], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  for (ax0.ax1.fused: int32, 0, 131072) "parallel" {
    for (ax2: int32, 0, 3) {
      T_add_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = ((float32x3*)placeholder_4[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] + broadcast((float32*)placeholder_5[0], 3))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op round
primfn(placeholder_1: handle, T_round_1: handle) -> ()
  attr = {"global_symbol": "fused_round_13", "tir.noalias": True}
  buffers = {T_round: Buffer(T_round_2: handle, float32, [512, 256, 3, 3], []),
             placeholder: Buffer(placeholder_2: handle, float32, [512, 256, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, T_round_1: T_round} {
  for (ax0.ax1.fused: int32, 0, 131072) "parallel" {
    for (ax2: int32, 0, 3) {
      T_round_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = @tir.round((float32x3*)placeholder_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)], dtype=float32x3)
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_27", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [512, 256, 3, 3], []),
             placeholder: Buffer(placeholder_2: handle, float32, [512, 256, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 131072) "parallel" {
    for (ax2: int32, 0, 3) {
      T_cast_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = cast(int32x3, (float32x3*)placeholder_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)])
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op clip
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_clip_13", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [512, 256, 3, 3], []),
             placeholder: Buffer(placeholder_2: handle, int32, [512, 256, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0.i1.fused: int32, 0, 131072) "parallel" {
    for (i2: int32, 0, 3) {
      compute_2[ramp(((i0.i1.fused*9) + (i2*3)), 1, 3)] = max(min((int32x3*)placeholder_2[ramp(((i0.i1.fused*9) + (i2*3)), 1, 3)], broadcast(127, 3)), broadcast(-128, 3))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_28", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [512, 256, 3, 3], []),
             placeholder: Buffer(placeholder_2: handle, int32, [512, 256, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 131072) "parallel" {
    for (ax2: int32, 0, 3) {
      T_cast_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = cast(int8x3, (int32x3*)placeholder_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)])
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op divide
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide_18", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: handle, float32, [512, 512, 3, 3], []),
             placeholder: Buffer(placeholder_4: handle, float32, [512, 512, 3, 3], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  for (ax0.ax1.fused: int32, 0, 262144) "parallel" {
    for (ax2: int32, 0, 3) {
      T_divide_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = ((float32x3*)placeholder_4[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] / broadcast((float32*)placeholder_5[0], 3))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op add
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add_32", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: handle, float32, [512, 512, 3, 3], []),
             placeholder: Buffer(placeholder_4: handle, float32, [512, 512, 3, 3], []),
             placeholder_1: Buffer(placeholder_5: handle, float32, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  for (ax0.ax1.fused: int32, 0, 262144) "parallel" {
    for (ax2: int32, 0, 3) {
      T_add_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = ((float32x3*)placeholder_4[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] + broadcast((float32*)placeholder_5[0], 3))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op round
primfn(placeholder_1: handle, T_round_1: handle) -> ()
  attr = {"global_symbol": "fused_round_14", "tir.noalias": True}
  buffers = {T_round: Buffer(T_round_2: handle, float32, [512, 512, 3, 3], []),
             placeholder: Buffer(placeholder_2: handle, float32, [512, 512, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, T_round_1: T_round} {
  for (ax0.ax1.fused: int32, 0, 262144) "parallel" {
    for (ax2: int32, 0, 3) {
      T_round_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = @tir.round((float32x3*)placeholder_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)], dtype=float32x3)
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_29", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int32, [512, 512, 3, 3], []),
             placeholder: Buffer(placeholder_2: handle, float32, [512, 512, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 262144) "parallel" {
    for (ax2: int32, 0, 3) {
      T_cast_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = cast(int32x3, (float32x3*)placeholder_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)])
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op clip
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_clip_14", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [512, 512, 3, 3], []),
             placeholder: Buffer(placeholder_2: handle, int32, [512, 512, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0.i1.fused: int32, 0, 262144) "parallel" {
    for (i2: int32, 0, 3) {
      compute_2[ramp(((i0.i1.fused*9) + (i2*3)), 1, 3)] = max(min((int32x3*)placeholder_2[ramp(((i0.i1.fused*9) + (i2*3)), 1, 3)], broadcast(127, 3)), broadcast(-128, 3))
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_30", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [512, 512, 3, 3], []),
             placeholder: Buffer(placeholder_2: handle, int32, [512, 512, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  for (ax0.ax1.fused: int32, 0, 262144) "parallel" {
    for (ax2: int32, 0, 3) {
      T_cast_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)] = cast(int8x3, (int32x3*)placeholder_2[ramp(((ax0.ax1.fused*9) + (ax2*3)), 1, 3)])
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op layout_transform
primfn(placeholder_1: handle, T_layout_trans_1: handle) -> ()
  attr = {"global_symbol": "fused_layout_transform", "tir.noalias": True}
  buffers = {T_layout_trans: Buffer(T_layout_trans_2: handle, int8, [16, 1, 7, 7, 4, 4], []),
             placeholder: Buffer(placeholder_2: handle, int8, [64, 4, 7, 7], [])}
  buffer_map = {placeholder_1: placeholder, T_layout_trans_1: T_layout_trans} {
  for (ax0.ax1.fused.ax2.fused: int32, 0, 112) "parallel" {
    for (ax3: int32, 0, 7) {
      for (ax4: int32, 0, 4) {
        T_layout_trans_2[ramp((((ax0.ax1.fused.ax2.fused*112) + (ax3*16)) + (ax4*4)), 1, 4)] = (int8x4*)placeholder_2[ramp(((((floordiv(ax0.ax1.fused.ax2.fused, 7)*784) + (ax4*196)) + (floormod(ax0.ax1.fused.ax2.fused, 7)*7)) + ax3), 49, 4)]
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op expand_dims
primfn(placeholder_1: handle, T_expand_dims_1: handle) -> ()
  attr = {"global_symbol": "fused_expand_dims_8", "tir.noalias": True}
  buffers = {T_expand_dims: Buffer(T_expand_dims_2: handle, int32, [1, 64, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [64, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_expand_dims_1: T_expand_dims} {
  for (ax0.ax1.fused: int32, 0, 64) "parallel" {
    T_expand_dims_2[ax0.ax1.fused] = (int32*)placeholder_2[ax0.ax1.fused]
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op layout_transform
primfn(placeholder_1: handle, T_layout_trans_1: handle) -> ()
  attr = {"global_symbol": "fused_layout_transform_1", "tir.noalias": True}
  buffers = {T_layout_trans: Buffer(T_layout_trans_2: handle, int32, [1, 16, 1, 1, 4], []),
             placeholder: Buffer(placeholder_2: handle, int32, [1, 64, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_layout_trans_1: T_layout_trans} {
  for (ax0.ax1.fused.ax2.fused: int32, 0, 16) "parallel" {
    T_layout_trans_2[ramp((ax0.ax1.fused.ax2.fused*4), 1, 4)] = (int32x4*)placeholder_2[ramp((ax0.ax1.fused.ax2.fused*4), 1, 4)]
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op layout_transform
primfn(placeholder_1: handle, T_layout_trans_1: handle) -> ()
  attr = {"global_symbol": "fused_layout_transform_2", "tir.noalias": True}
  buffers = {T_layout_trans: Buffer(T_layout_trans_2: handle, int8, [16, 16, 3, 3, 4, 4], []),
             placeholder: Buffer(placeholder_2: handle, int8, [64, 64, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, T_layout_trans_1: T_layout_trans} {
  for (ax0.ax1.fused.ax2.fused: int32, 0, 768) "parallel" {
    for (ax3: int32, 0, 3) {
      for (ax4: int32, 0, 4) {
        T_layout_trans_2[ramp((((ax0.ax1.fused.ax2.fused*48) + (ax3*16)) + (ax4*4)), 1, 4)] = (int8x4*)placeholder_2[ramp((((((floordiv(ax0.ax1.fused.ax2.fused, 48)*2304) + (ax4*576)) + (floordiv(floormod(ax0.ax1.fused.ax2.fused, 48), 3)*36)) + (floormod(ax0.ax1.fused.ax2.fused, 3)*3)) + ax3), 9, 4)]
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op layout_transform
primfn(placeholder_1: handle, T_layout_trans_1: handle) -> ()
  attr = {"global_symbol": "fused_layout_transform_3", "tir.noalias": True}
  buffers = {T_layout_trans: Buffer(T_layout_trans_2: handle, int8, [32, 16, 1, 1, 4, 4], []),
             placeholder: Buffer(placeholder_2: handle, int8, [128, 64, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_layout_trans_1: T_layout_trans} {
  for (ax0.ax1.fused.ax2.fused: int32, 0, 512) "parallel" {
    for (ax4: int32, 0, 4) {
      T_layout_trans_2[ramp(((ax0.ax1.fused.ax2.fused*16) + (ax4*4)), 1, 4)] = (int8x4*)placeholder_2[ramp((((floordiv(ax0.ax1.fused.ax2.fused, 16)*256) + (ax4*64)) + (floormod(ax0.ax1.fused.ax2.fused, 16)*4)), 1, 4)]
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op expand_dims
primfn(placeholder_1: handle, T_expand_dims_1: handle) -> ()
  attr = {"global_symbol": "fused_expand_dims_9", "tir.noalias": True}
  buffers = {T_expand_dims: Buffer(T_expand_dims_2: handle, int32, [1, 128, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [128, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_expand_dims_1: T_expand_dims} {
  for (ax0.ax1.fused: int32, 0, 128) "parallel" {
    T_expand_dims_2[ax0.ax1.fused] = (int32*)placeholder_2[ax0.ax1.fused]
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op layout_transform
primfn(placeholder_1: handle, T_layout_trans_1: handle) -> ()
  attr = {"global_symbol": "fused_layout_transform_4", "tir.noalias": True}
  buffers = {T_layout_trans: Buffer(T_layout_trans_2: handle, int32, [1, 32, 1, 1, 4], []),
             placeholder: Buffer(placeholder_2: handle, int32, [1, 128, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_layout_trans_1: T_layout_trans} {
  for (ax0.ax1.fused.ax2.fused: int32, 0, 32) "parallel" {
    T_layout_trans_2[ramp((ax0.ax1.fused.ax2.fused*4), 1, 4)] = (int32x4*)placeholder_2[ramp((ax0.ax1.fused.ax2.fused*4), 1, 4)]
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op layout_transform
primfn(placeholder_1: handle, T_layout_trans_1: handle) -> ()
  attr = {"global_symbol": "fused_layout_transform_5", "tir.noalias": True}
  buffers = {T_layout_trans: Buffer(T_layout_trans_2: handle, int8, [32, 16, 3, 3, 4, 4], []),
             placeholder: Buffer(placeholder_2: handle, int8, [128, 64, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, T_layout_trans_1: T_layout_trans} {
  for (ax0.ax1.fused.ax2.fused: int32, 0, 1536) "parallel" {
    for (ax3: int32, 0, 3) {
      for (ax4: int32, 0, 4) {
        T_layout_trans_2[ramp((((ax0.ax1.fused.ax2.fused*48) + (ax3*16)) + (ax4*4)), 1, 4)] = (int8x4*)placeholder_2[ramp((((((floordiv(ax0.ax1.fused.ax2.fused, 48)*2304) + (ax4*576)) + (floordiv(floormod(ax0.ax1.fused.ax2.fused, 48), 3)*36)) + (floormod(ax0.ax1.fused.ax2.fused, 3)*3)) + ax3), 9, 4)]
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op layout_transform
primfn(placeholder_1: handle, T_layout_trans_1: handle) -> ()
  attr = {"global_symbol": "fused_layout_transform_6", "tir.noalias": True}
  buffers = {T_layout_trans: Buffer(T_layout_trans_2: handle, int8, [32, 32, 3, 3, 4, 4], []),
             placeholder: Buffer(placeholder_2: handle, int8, [128, 128, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, T_layout_trans_1: T_layout_trans} {
  for (ax0.ax1.fused.ax2.fused: int32, 0, 3072) "parallel" {
    for (ax3: int32, 0, 3) {
      for (ax4: int32, 0, 4) {
        T_layout_trans_2[ramp((((ax0.ax1.fused.ax2.fused*48) + (ax3*16)) + (ax4*4)), 1, 4)] = (int8x4*)placeholder_2[ramp((((((floordiv(ax0.ax1.fused.ax2.fused, 96)*4608) + (ax4*1152)) + (floordiv(floormod(ax0.ax1.fused.ax2.fused, 96), 3)*36)) + (floormod(ax0.ax1.fused.ax2.fused, 3)*3)) + ax3), 9, 4)]
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op layout_transform
primfn(placeholder_1: handle, T_layout_trans_1: handle) -> ()
  attr = {"global_symbol": "fused_layout_transform_7", "tir.noalias": True}
  buffers = {T_layout_trans: Buffer(T_layout_trans_2: handle, int8, [64, 32, 1, 1, 4, 4], []),
             placeholder: Buffer(placeholder_2: handle, int8, [256, 128, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_layout_trans_1: T_layout_trans} {
  for (ax0.ax1.fused.ax2.fused: int32, 0, 2048) "parallel" {
    for (ax4: int32, 0, 4) {
      T_layout_trans_2[ramp(((ax0.ax1.fused.ax2.fused*16) + (ax4*4)), 1, 4)] = (int8x4*)placeholder_2[ramp((((floordiv(ax0.ax1.fused.ax2.fused, 32)*512) + (ax4*128)) + (floormod(ax0.ax1.fused.ax2.fused, 32)*4)), 1, 4)]
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op expand_dims
primfn(placeholder_1: handle, T_expand_dims_1: handle) -> ()
  attr = {"global_symbol": "fused_expand_dims_10", "tir.noalias": True}
  buffers = {T_expand_dims: Buffer(T_expand_dims_2: handle, int32, [1, 256, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [256, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_expand_dims_1: T_expand_dims} {
  for (ax0.ax1.fused: int32, 0, 256) "parallel" {
    T_expand_dims_2[ax0.ax1.fused] = (int32*)placeholder_2[ax0.ax1.fused]
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op layout_transform
primfn(placeholder_1: handle, T_layout_trans_1: handle) -> ()
  attr = {"global_symbol": "fused_layout_transform_8", "tir.noalias": True}
  buffers = {T_layout_trans: Buffer(T_layout_trans_2: handle, int32, [1, 64, 1, 1, 4], []),
             placeholder: Buffer(placeholder_2: handle, int32, [1, 256, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_layout_trans_1: T_layout_trans} {
  for (ax0.ax1.fused.ax2.fused: int32, 0, 64) "parallel" {
    T_layout_trans_2[ramp((ax0.ax1.fused.ax2.fused*4), 1, 4)] = (int32x4*)placeholder_2[ramp((ax0.ax1.fused.ax2.fused*4), 1, 4)]
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op layout_transform
primfn(placeholder_1: handle, T_layout_trans_1: handle) -> ()
  attr = {"global_symbol": "fused_layout_transform_9", "tir.noalias": True}
  buffers = {T_layout_trans: Buffer(T_layout_trans_2: handle, int8, [64, 32, 3, 3, 4, 4], []),
             placeholder: Buffer(placeholder_2: handle, int8, [256, 128, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, T_layout_trans_1: T_layout_trans} {
  for (ax0.ax1.fused.ax2.fused: int32, 0, 6144) "parallel" {
    for (ax3: int32, 0, 3) {
      for (ax4: int32, 0, 4) {
        T_layout_trans_2[ramp((((ax0.ax1.fused.ax2.fused*48) + (ax3*16)) + (ax4*4)), 1, 4)] = (int8x4*)placeholder_2[ramp((((((floordiv(ax0.ax1.fused.ax2.fused, 96)*4608) + (ax4*1152)) + (floordiv(floormod(ax0.ax1.fused.ax2.fused, 96), 3)*36)) + (floormod(ax0.ax1.fused.ax2.fused, 3)*3)) + ax3), 9, 4)]
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op layout_transform
primfn(placeholder_1: handle, T_layout_trans_1: handle) -> ()
  attr = {"global_symbol": "fused_layout_transform_10", "tir.noalias": True}
  buffers = {T_layout_trans: Buffer(T_layout_trans_2: handle, int8, [64, 64, 3, 3, 4, 4], []),
             placeholder: Buffer(placeholder_2: handle, int8, [256, 256, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, T_layout_trans_1: T_layout_trans} {
  for (ax0.ax1.fused.ax2.fused: int32, 0, 12288) "parallel" {
    for (ax3: int32, 0, 3) {
      for (ax4: int32, 0, 4) {
        T_layout_trans_2[ramp((((ax0.ax1.fused.ax2.fused*48) + (ax3*16)) + (ax4*4)), 1, 4)] = (int8x4*)placeholder_2[ramp((((((floordiv(ax0.ax1.fused.ax2.fused, 192)*9216) + (ax4*2304)) + (floordiv(floormod(ax0.ax1.fused.ax2.fused, 192), 3)*36)) + (floormod(ax0.ax1.fused.ax2.fused, 3)*3)) + ax3), 9, 4)]
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op layout_transform
primfn(placeholder_1: handle, T_layout_trans_1: handle) -> ()
  attr = {"global_symbol": "fused_layout_transform_11", "tir.noalias": True}
  buffers = {T_layout_trans: Buffer(T_layout_trans_2: handle, int8, [128, 64, 1, 1, 4, 4], []),
             placeholder: Buffer(placeholder_2: handle, int8, [512, 256, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_layout_trans_1: T_layout_trans} {
  for (ax0.ax1.fused.ax2.fused: int32, 0, 8192) "parallel" {
    for (ax4: int32, 0, 4) {
      T_layout_trans_2[ramp(((ax0.ax1.fused.ax2.fused*16) + (ax4*4)), 1, 4)] = (int8x4*)placeholder_2[ramp((((floordiv(ax0.ax1.fused.ax2.fused, 64)*1024) + (ax4*256)) + (floormod(ax0.ax1.fused.ax2.fused, 64)*4)), 1, 4)]
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op expand_dims
primfn(placeholder_1: handle, T_expand_dims_1: handle) -> ()
  attr = {"global_symbol": "fused_expand_dims_11", "tir.noalias": True}
  buffers = {T_expand_dims: Buffer(T_expand_dims_2: handle, int32, [1, 512, 1, 1], []),
             placeholder: Buffer(placeholder_2: handle, int32, [512, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_expand_dims_1: T_expand_dims} {
  for (ax0.ax1.fused: int32, 0, 512) "parallel" {
    T_expand_dims_2[ax0.ax1.fused] = (int32*)placeholder_2[ax0.ax1.fused]
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op layout_transform
primfn(placeholder_1: handle, T_layout_trans_1: handle) -> ()
  attr = {"global_symbol": "fused_layout_transform_12", "tir.noalias": True}
  buffers = {T_layout_trans: Buffer(T_layout_trans_2: handle, int32, [1, 128, 1, 1, 4], []),
             placeholder: Buffer(placeholder_2: handle, int32, [1, 512, 1, 1], [])}
  buffer_map = {placeholder_1: placeholder, T_layout_trans_1: T_layout_trans} {
  for (ax0.ax1.fused.ax2.fused: int32, 0, 128) "parallel" {
    T_layout_trans_2[ramp((ax0.ax1.fused.ax2.fused*4), 1, 4)] = (int32x4*)placeholder_2[ramp((ax0.ax1.fused.ax2.fused*4), 1, 4)]
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op layout_transform
primfn(placeholder_1: handle, T_layout_trans_1: handle) -> ()
  attr = {"global_symbol": "fused_layout_transform_13", "tir.noalias": True}
  buffers = {T_layout_trans: Buffer(T_layout_trans_2: handle, int8, [128, 64, 3, 3, 4, 4], []),
             placeholder: Buffer(placeholder_2: handle, int8, [512, 256, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, T_layout_trans_1: T_layout_trans} {
  for (ax0.ax1.fused.ax2.fused: int32, 0, 24576) "parallel" {
    for (ax3: int32, 0, 3) {
      for (ax4: int32, 0, 4) {
        T_layout_trans_2[ramp((((ax0.ax1.fused.ax2.fused*48) + (ax3*16)) + (ax4*4)), 1, 4)] = (int8x4*)placeholder_2[ramp((((((floordiv(ax0.ax1.fused.ax2.fused, 192)*9216) + (ax4*2304)) + (floordiv(floormod(ax0.ax1.fused.ax2.fused, 192), 3)*36)) + (floormod(ax0.ax1.fused.ax2.fused, 3)*3)) + ax3), 9, 4)]
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cpu for op layout_transform
primfn(placeholder_1: handle, T_layout_trans_1: handle) -> ()
  attr = {"global_symbol": "fused_layout_transform_14", "tir.noalias": True}
  buffers = {T_layout_trans: Buffer(T_layout_trans_2: handle, int8, [128, 128, 3, 3, 4, 4], []),
             placeholder: Buffer(placeholder_2: handle, int8, [512, 512, 3, 3], [])}
  buffer_map = {placeholder_1: placeholder, T_layout_trans_1: T_layout_trans} {
  for (ax0.ax1.fused.ax2.fused: int32, 0, 49152) "parallel" {
    for (ax3: int32, 0, 3) {
      for (ax4: int32, 0, 4) {
        T_layout_trans_2[ramp((((ax0.ax1.fused.ax2.fused*48) + (ax3*16)) + (ax4*4)), 1, 4)] = (int8x4*)placeholder_2[ramp((((((floordiv(ax0.ax1.fused.ax2.fused, 384)*18432) + (ax4*4608)) + (floordiv(floormod(ax0.ax1.fused.ax2.fused, 384), 3)*36)) + (floormod(ax0.ax1.fused.ax2.fused, 3)*3)) + ax3), 9, 4)]
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cuda for op layout_transform
INFO:compile_engine:Use implementation injective.cuda for op nn.batch_flatten
primfn(placeholder_1: handle, tensor_1: handle) -> ()
  attr = {"global_symbol": "fused_layout_transform_nn_batch_flatten", "tir.noalias": True}
  buffers = {tensor: Buffer(tensor_2: handle, float32, [32, 512], []),
             placeholder: Buffer(placeholder_2: handle, float32, [32, 128, 1, 1, 4], [])}
  buffer_map = {placeholder_1: placeholder, tensor_1: tensor} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 16;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  tensor_2[((blockIdx.x*1024) + threadIdx.x)] = (float32*)placeholder_2[((blockIdx.x*1024) + threadIdx.x)]
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation adaptive_pool.cuda for op nn.global_avg_pool2d
primfn(placeholder_1: handle, tensor_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_global_avg_pool2d_1", "tir.noalias": True}
  buffers = {tensor: Buffer(tensor_2: handle, float32, [32, 128, 1, 1, 4], []),
             placeholder: Buffer(placeholder_2: handle, float32, [32, 128, 7, 7, 4], [])}
  buffer_map = {placeholder_1: placeholder, tensor_1: tensor} {
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 4;
  attr [tensor_3: handle] "storage_scope" = "local";
  allocate(tensor_3, float32, [4]);
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 16;
  attr [IterVar(threadIdx.y: int32, [0:8], "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
  attr [IterVar(threadIdx.x: int32, [0:8], "ThreadIndex", "threadIdx.x")] "thread_extent" = 8 {
    for (ax4: int32, 0, 4) {
      tensor_3[ax4] = 0f32
      for (rv0: int32, 0, 7) {
        for (rv1: int32, 0, 7) {
          tensor_3[ax4] = ((float32*)tensor_3[ax4] + (float32*)placeholder_2[(((((((blockIdx.y*200704) + (threadIdx.y*25088)) + (blockIdx.x*1568)) + (threadIdx.x*196)) + (rv0*28)) + (rv1*4)) + ax4)])
        }
      }
    }
    for (ax4_1: int32, 0, 4) {
      tensor_2[(((((blockIdx.y*4096) + (threadIdx.y*512)) + (blockIdx.x*32)) + (threadIdx.x*4)) + ax4_1)] = ((float32*)tensor_3[ax4_1]*0.0204082f32)
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op subtract
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op multiply
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_fixed_point_multiply_nn_conv2d_cast_fixed_point_multiply_add_cast_fix_5734298839780500801_", "tir.noalias": True}
  buffers = {placeholder_3: Buffer(placeholder_8: handle, int32, [1, 128, 1, 1, 4], []),
             placeholder_2: Buffer(placeholder_9: handle, int8, [128, 128, 3, 3, 4, 4], []),
             placeholder: Buffer(placeholder_10: handle, int32, [32, 128, 7, 7, 4], []),
             T_multiply: Buffer(T_multiply_2: handle, float32, [32, 128, 7, 7, 4], []),
             placeholder_1: Buffer(placeholder_11: handle, int8, [32, 128, 7, 7, 4], [])}
  buffer_map = {placeholder_4: placeholder, placeholder_5: placeholder_1, placeholder_6: placeholder_2, placeholder_7: placeholder_3, T_multiply_1: T_multiply} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 16;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [28]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [1152]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [162]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 8;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7 {
    for (oh.init: int32, 0, 7) "unroll" {
      for (oc_block.init: int32, 0, 4) "unroll" {
        compute[((oh.init*4) + oc_block.init)] = 0
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 3) "unroll" {
      attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
      attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
      if (((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*224) + (threadIdx.z_1*112)) + (threadIdx.y_1*7)) + threadIdx.x_1) < 576) {
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.z_1*16)) + threadIdx.y_1) < 83) {
          placeholder.shared[ramp((((floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*224) + (threadIdx.z_1*112)) + (threadIdx.y_1*7)) + threadIdx.x_1), 12)*48) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.z_1*28)) + floordiv(((threadIdx.y_1*7) + threadIdx.x_1), 4)), 3)*16)) + (floormod(((threadIdx.y_1*7) + threadIdx.x_1), 4)*4)), 1, 4)] = (int8x4*)placeholder_9[ramp((((((blockIdx.y*294912) + (floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*224) + (threadIdx.z_1*112)) + (threadIdx.y_1*7)) + threadIdx.x_1), 36)*18432)) + (floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*224) + (threadIdx.z_1*112)) + (threadIdx.y_1*7)) + threadIdx.x_1), 36), 12)*48)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.z_1*28)) + floordiv(((threadIdx.y_1*7) + threadIdx.x_1), 4)), 3)*16)) + (floormod(((threadIdx.y_1*7) + threadIdx.x_1), 4)*4)), 1, 4)]
        }
      }
    }
    for (ic_chunk.outer.outer: int32, 0, 127) {
      attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
      attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
      attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
      if ((((threadIdx.z_2*112) + (threadIdx.y_2*7)) + threadIdx.x_2) < 162) {
        if (((threadIdx.z_2*16) + threadIdx.y_2) < 24) {
          pad_data.shared[ramp((((threadIdx.z_2*448) + (threadIdx.y_2*28)) + (threadIdx.x_2*4)), 1, 4)] = @tir.if_then_else(((((9 <= floormod((((threadIdx.z_2*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 81)) && (floormod((((threadIdx.z_2*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 81) < 72)) && (1 <= floormod((((threadIdx.z_2*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 9))) && (floormod((((threadIdx.z_2*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 9) < 8)), (int8x4*)placeholder_11[ramp(((((((blockIdx.z*50176) + (floordiv((((threadIdx.z_2*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 81)*25088)) + (ic_chunk.outer.outer*196)) + (floordiv(floormod((((threadIdx.z_2*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 81), 9)*28)) + (floormod((((threadIdx.z_2*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 9)*4)) - 32), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
        }
      }
      attr [placeholder.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 3) "unroll" {
        attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
        attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
        attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
        if (((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*224) + (threadIdx.z_1*112)) + (threadIdx.y_1*7)) + threadIdx.x_1) < 576) {
          if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.z_1*16)) + threadIdx.y_1) < 83) {
            placeholder.shared[ramp(((((floormod((ic_chunk.outer.outer + 1), 2)*2304) + (floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*224) + (threadIdx.z_1*112)) + (threadIdx.y_1*7)) + threadIdx.x_1), 12)*48)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.z_1*28)) + floordiv(((threadIdx.y_1*7) + threadIdx.x_1), 4)), 3)*16)) + (floormod(((threadIdx.y_1*7) + threadIdx.x_1), 4)*4)), 1, 4)] = (int8x4*)placeholder_9[ramp((((((((blockIdx.y*294912) + (floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*224) + (threadIdx.z_1*112)) + (threadIdx.y_1*7)) + threadIdx.x_1), 36)*18432)) + (ic_chunk.outer.outer*144)) + (floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*224) + (threadIdx.z_1*112)) + (threadIdx.y_1*7)) + threadIdx.x_1), 36), 12)*48)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.z_1*28)) + floordiv(((threadIdx.y_1*7) + threadIdx.x_1), 4)), 3)*16)) + (floormod(((threadIdx.y_1*7) + threadIdx.x_1), 4)*4)) + 144), 1, 4)]
          }
        }
      }
      for (kw.inner: int32, 0, 3) "unroll" {
        for (kh.inner: int32, 0, 3) "unroll" {
          for (oh: int32, 0, 7) "unroll" {
            for (oc_block: int32, 0, 4) "unroll" {
              compute[((oh*4) + oc_block)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((threadIdx.z*324) + (oh*36)) + (kh.inner*36)) + (threadIdx.x*4)) + (kw.inner*4)), 1, 4)], (int8x4*)placeholder.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*2304) + (threadIdx.y*144)) + (kh.inner*48)) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[((oh*4) + oc_block)], dtype=int32)
            }
          }
        }
      }
    }
    attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
    attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
    attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
    if ((((threadIdx.z_2*112) + (threadIdx.y_2*7)) + threadIdx.x_2) < 162) {
      if (((threadIdx.z_2*16) + threadIdx.y_2) < 24) {
        pad_data.shared[ramp((((threadIdx.z_2*448) + (threadIdx.y_2*28)) + (threadIdx.x_2*4)), 1, 4)] = @tir.if_then_else(((((9 <= floormod((((threadIdx.z_2*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 81)) && (floormod((((threadIdx.z_2*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 81) < 72)) && (1 <= floormod((((threadIdx.z_2*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 9))) && (floormod((((threadIdx.z_2*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 9) < 8)), (int8x4*)placeholder_11[ramp((((((blockIdx.z*50176) + (floordiv((((threadIdx.z_2*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 81)*25088)) + (floordiv(floormod((((threadIdx.z_2*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 81), 9)*28)) + (floormod((((threadIdx.z_2*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 9)*4)) + 24860), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
      }
    }
    for (kw.inner_1: int32, 0, 3) "unroll" {
      for (kh.inner_1: int32, 0, 3) "unroll" {
        for (oh_1: int32, 0, 7) "unroll" {
          for (oc_block_1: int32, 0, 4) "unroll" {
            compute[((oh_1*4) + oc_block_1)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((threadIdx.z*324) + (oh_1*36)) + (kh.inner_1*36)) + (threadIdx.x*4)) + (kw.inner_1*4)), 1, 4)], (int8x4*)placeholder.shared[ramp((((((threadIdx.y*144) + (kh.inner_1*48)) + (kw.inner_1*16)) + (oc_block_1*4)) + 2304), 1, 4)], (int32*)compute[((oh_1*4) + oc_block_1)], dtype=int32)
          }
        }
      }
    }
    for (ax2.inner.inner.inner: int32, 0, 7) "unroll" {
      for (ax4: int32, 0, 4) "unroll" {
        T_multiply_2[(((((((blockIdx.z*50176) + (threadIdx.z*25088)) + (blockIdx.y*3136)) + (threadIdx.y*196)) + (ax2.inner.inner.inner*28)) + (threadIdx.x*4)) + ax4)] = (cast(float32, max((@tir.q_multiply_shift((int32*)placeholder_10[(((((((blockIdx.z*50176) + (threadIdx.z*25088)) + (blockIdx.y*3136)) + (threadIdx.y*196)) + (ax2.inner.inner.inner*28)) + (threadIdx.x*4)) + ax4)], 1389035277, 31, -2, dtype=int32) + @tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[((ax2.inner.inner.inner*4) + ax4)], 1494953172, 31, 16, dtype=int32) + (int32*)placeholder_8[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 2115906545, 31, 0, dtype=int32)), 0))*1.5472e-08f32)
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_relu_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_fixed_point_multiply_add_cast_13255070459903635369_", "tir.noalias": True}
  buffers = {T_relu: Buffer(T_relu_2: handle, int32, [32, 128, 7, 7, 4], []),
             placeholder_3: Buffer(placeholder_8: handle, int8, [32, 64, 14, 14, 4], []),
             placeholder_2: Buffer(placeholder_9: handle, int32, [1, 128, 1, 1, 4], []),
             placeholder: Buffer(placeholder_10: handle, int8, [128, 64, 1, 1, 4, 4], []),
             placeholder_1: Buffer(placeholder_11: handle, int32, [32, 128, 7, 7, 4], [])}
  buffer_map = {placeholder_5: placeholder, placeholder_7: placeholder_1, placeholder_6: placeholder_2, placeholder_4: placeholder_3, T_relu_1: T_relu} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 4;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [32]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [832]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [512]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 8;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 7;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 16;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 1;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7 {
    for (oc_block.init: int32, 0, 4) "unroll" {
      compute[oc_block.init] = 0
      compute[(oc_block.init + 8)] = 0
      compute[(oc_block.init + 16)] = 0
      compute[(oc_block.init + 24)] = 0
      compute[(oc_block.init + 4)] = 0
      compute[(oc_block.init + 12)] = 0
      compute[(oc_block.init + 20)] = 0
      compute[(oc_block.init + 28)] = 0
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 4) "unroll" {
      attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 16;
      attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 1;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*112) + (threadIdx.z_1*7)) + threadIdx.x_1) < 416) {
        if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*16) + threadIdx.z_1) < 60) {
          pad_data.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*448) + (threadIdx.z_1*28)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_8[ramp((((((blockIdx.z*401408) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*112) + (threadIdx.z_1*7)) + threadIdx.x_1), 52)*50176)) + (floordiv(floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*112) + (threadIdx.z_1*7)) + threadIdx.x_1), 52), 13)*784)) + (blockIdx.x*112)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*112) + (threadIdx.z_1*7)) + threadIdx.x_1), 13)*4)), 1, 4)]
        }
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 3) "unroll" {
      attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 16;
      attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 1;
      attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*112) + (threadIdx.z_2*7)) + threadIdx.x_2) < 256) {
        if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*16) + threadIdx.z_2) < 37) {
          if ((((blockIdx.y*16) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*7)) + floordiv(((threadIdx.z_2*7) + threadIdx.x_2), 16)) < 128) {
            placeholder.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*448) + (threadIdx.z_2*28)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_10[ramp(((((blockIdx.y*16384) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*7168)) + (floordiv(((threadIdx.z_2*7) + threadIdx.x_2), 16)*1024)) + (floormod(((threadIdx.z_2*7) + threadIdx.x_2), 16)*4)), 1, 4)]
          }
        }
      }
    }
    for (ic_chunk.outer.outer: int32, 0, 15) {
      attr [pad_data.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1: int32, 0, 4) "unroll" {
        attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 16;
        attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 1;
        attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*112) + (threadIdx.z_1*7)) + threadIdx.x_1) < 416) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*16) + threadIdx.z_1) < 60) {
            pad_data.shared[ramp(((((floormod((ic_chunk.outer.outer + 1), 2)*1664) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*448)) + (threadIdx.z_1*28)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_8[ramp((((((((blockIdx.z*401408) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*112) + (threadIdx.z_1*7)) + threadIdx.x_1), 52)*50176)) + (ic_chunk.outer.outer*3136)) + (floordiv(floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*112) + (threadIdx.z_1*7)) + threadIdx.x_1), 52), 13)*784)) + (blockIdx.x*112)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*112) + (threadIdx.z_1*7)) + threadIdx.x_1), 13)*4)) + 3136), 1, 4)]
          }
        }
      }
      attr [placeholder.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 3) "unroll" {
        attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 16;
        attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 1;
        attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*112) + (threadIdx.z_2*7)) + threadIdx.x_2) < 256) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*16) + threadIdx.z_2) < 37) {
            if ((((blockIdx.y*16) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*7)) + floordiv(((threadIdx.z_2*7) + threadIdx.x_2), 16)) < 128) {
              placeholder.shared[ramp(((((floormod((ic_chunk.outer.outer + 1), 2)*1024) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*448)) + (threadIdx.z_2*28)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_10[ramp(((((((blockIdx.y*16384) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*7168)) + (floordiv(((threadIdx.z_2*7) + threadIdx.x_2), 16)*1024)) + (ic_chunk.outer.outer*64)) + (floormod(((threadIdx.z_2*7) + threadIdx.x_2), 16)*4)) + 64), 1, 4)]
            }
          }
        }
      }
      for (ic_chunk.inner: int32, 0, 4) "unroll" {
        for (oc_block: int32, 0, 4) "unroll" {
          compute[oc_block] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*1664) + (floordiv(threadIdx.z, 8)*208)) + (ic_chunk.inner*52)) + (threadIdx.x*8)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*1024) + (floormod(threadIdx.z, 8)*64)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[oc_block], dtype=int32)
          compute[(oc_block + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*1664) + (floordiv(threadIdx.z, 8)*208)) + (ic_chunk.inner*52)) + (threadIdx.x*8)) + 416), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*1024) + (floormod(threadIdx.z, 8)*64)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 8)], dtype=int32)
          compute[(oc_block + 16)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*1664) + (floordiv(threadIdx.z, 8)*208)) + (ic_chunk.inner*52)) + (threadIdx.x*8)) + 832), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*1024) + (floormod(threadIdx.z, 8)*64)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 16)], dtype=int32)
          compute[(oc_block + 24)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*1664) + (floordiv(threadIdx.z, 8)*208)) + (ic_chunk.inner*52)) + (threadIdx.x*8)) + 1248), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*1024) + (floormod(threadIdx.z, 8)*64)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(oc_block + 24)], dtype=int32)
          compute[(oc_block + 4)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*1664) + (floordiv(threadIdx.z, 8)*208)) + (ic_chunk.inner*52)) + (threadIdx.x*8)), 1, 4)], (int8x4*)placeholder.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*1024) + (floormod(threadIdx.z, 8)*64)) + (ic_chunk.inner*16)) + (oc_block*4)) + 512), 1, 4)], (int32*)compute[(oc_block + 4)], dtype=int32)
          compute[(oc_block + 12)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*1664) + (floordiv(threadIdx.z, 8)*208)) + (ic_chunk.inner*52)) + (threadIdx.x*8)) + 416), 1, 4)], (int8x4*)placeholder.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*1024) + (floormod(threadIdx.z, 8)*64)) + (ic_chunk.inner*16)) + (oc_block*4)) + 512), 1, 4)], (int32*)compute[(oc_block + 12)], dtype=int32)
          compute[(oc_block + 20)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*1664) + (floordiv(threadIdx.z, 8)*208)) + (ic_chunk.inner*52)) + (threadIdx.x*8)) + 832), 1, 4)], (int8x4*)placeholder.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*1024) + (floormod(threadIdx.z, 8)*64)) + (ic_chunk.inner*16)) + (oc_block*4)) + 512), 1, 4)], (int32*)compute[(oc_block + 20)], dtype=int32)
          compute[(oc_block + 28)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*1664) + (floordiv(threadIdx.z, 8)*208)) + (ic_chunk.inner*52)) + (threadIdx.x*8)) + 1248), 1, 4)], (int8x4*)placeholder.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*1024) + (floormod(threadIdx.z, 8)*64)) + (ic_chunk.inner*16)) + (oc_block*4)) + 512), 1, 4)], (int32*)compute[(oc_block + 28)], dtype=int32)
        }
      }
    }
    for (ic_chunk.inner_1: int32, 0, 4) "unroll" {
      for (oc_block_1: int32, 0, 4) "unroll" {
        compute[oc_block_1] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floordiv(threadIdx.z, 8)*208) + (ic_chunk.inner_1*52)) + (threadIdx.x*8)) + 1664), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(threadIdx.z, 8)*64) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 1024), 1, 4)], (int32*)compute[oc_block_1], dtype=int32)
        compute[(oc_block_1 + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floordiv(threadIdx.z, 8)*208) + (ic_chunk.inner_1*52)) + (threadIdx.x*8)) + 2080), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(threadIdx.z, 8)*64) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 1024), 1, 4)], (int32*)compute[(oc_block_1 + 8)], dtype=int32)
        compute[(oc_block_1 + 16)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floordiv(threadIdx.z, 8)*208) + (ic_chunk.inner_1*52)) + (threadIdx.x*8)) + 2496), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(threadIdx.z, 8)*64) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 1024), 1, 4)], (int32*)compute[(oc_block_1 + 16)], dtype=int32)
        compute[(oc_block_1 + 24)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floordiv(threadIdx.z, 8)*208) + (ic_chunk.inner_1*52)) + (threadIdx.x*8)) + 2912), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(threadIdx.z, 8)*64) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 1024), 1, 4)], (int32*)compute[(oc_block_1 + 24)], dtype=int32)
        compute[(oc_block_1 + 4)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floordiv(threadIdx.z, 8)*208) + (ic_chunk.inner_1*52)) + (threadIdx.x*8)) + 1664), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(threadIdx.z, 8)*64) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 1536), 1, 4)], (int32*)compute[(oc_block_1 + 4)], dtype=int32)
        compute[(oc_block_1 + 12)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floordiv(threadIdx.z, 8)*208) + (ic_chunk.inner_1*52)) + (threadIdx.x*8)) + 2080), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(threadIdx.z, 8)*64) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 1536), 1, 4)], (int32*)compute[(oc_block_1 + 12)], dtype=int32)
        compute[(oc_block_1 + 20)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floordiv(threadIdx.z, 8)*208) + (ic_chunk.inner_1*52)) + (threadIdx.x*8)) + 2496), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(threadIdx.z, 8)*64) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 1536), 1, 4)], (int32*)compute[(oc_block_1 + 20)], dtype=int32)
        compute[(oc_block_1 + 28)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floordiv(threadIdx.z, 8)*208) + (ic_chunk.inner_1*52)) + (threadIdx.x*8)) + 2912), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(threadIdx.z, 8)*64) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 1536), 1, 4)], (int32*)compute[(oc_block_1 + 28)], dtype=int32)
      }
    }
    for (ax4: int32, 0, 4) "unroll" {
      T_relu_2[(((((((blockIdx.z*200704) + (floordiv(threadIdx.z, 8)*25088)) + (blockIdx.y*3136)) + (floormod(threadIdx.z, 8)*196)) + (blockIdx.x*28)) + (threadIdx.x*4)) + ax4)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[ax4], 1681959885, 31, 19, dtype=int32) + (int32*)placeholder_9[(((blockIdx.y*64) + (floormod(threadIdx.z, 8)*4)) + ax4)]), 1734818005, 31, -1, dtype=int32) + (int32*)placeholder_11[(((((((blockIdx.z*200704) + (floordiv(threadIdx.z, 8)*25088)) + (blockIdx.y*3136)) + (floormod(threadIdx.z, 8)*196)) + (blockIdx.x*28)) + (threadIdx.x*4)) + ax4)]), 0)
      T_relu_2[((((((((blockIdx.z*200704) + (floordiv(threadIdx.z, 8)*25088)) + (blockIdx.y*3136)) + (floormod(threadIdx.z, 8)*196)) + (blockIdx.x*28)) + (threadIdx.x*4)) + ax4) + 50176)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 8)], 1681959885, 31, 19, dtype=int32) + (int32*)placeholder_9[(((blockIdx.y*64) + (floormod(threadIdx.z, 8)*4)) + ax4)]), 1734818005, 31, -1, dtype=int32) + (int32*)placeholder_11[((((((((blockIdx.z*200704) + (floordiv(threadIdx.z, 8)*25088)) + (blockIdx.y*3136)) + (floormod(threadIdx.z, 8)*196)) + (blockIdx.x*28)) + (threadIdx.x*4)) + ax4) + 50176)]), 0)
      T_relu_2[((((((((blockIdx.z*200704) + (floordiv(threadIdx.z, 8)*25088)) + (blockIdx.y*3136)) + (floormod(threadIdx.z, 8)*196)) + (blockIdx.x*28)) + (threadIdx.x*4)) + ax4) + 100352)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 16)], 1681959885, 31, 19, dtype=int32) + (int32*)placeholder_9[(((blockIdx.y*64) + (floormod(threadIdx.z, 8)*4)) + ax4)]), 1734818005, 31, -1, dtype=int32) + (int32*)placeholder_11[((((((((blockIdx.z*200704) + (floordiv(threadIdx.z, 8)*25088)) + (blockIdx.y*3136)) + (floormod(threadIdx.z, 8)*196)) + (blockIdx.x*28)) + (threadIdx.x*4)) + ax4) + 100352)]), 0)
      T_relu_2[((((((((blockIdx.z*200704) + (floordiv(threadIdx.z, 8)*25088)) + (blockIdx.y*3136)) + (floormod(threadIdx.z, 8)*196)) + (blockIdx.x*28)) + (threadIdx.x*4)) + ax4) + 150528)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 24)], 1681959885, 31, 19, dtype=int32) + (int32*)placeholder_9[(((blockIdx.y*64) + (floormod(threadIdx.z, 8)*4)) + ax4)]), 1734818005, 31, -1, dtype=int32) + (int32*)placeholder_11[((((((((blockIdx.z*200704) + (floordiv(threadIdx.z, 8)*25088)) + (blockIdx.y*3136)) + (floormod(threadIdx.z, 8)*196)) + (blockIdx.x*28)) + (threadIdx.x*4)) + ax4) + 150528)]), 0)
      T_relu_2[((((((((blockIdx.z*200704) + (floordiv(threadIdx.z, 8)*25088)) + (blockIdx.y*3136)) + (floormod(threadIdx.z, 8)*196)) + (blockIdx.x*28)) + (threadIdx.x*4)) + ax4) + 1568)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 4)], 1681959885, 31, 19, dtype=int32) + (int32*)placeholder_9[((((blockIdx.y*64) + (floormod(threadIdx.z, 8)*4)) + ax4) + 32)]), 1734818005, 31, -1, dtype=int32) + (int32*)placeholder_11[((((((((blockIdx.z*200704) + (floordiv(threadIdx.z, 8)*25088)) + (blockIdx.y*3136)) + (floormod(threadIdx.z, 8)*196)) + (blockIdx.x*28)) + (threadIdx.x*4)) + ax4) + 1568)]), 0)
      T_relu_2[((((((((blockIdx.z*200704) + (floordiv(threadIdx.z, 8)*25088)) + (blockIdx.y*3136)) + (floormod(threadIdx.z, 8)*196)) + (blockIdx.x*28)) + (threadIdx.x*4)) + ax4) + 51744)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 12)], 1681959885, 31, 19, dtype=int32) + (int32*)placeholder_9[((((blockIdx.y*64) + (floormod(threadIdx.z, 8)*4)) + ax4) + 32)]), 1734818005, 31, -1, dtype=int32) + (int32*)placeholder_11[((((((((blockIdx.z*200704) + (floordiv(threadIdx.z, 8)*25088)) + (blockIdx.y*3136)) + (floormod(threadIdx.z, 8)*196)) + (blockIdx.x*28)) + (threadIdx.x*4)) + ax4) + 51744)]), 0)
      T_relu_2[((((((((blockIdx.z*200704) + (floordiv(threadIdx.z, 8)*25088)) + (blockIdx.y*3136)) + (floormod(threadIdx.z, 8)*196)) + (blockIdx.x*28)) + (threadIdx.x*4)) + ax4) + 101920)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 20)], 1681959885, 31, 19, dtype=int32) + (int32*)placeholder_9[((((blockIdx.y*64) + (floormod(threadIdx.z, 8)*4)) + ax4) + 32)]), 1734818005, 31, -1, dtype=int32) + (int32*)placeholder_11[((((((((blockIdx.z*200704) + (floordiv(threadIdx.z, 8)*25088)) + (blockIdx.y*3136)) + (floormod(threadIdx.z, 8)*196)) + (blockIdx.x*28)) + (threadIdx.x*4)) + ax4) + 101920)]), 0)
      T_relu_2[((((((((blockIdx.z*200704) + (floordiv(threadIdx.z, 8)*25088)) + (blockIdx.y*3136)) + (floormod(threadIdx.z, 8)*196)) + (blockIdx.x*28)) + (threadIdx.x*4)) + ax4) + 152096)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(ax4 + 28)], 1681959885, 31, 19, dtype=int32) + (int32*)placeholder_9[((((blockIdx.y*64) + (floormod(threadIdx.z, 8)*4)) + ax4) + 32)]), 1734818005, 31, -1, dtype=int32) + (int32*)placeholder_11[((((((((blockIdx.z*200704) + (floordiv(threadIdx.z, 8)*25088)) + (blockIdx.y*3136)) + (floormod(threadIdx.z, 8)*196)) + (blockIdx.x*28)) + (threadIdx.x*4)) + ax4) + 152096)]), 0)
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_fixed_point_multiply_clip_cast", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [32, 64, 14, 14, 4], []),
             placeholder: Buffer(placeholder_2: handle, int32, [32, 64, 14, 14, 4], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer: int32, 0, 7) {
    if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*65536) + (blockIdx.x*256)) + floordiv(threadIdx.x, 4)) < 401408) {
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x) < 1605632) {
        T_cast_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = cast(int8, max(min(@tir.q_multiply_shift((int32*)placeholder_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)], 1839678963, 31, -24, dtype=int32), 127), -128))
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_relu_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_fixed_point_multiply_nn_conv2d_cast_fixed_point_multiply_add_cast_fix_1476761249106760241_", "tir.noalias": True}
  buffers = {placeholder_3: Buffer(placeholder_8: handle, int8, [64, 64, 3, 3, 4, 4], []),
             placeholder_2: Buffer(placeholder_9: handle, int32, [32, 64, 14, 14, 4], []),
             placeholder_1: Buffer(placeholder_10: handle, int32, [1, 64, 1, 1, 4], []),
             T_relu: Buffer(T_relu_2: handle, int32, [32, 64, 14, 14, 4], []),
             placeholder: Buffer(placeholder_11: handle, int8, [32, 64, 14, 14, 4], [])}
  buffer_map = {T_relu_1: T_relu, placeholder_5: placeholder, placeholder_7: placeholder_1, placeholder_4: placeholder_2, placeholder_6: placeholder_3} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 8;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [28]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [1024]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [1152]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 8;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 7;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 4;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4 {
    for (oh.init: int32, 0, 7) "unroll" {
      for (oc_block.init: int32, 0, 4) "unroll" {
        compute[((oh.init*4) + oc_block.init)] = 0
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 4) "unroll" {
      attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 4;
      attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
      pad_data.shared[ramp(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*512) + (threadIdx.z_1*128)) + (threadIdx.y_1*16)) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((1 <= floormod(((threadIdx.z_1*8) + threadIdx.y_1), 16)) && (floormod(((threadIdx.z_1*8) + threadIdx.y_1), 16) < 15)) && (1 <= ((blockIdx.x*2) + threadIdx.x_1))) && (((blockIdx.x*2) + threadIdx.x_1) < 15)), (int8x4*)placeholder_11[ramp((((((((blockIdx.z*200704) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*50176)) + (floordiv(((threadIdx.z_1*8) + threadIdx.y_1), 16)*784)) + (floormod(((threadIdx.z_1*8) + threadIdx.y_1), 16)*56)) + (blockIdx.x*8)) + (threadIdx.x_1*4)) - 60), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 5) "unroll" {
      attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 4;
      attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
      attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.z_2*8)) + threadIdx.y_2) < 144) {
        if (((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*128) + (threadIdx.z_2*32)) + (threadIdx.y_2*4)) + threadIdx.x_2) < 576) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*4) + threadIdx.z_2) < 18) {
            placeholder.shared[ramp(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*512) + (threadIdx.z_2*128)) + (threadIdx.y_2*16)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp(((((blockIdx.y*73728) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.z_2*8)) + threadIdx.y_2), 18)*9216)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.z_2*8)) + threadIdx.y_2), 18)*16)) + (threadIdx.x_2*4)), 1, 4)]
          }
        }
      }
    }
    for (ic_chunk.outer.outer: int32, 0, 31) {
      attr [pad_data.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1: int32, 0, 4) "unroll" {
        attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 4;
        attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
        attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
        pad_data.shared[ramp((((((floormod((ic_chunk.outer.outer + 1), 2)*2048) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*512)) + (threadIdx.z_1*128)) + (threadIdx.y_1*16)) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((1 <= floormod(((threadIdx.z_1*8) + threadIdx.y_1), 16)) && (floormod(((threadIdx.z_1*8) + threadIdx.y_1), 16) < 15)) && (1 <= ((blockIdx.x*2) + threadIdx.x_1))) && (((blockIdx.x*2) + threadIdx.x_1) < 15)), (int8x4*)placeholder_11[ramp(((((((((blockIdx.z*200704) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*50176)) + (ic_chunk.outer.outer*1568)) + (floordiv(((threadIdx.z_1*8) + threadIdx.y_1), 16)*784)) + (floormod(((threadIdx.z_1*8) + threadIdx.y_1), 16)*56)) + (blockIdx.x*8)) + (threadIdx.x_1*4)) + 1508), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
      }
      attr [placeholder.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 5) "unroll" {
        attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 4;
        attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
        attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.z_2*8)) + threadIdx.y_2) < 144) {
          if (((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_2*32)) + (threadIdx.y_2*4)) + threadIdx.x_2) < 576) {
            if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*4) + threadIdx.z_2) < 18) {
              placeholder.shared[ramp((((((floormod((ic_chunk.outer.outer + 1), 2)*2304) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*512)) + (threadIdx.z_2*128)) + (threadIdx.y_2*16)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp(((((((blockIdx.y*73728) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.z_2*8)) + threadIdx.y_2), 18)*9216)) + (ic_chunk.outer.outer*288)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.z_2*8)) + threadIdx.y_2), 18)*16)) + (threadIdx.x_2*4)) + 288), 1, 4)]
            }
          }
        }
      }
      for (ic_chunk.inner: int32, 0, 2) "unroll" {
        for (kw.inner: int32, 0, 3) "unroll" {
          for (kh.inner: int32, 0, 3) "unroll" {
            for (oh: int32, 0, 7) "unroll" {
              for (oc_block: int32, 0, 4) "unroll" {
                compute[((oh*4) + oc_block)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((((((floormod(ic_chunk.outer.outer, 2)*2048) + (threadIdx.z*512)) + (ic_chunk.inner*256)) + (floordiv(threadIdx.x, 2)*112)) + (oh*16)) + (kh.inner*16)) + (kw.inner*4)) + (floormod(threadIdx.x, 2)*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((((floormod(ic_chunk.outer.outer, 2)*2304) + (threadIdx.y*288)) + (ic_chunk.inner*144)) + (kh.inner*48)) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[((oh*4) + oc_block)], dtype=int32)
              }
            }
          }
        }
      }
    }
    for (ic_chunk.inner_1: int32, 0, 2) "unroll" {
      for (kw.inner_1: int32, 0, 3) "unroll" {
        for (kh.inner_1: int32, 0, 3) "unroll" {
          for (oh_1: int32, 0, 7) "unroll" {
            for (oc_block_1: int32, 0, 4) "unroll" {
              compute[((oh_1*4) + oc_block_1)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((((((threadIdx.z*512) + (ic_chunk.inner_1*256)) + (floordiv(threadIdx.x, 2)*112)) + (oh_1*16)) + (kh.inner_1*16)) + (kw.inner_1*4)) + (floormod(threadIdx.x, 2)*4)) + 2048), 1, 4)], (int8x4*)placeholder.shared[ramp(((((((threadIdx.y*288) + (ic_chunk.inner_1*144)) + (kh.inner_1*48)) + (kw.inner_1*16)) + (oc_block_1*4)) + 2304), 1, 4)], (int32*)compute[((oh_1*4) + oc_block_1)], dtype=int32)
            }
          }
        }
      }
    }
    for (ax2.inner.inner.inner: int32, 0, 7) "unroll" {
      for (ax4: int32, 0, 4) "unroll" {
        T_relu_2[(((((((((blockIdx.z*200704) + (threadIdx.z*50176)) + (blockIdx.y*6272)) + (threadIdx.y*784)) + (floordiv(threadIdx.x, 2)*392)) + (ax2.inner.inner.inner*56)) + (blockIdx.x*8)) + (floormod(threadIdx.x, 2)*4)) + ax4)] = max((@tir.q_multiply_shift((int32*)placeholder_9[(((((((((blockIdx.z*200704) + (threadIdx.z*50176)) + (blockIdx.y*6272)) + (threadIdx.y*784)) + (floordiv(threadIdx.x, 2)*392)) + (ax2.inner.inner.inner*56)) + (blockIdx.x*8)) + (floormod(threadIdx.x, 2)*4)) + ax4)], 1940156806, 31, 0, dtype=int32) + @tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[((ax2.inner.inner.inner*4) + ax4)], 1804115175, 31, 16, dtype=int32) + (int32*)placeholder_10[(((blockIdx.y*32) + (threadIdx.y*4)) + ax4)]), 1118691894, 31, 1, dtype=int32)), 0)
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_relu_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_fixed_point_multiply_add_cast_13255070459903635369__1", "tir.noalias": True}
  buffers = {placeholder_3: Buffer(placeholder_8: handle, int8, [32, 32, 28, 28, 4], []),
             placeholder_2: Buffer(placeholder_9: handle, int32, [1, 64, 1, 1, 4], []),
             T_relu: Buffer(T_relu_2: handle, int32, [32, 64, 14, 14, 4], []),
             placeholder: Buffer(placeholder_10: handle, int8, [64, 32, 1, 1, 4, 4], []),
             placeholder_1: Buffer(placeholder_11: handle, int32, [32, 64, 14, 14, 4], [])}
  buffer_map = {placeholder_5: placeholder, placeholder_7: placeholder_1, T_relu_1: T_relu, placeholder_6: placeholder_2, placeholder_4: placeholder_3} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 8;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [32]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [432]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [256]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 4;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 14;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 8;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 1;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 14 {
    for (n.init: int32, 0, 4) "unroll" {
      for (oc_block.init: int32, 0, 4) "unroll" {
        compute[((n.init*4) + oc_block.init)] = 0
        compute[(((n.init*4) + oc_block.init) + 16)] = 0
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 2) "unroll" {
      attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 8;
      attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 1;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 14;
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*112) + (threadIdx.z_1*14)) + threadIdx.x_1) < 216) {
        pad_data.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*448) + (threadIdx.z_1*56)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_8[ramp((((((blockIdx.z*401408) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*112) + (threadIdx.z_1*14)) + threadIdx.x_1), 54)*100352)) + (floordiv(floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*112) + (threadIdx.z_1*14)) + threadIdx.x_1), 54), 27)*3136)) + (blockIdx.x*224)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*112) + (threadIdx.z_1*14)) + threadIdx.x_1), 27)*4)), 1, 4)]
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 2) "unroll" {
      attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 8;
      attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 1;
      attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 14;
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*112) + (threadIdx.z_2*14)) + threadIdx.x_2) < 128) {
        if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*8) + threadIdx.z_2) < 10) {
          if ((((blockIdx.y*16) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*14)) + floordiv(((threadIdx.z_2*14) + threadIdx.x_2), 8)) < 64) {
            placeholder.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*448) + (threadIdx.z_2*56)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_10[ramp(((((blockIdx.y*8192) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*7168)) + (floordiv(((threadIdx.z_2*14) + threadIdx.x_2), 8)*512)) + (floormod(((threadIdx.z_2*14) + threadIdx.x_2), 8)*4)), 1, 4)]
          }
        }
      }
    }
    for (ic_chunk.outer.outer: int32, 0, 15) "unroll" {
      attr [pad_data.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1: int32, 0, 2) "unroll" {
        attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 8;
        attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 1;
        attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 14;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*112) + (threadIdx.z_1*14)) + threadIdx.x_1) < 216) {
          pad_data.shared[ramp(((((floormod((ic_chunk.outer.outer + 1), 2)*864) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*448)) + (threadIdx.z_1*56)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_8[ramp((((((((blockIdx.z*401408) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*112) + (threadIdx.z_1*14)) + threadIdx.x_1), 54)*100352)) + (ic_chunk.outer.outer*6272)) + (floordiv(floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*112) + (threadIdx.z_1*14)) + threadIdx.x_1), 54), 27)*3136)) + (blockIdx.x*224)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*112) + (threadIdx.z_1*14)) + threadIdx.x_1), 27)*4)) + 6272), 1, 4)]
        }
      }
      attr [placeholder.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 2) "unroll" {
        attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 8;
        attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 1;
        attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 14;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*112) + (threadIdx.z_2*14)) + threadIdx.x_2) < 128) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*8) + threadIdx.z_2) < 10) {
            if ((((blockIdx.y*16) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*14)) + floordiv(((threadIdx.z_2*14) + threadIdx.x_2), 8)) < 64) {
              placeholder.shared[ramp(((((floormod((ic_chunk.outer.outer + 1), 2)*512) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*448)) + (threadIdx.z_2*56)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_10[ramp(((((((blockIdx.y*8192) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*7168)) + (floordiv(((threadIdx.z_2*14) + threadIdx.x_2), 8)*512)) + (ic_chunk.outer.outer*32)) + (floormod(((threadIdx.z_2*14) + threadIdx.x_2), 8)*4)) + 32), 1, 4)]
            }
          }
        }
      }
      for (ic_chunk.inner: int32, 0, 2) "unroll" {
        for (n: int32, 0, 4) "unroll" {
          for (oc_block: int32, 0, 4) "unroll" {
            compute[((n*4) + oc_block)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*864) + (n*216)) + (ic_chunk.inner*108)) + (threadIdx.x*8)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*512) + (threadIdx.z*32)) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[((n*4) + oc_block)], dtype=int32)
            compute[(((n*4) + oc_block) + 16)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floormod(ic_chunk.outer.outer, 2)*864) + (n*216)) + (ic_chunk.inner*108)) + (threadIdx.x*8)), 1, 4)], (int8x4*)placeholder.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*512) + (threadIdx.z*32)) + (ic_chunk.inner*16)) + (oc_block*4)) + 256), 1, 4)], (int32*)compute[(((n*4) + oc_block) + 16)], dtype=int32)
          }
        }
      }
    }
    for (ic_chunk.inner_1: int32, 0, 2) "unroll" {
      for (n_1: int32, 0, 4) "unroll" {
        for (oc_block_1: int32, 0, 4) "unroll" {
          compute[((n_1*4) + oc_block_1)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((n_1*216) + (ic_chunk.inner_1*108)) + (threadIdx.x*8)) + 864), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.z*32) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 512), 1, 4)], (int32*)compute[((n_1*4) + oc_block_1)], dtype=int32)
          compute[(((n_1*4) + oc_block_1) + 16)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((n_1*216) + (ic_chunk.inner_1*108)) + (threadIdx.x*8)) + 864), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.z*32) + (ic_chunk.inner_1*16)) + (oc_block_1*4)) + 768), 1, 4)], (int32*)compute[(((n_1*4) + oc_block_1) + 16)], dtype=int32)
        }
      }
    }
    for (ax0.inner.inner.inner.inner: int32, 0, 4) "unroll" {
      for (ax4: int32, 0, 4) "unroll" {
        T_relu_2[(((((((blockIdx.z*200704) + (ax0.inner.inner.inner.inner*50176)) + (blockIdx.y*12544)) + (threadIdx.z*784)) + (blockIdx.x*56)) + (threadIdx.x*4)) + ax4)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[((ax0.inner.inner.inner.inner*4) + ax4)], 1170196338, 31, 18, dtype=int32) + (int32*)placeholder_9[(((blockIdx.y*64) + (threadIdx.z*4)) + ax4)]), 1537115942, 31, -1, dtype=int32) + (int32*)placeholder_11[(((((((blockIdx.z*200704) + (ax0.inner.inner.inner.inner*50176)) + (blockIdx.y*12544)) + (threadIdx.z*784)) + (blockIdx.x*56)) + (threadIdx.x*4)) + ax4)]), 0)
        T_relu_2[((((((((blockIdx.z*200704) + (ax0.inner.inner.inner.inner*50176)) + (blockIdx.y*12544)) + (threadIdx.z*784)) + (blockIdx.x*56)) + (threadIdx.x*4)) + ax4) + 6272)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(((ax0.inner.inner.inner.inner*4) + ax4) + 16)], 1170196338, 31, 18, dtype=int32) + (int32*)placeholder_9[((((blockIdx.y*64) + (threadIdx.z*4)) + ax4) + 32)]), 1537115942, 31, -1, dtype=int32) + (int32*)placeholder_11[((((((((blockIdx.z*200704) + (ax0.inner.inner.inner.inner*50176)) + (blockIdx.y*12544)) + (threadIdx.z*784)) + (blockIdx.x*56)) + (threadIdx.x*4)) + ax4) + 6272)]), 0)
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_fixed_point_multiply_clip_cast_1", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [32, 32, 28, 28, 4], []),
             placeholder: Buffer(placeholder_2: handle, int32, [32, 32, 28, 28, 4], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer: int32, 0, 13) {
    if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*65536) + (blockIdx.x*256)) + floordiv(threadIdx.x, 4)) < 802816) {
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x) < 3211264) {
        T_cast_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = cast(int8, max(min(@tir.q_multiply_shift((int32*)placeholder_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)], 2058331460, 31, -24, dtype=int32), 127), -128))
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_relu_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_fixed_point_multiply_nn_conv2d_cast_fixed_point_multiply_add_cast_fix_1476761249106760241__1", "tir.noalias": True}
  buffers = {placeholder_2: Buffer(placeholder_8: handle, int32, [1, 32, 1, 1, 4], []),
             placeholder_1: Buffer(placeholder_9: handle, int8, [32, 32, 3, 3, 4, 4], []),
             T_relu: Buffer(T_relu_2: handle, int32, [32, 32, 28, 28, 4], []),
             placeholder_3: Buffer(placeholder_10: handle, int32, [32, 32, 28, 28, 4], []),
             placeholder: Buffer(placeholder_11: handle, int8, [32, 32, 28, 28, 4], [])}
  buffer_map = {T_relu_1: T_relu, placeholder_5: placeholder, placeholder_6: placeholder_1, placeholder_7: placeholder_2, placeholder_4: placeholder_3} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 32;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [56]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [96]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [288]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 4;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 14;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 4;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 2;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4 {
    for (oc_chunk.init: int32, 0, 2) "unroll" {
      for (oh.init: int32, 0, 7) "unroll" {
        for (oc_block.init: int32, 0, 4) "unroll" {
          compute[(((oc_chunk.init*28) + (oh.init*4)) + oc_block.init)] = 0
        }
      }
    }
    for (ic_chunk.outer: int32, 0, 32) {
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 3) "unroll" {
        attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 4;
        attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 2;
        attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
        pad_data.shared[ramp(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*32)) + (threadIdx.y_1*16)) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((1 <= ((floordiv(blockIdx.x, 7)*14) + floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*32) + (threadIdx.z_1*8)) + (threadIdx.y_1*4)) + threadIdx.x_1), 6))) && (((floordiv(blockIdx.x, 7)*14) + floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*32) + (threadIdx.z_1*8)) + (threadIdx.y_1*4)) + threadIdx.x_1), 6)) < 29)) && (1 <= ((floormod(blockIdx.x, 7)*4) + floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*32) + (threadIdx.z_1*8)) + (threadIdx.y_1*4)) + threadIdx.x_1), 6)))) && (((floormod(blockIdx.x, 7)*4) + floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*32) + (threadIdx.z_1*8)) + (threadIdx.y_1*4)) + threadIdx.x_1), 6)) < 29)), (int8x4*)placeholder_11[ramp((((((((blockIdx.z*100352) + (ic_chunk.outer*3136)) + (floordiv(blockIdx.x, 7)*1568)) + (floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*32) + (threadIdx.z_1*8)) + (threadIdx.y_1*4)) + threadIdx.x_1), 6)*112)) + (floormod(blockIdx.x, 7)*16)) + (floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*32) + (threadIdx.z_1*8)) + (threadIdx.y_1*4)) + threadIdx.x_1), 6)*4)) - 116), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
      }
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 9) "unroll" {
        attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 4;
        attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 2;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
        placeholder.shared[ramp(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*128) + (threadIdx.z_2*32)) + (threadIdx.y_2*16)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_9[ramp((((((blockIdx.y*36864) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*8) + (threadIdx.z_2*2)) + threadIdx.y_2), 9)*4608)) + (ic_chunk.outer*144)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*8) + (threadIdx.z_2*2)) + threadIdx.y_2), 9)*16)) + (threadIdx.x_2*4)), 1, 4)]
      }
      for (kw.inner: int32, 0, 3) "unroll" {
        for (kh.inner: int32, 0, 3) "unroll" {
          for (oc_chunk: int32, 0, 2) "unroll" {
            for (oh: int32, 0, 7) "unroll" {
              for (oc_block: int32, 0, 4) "unroll" {
                compute[(((oc_chunk*28) + (oh*4)) + oc_block)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((threadIdx.y*168) + (oh*24)) + (kh.inner*24)) + (threadIdx.x*4)) + (kw.inner*4)), 1, 4)], (int8x4*)placeholder.shared[ramp((((((threadIdx.z*288) + (oc_chunk*144)) + (kh.inner*48)) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(((oc_chunk*28) + (oh*4)) + oc_block)], dtype=int32)
              }
            }
          }
        }
      }
    }
    for (ax1.inner.inner.inner: int32, 0, 2) "unroll" {
      for (ax2.inner.inner.inner: int32, 0, 7) "unroll" {
        for (ax4: int32, 0, 4) "unroll" {
          T_relu_2[((((((((((blockIdx.z*100352) + (blockIdx.y*25088)) + (threadIdx.z*6272)) + (ax1.inner.inner.inner*3136)) + (floordiv(blockIdx.x, 7)*1568)) + (threadIdx.y*784)) + (ax2.inner.inner.inner*112)) + (floormod(blockIdx.x, 7)*16)) + (threadIdx.x*4)) + ax4)] = max((@tir.q_multiply_shift((int32*)placeholder_10[((((((((((blockIdx.z*100352) + (blockIdx.y*25088)) + (threadIdx.z*6272)) + (ax1.inner.inner.inner*3136)) + (floordiv(blockIdx.x, 7)*1568)) + (threadIdx.y*784)) + (ax2.inner.inner.inner*112)) + (floormod(blockIdx.x, 7)*16)) + (threadIdx.x*4)) + ax4)], 1730082555, 31, 0, dtype=int32) + @tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[(((ax1.inner.inner.inner*28) + (ax2.inner.inner.inner*4)) + ax4)], 1219446002, 31, 17, dtype=int32) + (int32*)placeholder_8[((((blockIdx.y*32) + (threadIdx.z*8)) + (ax1.inner.inner.inner*4)) + ax4)]), 2074804792, 31, 0, dtype=int32)), 0)
        }
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_relu_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_fixed_point_multiply_add_cast_13255070459903635369__2", "tir.noalias": True}
  buffers = {T_relu: Buffer(T_relu_2: handle, int32, [32, 32, 28, 28, 4], []),
             placeholder_3: Buffer(placeholder_8: handle, int32, [1, 32, 1, 1, 4], []),
             placeholder_2: Buffer(placeholder_9: handle, int8, [32, 16, 1, 1, 4, 4], []),
             placeholder: Buffer(placeholder_10: handle, int8, [32, 16, 56, 56, 4], []),
             placeholder_1: Buffer(placeholder_11: handle, int32, [32, 32, 28, 28, 4], [])}
  buffer_map = {placeholder_4: placeholder, placeholder_7: placeholder_1, placeholder_5: placeholder_2, placeholder_6: placeholder_3, T_relu_1: T_relu} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 16;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [8]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [440]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [128]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 4;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 28;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 8;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 1;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28 {
    for (n.init: int32, 0, 2) "unroll" {
      for (oc_block.init: int32, 0, 4) "unroll" {
        compute[((n.init*4) + oc_block.init)] = 0
      }
    }
    for (ic_chunk.outer: int32, 0, 4) "unroll" {
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 2) "unroll" {
        attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 8;
        attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 1;
        attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*224) + (threadIdx.z_1*28)) + threadIdx.x_1) < 440) {
          pad_data.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*896) + (threadIdx.z_1*112)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_10[ramp(((((((blockIdx.z*401408) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*224) + (threadIdx.z_1*28)) + threadIdx.x_1), 220)*200704)) + (ic_chunk.outer*50176)) + (floordiv(floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*224) + (threadIdx.z_1*28)) + threadIdx.x_1), 220), 55)*12544)) + (blockIdx.x*448)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*224) + (threadIdx.z_1*28)) + threadIdx.x_1), 55)*4)), 1, 4)]
        }
      }
      attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 8;
      attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 1;
      attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 28;
      if (((threadIdx.z_2*7) + floordiv(threadIdx.x_2, 4)) < 32) {
        if (((threadIdx.z_2*28) + threadIdx.x_2) < 128) {
          if (threadIdx.z_2 < 5) {
            placeholder.shared[ramp(((threadIdx.z_2*112) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_9[ramp((((((blockIdx.y*2048) + (floordiv(((threadIdx.z_2*7) + floordiv(threadIdx.x_2, 4)), 4)*256)) + (ic_chunk.outer*64)) + (floormod(((threadIdx.z_2*7) + floordiv(threadIdx.x_2, 4)), 4)*16)) + (floormod(threadIdx.x_2, 4)*4)), 1, 4)]
          }
        }
      }
      for (ic_chunk.inner: int32, 0, 4) "unroll" {
        for (n: int32, 0, 2) "unroll" {
          for (oc_block: int32, 0, 4) "unroll" {
            compute[((n*4) + oc_block)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((n*880) + (ic_chunk.inner*220)) + (threadIdx.x*8)), 1, 4)], (int8x4*)placeholder.shared[ramp((((threadIdx.z*64) + (ic_chunk.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[((n*4) + oc_block)], dtype=int32)
          }
        }
      }
    }
    for (ax0.inner.inner.inner.inner: int32, 0, 2) "unroll" {
      for (ax4: int32, 0, 4) "unroll" {
        T_relu_2[(((((((blockIdx.z*200704) + (ax0.inner.inner.inner.inner*100352)) + (blockIdx.y*25088)) + (threadIdx.z*3136)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4)] = max((@tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[((ax0.inner.inner.inner.inner*4) + ax4)], 1608224298, 31, 18, dtype=int32) + (int32*)placeholder_8[(((blockIdx.y*32) + (threadIdx.z*4)) + ax4)]), 1462212557, 31, 0, dtype=int32) + (int32*)placeholder_11[(((((((blockIdx.z*200704) + (ax0.inner.inner.inner.inner*100352)) + (blockIdx.y*25088)) + (threadIdx.z*3136)) + (blockIdx.x*112)) + (threadIdx.x*4)) + ax4)]), 0)
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_fixed_point_multiply_clip_cast_2", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [32, 16, 56, 56, 4], []),
             placeholder: Buffer(placeholder_2: handle, int32, [32, 16, 56, 56, 4], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer: int32, 0, 25) {
    if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*65536) + (blockIdx.x*256)) + floordiv(threadIdx.x, 4)) < 1605632) {
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x) < 6422528) {
        T_cast_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = cast(int8, max(min(@tir.q_multiply_shift((int32*)placeholder_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)], 1763041040, 31, -24, dtype=int32), 127), -128))
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_relu_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_fixed_point_multiply_nn_conv2d_cast_fixed_point_multiply_add_cast_fix_1476761249106760241__2", "tir.noalias": True}
  buffers = {placeholder_3: Buffer(placeholder_8: handle, int8, [32, 16, 56, 56, 4], []),
             placeholder_2: Buffer(placeholder_9: handle, int32, [1, 16, 1, 1, 4], []),
             T_relu: Buffer(T_relu_2: handle, int32, [32, 16, 56, 56, 4], []),
             placeholder: Buffer(placeholder_10: handle, int32, [32, 16, 56, 56, 4], []),
             placeholder_1: Buffer(placeholder_11: handle, int8, [16, 16, 3, 3, 4, 4], [])}
  buffer_map = {placeholder_4: placeholder, placeholder_6: placeholder_1, T_relu_1: T_relu, placeholder_7: placeholder_2, placeholder_5: placeholder_3} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 32;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [32]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [200]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [576]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 1;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 49;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8 {
    for (oh.init: int32, 0, 8) "unroll" {
      for (oc_block.init: int32, 0, 4) "unroll" {
        compute[((oh.init*4) + oc_block.init)] = 0
      }
    }
    attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
    attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
    attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8;
    if (((threadIdx.y_1*8) + threadIdx.x_1) < 100) {
      if (threadIdx.y_1 < 13) {
        pad_data.shared[ramp(((threadIdx.y_1*32) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((1 <= ((floordiv(blockIdx.x, 7)*8) + floordiv(((threadIdx.y_1*8) + threadIdx.x_1), 10))) && (((floordiv(blockIdx.x, 7)*8) + floordiv(((threadIdx.y_1*8) + threadIdx.x_1), 10)) < 57)) && (1 <= ((floormod(blockIdx.x, 7)*8) + floormod(((threadIdx.y_1*8) + threadIdx.x_1), 10)))) && (((floormod(blockIdx.x, 7)*8) + floormod(((threadIdx.y_1*8) + threadIdx.x_1), 10)) < 57)), (int8x4*)placeholder_8[ramp(((((((blockIdx.z*200704) + (floordiv(blockIdx.x, 7)*1792)) + (floordiv(((threadIdx.y_1*8) + threadIdx.x_1), 10)*224)) + (floormod(blockIdx.x, 7)*32)) + (floormod(((threadIdx.y_1*8) + threadIdx.x_1), 10)*4)) - 228), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
      }
    }
    for (ic_chunk.outer.outer: int32, 0, 15) {
      attr [pad_data.shared] "double_buffer_write" = 1;
      attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
      attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8;
      if (((threadIdx.y_1*8) + threadIdx.x_1) < 100) {
        if (threadIdx.y_1 < 13) {
          pad_data.shared[ramp((((floormod((ic_chunk.outer.outer + 1), 2)*400) + (threadIdx.y_1*32)) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((1 <= ((floordiv(blockIdx.x, 7)*8) + floordiv(((threadIdx.y_1*8) + threadIdx.x_1), 10))) && (((floordiv(blockIdx.x, 7)*8) + floordiv(((threadIdx.y_1*8) + threadIdx.x_1), 10)) < 57)) && (1 <= ((floormod(blockIdx.x, 7)*8) + floormod(((threadIdx.y_1*8) + threadIdx.x_1), 10)))) && (((floormod(blockIdx.x, 7)*8) + floormod(((threadIdx.y_1*8) + threadIdx.x_1), 10)) < 57)), (int8x4*)placeholder_8[ramp((((((((blockIdx.z*200704) + (ic_chunk.outer.outer*12544)) + (floordiv(blockIdx.x, 7)*1792)) + (floordiv(((threadIdx.y_1*8) + threadIdx.x_1), 10)*224)) + (floormod(blockIdx.x, 7)*32)) + (floormod(((threadIdx.y_1*8) + threadIdx.x_1), 10)*4)) + 12316), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
        }
      }
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 5) "unroll" {
        attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.y_2*2)) + floordiv(threadIdx.x_2, 4)) < 144) {
          if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*128) + (threadIdx.y_2*8)) + threadIdx.x_2) < 576) {
            if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*16) + threadIdx.y_2) < 72) {
              placeholder.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*512) + (threadIdx.y_2*32)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_11[ramp(((((floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.y_2*2)) + floordiv(threadIdx.x_2, 4)), 9)*2304) + (ic_chunk.outer.outer*144)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.y_2*2)) + floordiv(threadIdx.x_2, 4)), 9)*16)) + (floormod(threadIdx.x_2, 4)*4)), 1, 4)]
            }
          }
        }
      }
      for (kw.inner: int32, 0, 3) "unroll" {
        for (kh.inner: int32, 0, 3) "unroll" {
          for (oh: int32, 0, 8) "unroll" {
            for (oc_block: int32, 0, 4) "unroll" {
              compute[((oh*4) + oc_block)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*400) + (oh*40)) + (kh.inner*40)) + (threadIdx.x*4)) + (kw.inner*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*144) + (kh.inner*48)) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[((oh*4) + oc_block)], dtype=int32)
            }
          }
        }
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 5) "unroll" {
      attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
      attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8;
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.y_2*2)) + floordiv(threadIdx.x_2, 4)) < 144) {
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*128) + (threadIdx.y_2*8)) + threadIdx.x_2) < 576) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*16) + threadIdx.y_2) < 72) {
            placeholder.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*512) + (threadIdx.y_2*32)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_11[ramp(((((floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.y_2*2)) + floordiv(threadIdx.x_2, 4)), 9)*2304) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.y_2*2)) + floordiv(threadIdx.x_2, 4)), 9)*16)) + (floormod(threadIdx.x_2, 4)*4)) + 2160), 1, 4)]
          }
        }
      }
    }
    for (kw.inner_1: int32, 0, 3) "unroll" {
      for (kh.inner_1: int32, 0, 3) "unroll" {
        for (oh_1: int32, 0, 8) "unroll" {
          for (oc_block_1: int32, 0, 4) "unroll" {
            compute[((oh_1*4) + oc_block_1)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((oh_1*40) + (kh.inner_1*40)) + (threadIdx.x*4)) + (kw.inner_1*4)) + 400), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*144) + (kh.inner_1*48)) + (kw.inner_1*16)) + (oc_block_1*4)), 1, 4)], (int32*)compute[((oh_1*4) + oc_block_1)], dtype=int32)
          }
        }
      }
    }
    for (ax2.inner.inner.inner: int32, 0, 8) "unroll" {
      for (ax4: int32, 0, 4) "unroll" {
        T_relu_2[(((((((blockIdx.z*200704) + (threadIdx.y*12544)) + (floordiv(blockIdx.x, 7)*1792)) + (ax2.inner.inner.inner*224)) + (floormod(blockIdx.x, 7)*32)) + (threadIdx.x*4)) + ax4)] = max((@tir.q_multiply_shift((int32*)placeholder_10[(((((((blockIdx.z*200704) + (threadIdx.y*12544)) + (floordiv(blockIdx.x, 7)*1792)) + (ax2.inner.inner.inner*224)) + (floormod(blockIdx.x, 7)*32)) + (threadIdx.x*4)) + ax4)], 1972011630, 31, 1, dtype=int32) + @tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[((ax2.inner.inner.inner*4) + ax4)], 2071811799, 31, 16, dtype=int32) + (int32*)placeholder_9[((threadIdx.y*4) + ax4)]), 2128621749, 31, 0, dtype=int32)), 0)
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_relu_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_fixed_point_multiply_nn_conv2d_cast_fixed_point_multiply_add_cast_fix_1476761249106760241__3", "tir.noalias": True}
  buffers = {placeholder_3: Buffer(placeholder_8: handle, int32, [1, 16, 1, 1, 4], []),
             T_relu: Buffer(T_relu_2: handle, int32, [32, 16, 56, 56, 4], []),
             placeholder_2: Buffer(placeholder_9: handle, int8, [32, 16, 56, 56, 4], []),
             placeholder: Buffer(placeholder_10: handle, int32, [32, 16, 56, 56, 4], []),
             placeholder_1: Buffer(placeholder_11: handle, int8, [16, 16, 3, 3, 4, 4], [])}
  buffer_map = {placeholder_4: placeholder, placeholder_6: placeholder_1, placeholder_5: placeholder_2, T_relu_1: T_relu, placeholder_7: placeholder_3} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 32;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [32]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [200]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [576]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 1;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 49;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8 {
    for (oh.init: int32, 0, 8) "unroll" {
      for (oc_block.init: int32, 0, 4) "unroll" {
        compute[((oh.init*4) + oc_block.init)] = 0
      }
    }
    attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
    attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
    attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8;
    if (((threadIdx.y_1*8) + threadIdx.x_1) < 100) {
      if (threadIdx.y_1 < 13) {
        pad_data.shared[ramp(((threadIdx.y_1*32) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((1 <= ((floordiv(blockIdx.x, 7)*8) + floordiv(((threadIdx.y_1*8) + threadIdx.x_1), 10))) && (((floordiv(blockIdx.x, 7)*8) + floordiv(((threadIdx.y_1*8) + threadIdx.x_1), 10)) < 57)) && (1 <= ((floormod(blockIdx.x, 7)*8) + floormod(((threadIdx.y_1*8) + threadIdx.x_1), 10)))) && (((floormod(blockIdx.x, 7)*8) + floormod(((threadIdx.y_1*8) + threadIdx.x_1), 10)) < 57)), (int8x4*)placeholder_9[ramp(((((((blockIdx.z*200704) + (floordiv(blockIdx.x, 7)*1792)) + (floordiv(((threadIdx.y_1*8) + threadIdx.x_1), 10)*224)) + (floormod(blockIdx.x, 7)*32)) + (floormod(((threadIdx.y_1*8) + threadIdx.x_1), 10)*4)) - 228), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
      }
    }
    for (ic_chunk.outer.outer: int32, 0, 15) {
      attr [pad_data.shared] "double_buffer_write" = 1;
      attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
      attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8;
      if (((threadIdx.y_1*8) + threadIdx.x_1) < 100) {
        if (threadIdx.y_1 < 13) {
          pad_data.shared[ramp((((floormod((ic_chunk.outer.outer + 1), 2)*400) + (threadIdx.y_1*32)) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((1 <= ((floordiv(blockIdx.x, 7)*8) + floordiv(((threadIdx.y_1*8) + threadIdx.x_1), 10))) && (((floordiv(blockIdx.x, 7)*8) + floordiv(((threadIdx.y_1*8) + threadIdx.x_1), 10)) < 57)) && (1 <= ((floormod(blockIdx.x, 7)*8) + floormod(((threadIdx.y_1*8) + threadIdx.x_1), 10)))) && (((floormod(blockIdx.x, 7)*8) + floormod(((threadIdx.y_1*8) + threadIdx.x_1), 10)) < 57)), (int8x4*)placeholder_9[ramp((((((((blockIdx.z*200704) + (ic_chunk.outer.outer*12544)) + (floordiv(blockIdx.x, 7)*1792)) + (floordiv(((threadIdx.y_1*8) + threadIdx.x_1), 10)*224)) + (floormod(blockIdx.x, 7)*32)) + (floormod(((threadIdx.y_1*8) + threadIdx.x_1), 10)*4)) + 12316), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
        }
      }
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 5) "unroll" {
        attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.y_2*2)) + floordiv(threadIdx.x_2, 4)) < 144) {
          if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*128) + (threadIdx.y_2*8)) + threadIdx.x_2) < 576) {
            if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*16) + threadIdx.y_2) < 72) {
              placeholder.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*512) + (threadIdx.y_2*32)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_11[ramp(((((floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.y_2*2)) + floordiv(threadIdx.x_2, 4)), 9)*2304) + (ic_chunk.outer.outer*144)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.y_2*2)) + floordiv(threadIdx.x_2, 4)), 9)*16)) + (floormod(threadIdx.x_2, 4)*4)), 1, 4)]
            }
          }
        }
      }
      for (kw.inner: int32, 0, 3) "unroll" {
        for (kh.inner: int32, 0, 3) "unroll" {
          for (oh: int32, 0, 8) "unroll" {
            for (oc_block: int32, 0, 4) "unroll" {
              compute[((oh*4) + oc_block)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*400) + (oh*40)) + (kh.inner*40)) + (threadIdx.x*4)) + (kw.inner*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*144) + (kh.inner*48)) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[((oh*4) + oc_block)], dtype=int32)
            }
          }
        }
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 5) "unroll" {
      attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
      attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8;
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.y_2*2)) + floordiv(threadIdx.x_2, 4)) < 144) {
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*128) + (threadIdx.y_2*8)) + threadIdx.x_2) < 576) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*16) + threadIdx.y_2) < 72) {
            placeholder.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*512) + (threadIdx.y_2*32)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_11[ramp(((((floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.y_2*2)) + floordiv(threadIdx.x_2, 4)), 9)*2304) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.y_2*2)) + floordiv(threadIdx.x_2, 4)), 9)*16)) + (floormod(threadIdx.x_2, 4)*4)) + 2160), 1, 4)]
          }
        }
      }
    }
    for (kw.inner_1: int32, 0, 3) "unroll" {
      for (kh.inner_1: int32, 0, 3) "unroll" {
        for (oh_1: int32, 0, 8) "unroll" {
          for (oc_block_1: int32, 0, 4) "unroll" {
            compute[((oh_1*4) + oc_block_1)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((oh_1*40) + (kh.inner_1*40)) + (threadIdx.x*4)) + (kw.inner_1*4)) + 400), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*144) + (kh.inner_1*48)) + (kw.inner_1*16)) + (oc_block_1*4)), 1, 4)], (int32*)compute[((oh_1*4) + oc_block_1)], dtype=int32)
          }
        }
      }
    }
    for (ax2.inner.inner.inner: int32, 0, 8) "unroll" {
      for (ax4: int32, 0, 4) "unroll" {
        T_relu_2[(((((((blockIdx.z*200704) + (threadIdx.y*12544)) + (floordiv(blockIdx.x, 7)*1792)) + (ax2.inner.inner.inner*224)) + (floormod(blockIdx.x, 7)*32)) + (threadIdx.x*4)) + ax4)] = max((@tir.q_multiply_shift((int32*)placeholder_10[(((((((blockIdx.z*200704) + (threadIdx.y*12544)) + (floordiv(blockIdx.x, 7)*1792)) + (ax2.inner.inner.inner*224)) + (floormod(blockIdx.x, 7)*32)) + (threadIdx.x*4)) + ax4)], 1807194190, 31, -1, dtype=int32) + @tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute[((ax2.inner.inner.inner*4) + ax4)], 1574726727, 31, 16, dtype=int32) + (int32*)placeholder_8[((threadIdx.y*4) + ax4)]), 1137624986, 31, 1, dtype=int32)), 0)
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation pool.cuda for op nn.max_pool2d
primfn(placeholder_1: handle, tensor_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_max_pool2d_1", "tir.noalias": True}
  buffers = {tensor: Buffer(tensor_2: handle, int32, [32, 16, 56, 56, 4], []),
             placeholder: Buffer(placeholder_2: handle, int32, [32, 16, 112, 112, 4], [])}
  buffer_map = {placeholder_1: placeholder, tensor_1: tensor} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 6272;
  attr [tensor.local: handle] "storage_scope" = "local";
  allocate(tensor.local, int32, [1]);
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
    tensor.local[0] = -2147483648
    for (rv: int32, 0, 3) {
      for (rv_1: int32, 0, 3) {
        tensor.local[0] = max((int32*)tensor.local[0], @tir.if_then_else(((1 <= ((floordiv(floormod(((blockIdx.x*256) + floordiv(threadIdx.x, 4)), 3136), 56)*2) + rv)) && (1 <= ((floormod(((blockIdx.x*256) + floordiv(threadIdx.x, 4)), 56)*2) + rv_1))), (int32*)placeholder_2[((((((floordiv(((blockIdx.x*256) + floordiv(threadIdx.x, 4)), 56)*896) + (rv*448)) + (floormod(((blockIdx.x*256) + floordiv(threadIdx.x, 4)), 56)*8)) + (rv_1*4)) + floormod(threadIdx.x, 4)) - 452)], -2147483648, dtype=int32))
      }
    }
    tensor_2[((blockIdx.x*1024) + threadIdx.x)] = (int32*)tensor.local[0]
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_nn_relu_cast_fixed_point_mult_6343854372805914660_", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [32, 16, 112, 112, 4], []),
             placeholder_2: Buffer(placeholder_6: handle, int32, [1, 16, 1, 1, 4], []),
             placeholder: Buffer(placeholder_7: handle, int8, [32, 1, 224, 224, 4], []),
             placeholder_1: Buffer(placeholder_8: handle, int8, [16, 1, 7, 7, 4, 4], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, compute_1: compute} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 4;
  attr [compute_3: handle] "storage_scope" = "local";
  allocate(compute_3, int32, [64]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [896]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [296]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 1;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 784;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 8;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 1;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 16 {
    for (n.init: int32, 0, 4) "unroll" {
      for (oc_chunk.init: int32, 0, 4) "unroll" {
        for (oc_block.init: int32, 0, 4) "unroll" {
          compute_3[(((n.init*16) + (oc_chunk.init*4)) + oc_block.init)] = 0
        }
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 4) "unroll" {
      attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 8;
      attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 1;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 16;
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.z_1*4)) + floordiv(threadIdx.x_1, 4)) < 112) {
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*16)) + threadIdx.x_1) < 448) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*8) + threadIdx.z_1) < 28) {
            placeholder.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*512) + (threadIdx.z_1*64)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_8[ramp((((floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.z_1*4)) + floordiv(threadIdx.x_1, 4)), 7)*784) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.z_1*4)) + floordiv(threadIdx.x_1, 4)), 7)*16)) + (floormod(threadIdx.x_1, 4)*4)), 1, 4)]
          }
        }
      }
    }
    for (kh.outer.outer: int32, 0, 6) {
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 3) "unroll" {
        attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 8;
        attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 1;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 16;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_2*16)) + threadIdx.x_2) < 296) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*8) + threadIdx.z_2) < 19) {
            pad_data.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*512) + (threadIdx.z_2*64)) + (threadIdx.x_2*4)), 1, 4)] = @tir.if_then_else(((((3 <= ((floordiv(blockIdx.x, 7)*2) + kh.outer.outer)) && (((floordiv(blockIdx.x, 7)*2) + kh.outer.outer) < 227)) && (3 <= ((floormod(blockIdx.x, 7)*32) + floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_2*16)) + threadIdx.x_2), 37)))) && (((floormod(blockIdx.x, 7)*32) + floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_2*16)) + threadIdx.x_2), 37)) < 227)), (int8x4*)placeholder_7[ramp((((((((blockIdx.z*1605632) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_2*16)) + threadIdx.x_2), 37)*200704)) + (floordiv(blockIdx.x, 7)*1792)) + (kh.outer.outer*896)) + (floormod(blockIdx.x, 7)*128)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_2*16)) + threadIdx.x_2), 37)*4)) - 2700), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
          }
        }
      }
      attr [placeholder.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 4) "unroll" {
        attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 8;
        attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 1;
        attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 16;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.z_1*4)) + floordiv(threadIdx.x_1, 4)) < 112) {
          if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_1*16)) + threadIdx.x_1) < 448) {
            if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*8) + threadIdx.z_1) < 28) {
              placeholder.shared[ramp(((((floormod((kh.outer.outer + 1), 2)*1792) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*512)) + (threadIdx.z_1*64)) + (threadIdx.x_1*4)), 1, 4)] = (int8x4*)placeholder_8[ramp((((((floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.z_1*4)) + floordiv(threadIdx.x_1, 4)), 7)*784) + (kh.outer.outer*112)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.z_1*4)) + floordiv(threadIdx.x_1, 4)), 7)*16)) + (floormod(threadIdx.x_1, 4)*4)) + 112), 1, 4)]
            }
          }
        }
      }
      for (kw.inner: int32, 0, 7) "unroll" {
        for (n: int32, 0, 4) "unroll" {
          for (oc_chunk: int32, 0, 4) "unroll" {
            for (oc_block: int32, 0, 4) "unroll" {
              compute_3[(((n*16) + (oc_chunk*4)) + oc_block)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floordiv(threadIdx.z, 4)*592) + (n*148)) + (threadIdx.x*8)) + (kw.inner*4)), 1, 4)], (int8x4*)placeholder.shared[ramp((((((floormod(kh.outer.outer, 2)*1792) + (floormod(threadIdx.z, 4)*448)) + (oc_chunk*112)) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute_3[(((n*16) + (oc_chunk*4)) + oc_block)], dtype=int32)
            }
          }
        }
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1: int32, 0, 3) "unroll" {
      attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 8;
      attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 1;
      attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 16;
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_2*16)) + threadIdx.x_2) < 296) {
        if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*8) + threadIdx.z_2) < 19) {
          pad_data.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*512) + (threadIdx.z_2*64)) + (threadIdx.x_2*4)), 1, 4)] = @tir.if_then_else((((blockIdx.x < 777) && (3 <= ((floormod(blockIdx.x, 7)*32) + floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_2*16)) + threadIdx.x_2), 37)))) && (((floormod(blockIdx.x, 7)*32) + floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_2*16)) + threadIdx.x_2), 37)) < 227)), (int8x4*)placeholder_7[ramp(((((((blockIdx.z*1605632) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_2*16)) + threadIdx.x_2), 37)*200704)) + (floordiv(blockIdx.x, 7)*1792)) + (floormod(blockIdx.x, 7)*128)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_2*16)) + threadIdx.x_2), 37)*4)) + 2676), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
        }
      }
    }
    for (kw.inner_1: int32, 0, 7) "unroll" {
      for (n_1: int32, 0, 4) "unroll" {
        for (oc_chunk_1: int32, 0, 4) "unroll" {
          for (oc_block_1: int32, 0, 4) "unroll" {
            compute_3[(((n_1*16) + (oc_chunk_1*4)) + oc_block_1)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((floordiv(threadIdx.z, 4)*592) + (n_1*148)) + (threadIdx.x*8)) + (kw.inner_1*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((floormod(threadIdx.z, 4)*448) + (oc_chunk_1*112)) + (kw.inner_1*16)) + (oc_block_1*4)), 1, 4)], (int32*)compute_3[(((n_1*16) + (oc_chunk_1*4)) + oc_block_1)], dtype=int32)
          }
        }
      }
    }
    for (i0.inner.inner.inner.inner: int32, 0, 4) "unroll" {
      for (i1.inner.inner.inner: int32, 0, 4) "unroll" {
        for (i4: int32, 0, 4) "unroll" {
          compute_2[((((((((blockIdx.z*6422528) + (floordiv(threadIdx.z, 4)*3211264)) + (i0.inner.inner.inner.inner*802816)) + (floormod(threadIdx.z, 4)*200704)) + (i1.inner.inner.inner*50176)) + (blockIdx.x*64)) + (threadIdx.x*4)) + i4)] = @tir.q_multiply_shift(max((@tir.q_multiply_shift((int32*)compute_3[(((i0.inner.inner.inner.inner*16) + (i1.inner.inner.inner*4)) + i4)], 1154272231, 31, 15, dtype=int32) + (int32*)placeholder_6[(((floormod(threadIdx.z, 4)*16) + (i1.inner.inner.inner*4)) + i4)]), 0), 2107679426, 31, 0, dtype=int32)
        }
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cuda for op divide
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op round
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.pad
INFO:compile_engine:Use implementation injective.cuda for op layout_transform
primfn(placeholder_1: handle, T_layout_trans_1: handle) -> ()
  attr = {"global_symbol": "fused_divide_add_round_cast_clip_cast_nn_pad_layout_transform", "tir.noalias": True}
  buffers = {T_layout_trans: Buffer(T_layout_trans_2: handle, int8, [32, 1, 224, 224, 4], []),
             placeholder: Buffer(placeholder_2: handle, float32, [32, 3, 224, 224], [])}
  buffer_map = {placeholder_1: placeholder, T_layout_trans_1: T_layout_trans} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer: int32, 0, 25) {
    if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*65536) + (blockIdx.x*256)) + floordiv(threadIdx.x, 4)) < 1605632) {
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x) < 6422528) {
        T_layout_trans_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = @tir.if_then_else((floormod(threadIdx.x, 4) < 3), cast(int8, max(min(cast(int32, @tir.round(((float32*)placeholder_2[(((floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*65536) + (blockIdx.x*256)) + floordiv(threadIdx.x, 4)), 50176)*150528) + (floormod(threadIdx.x, 4)*50176)) + floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*65536) + (blockIdx.x*256)) + floordiv(threadIdx.x, 4)), 50176))]*48.6161f32), dtype=float32)), 127), -128)), 0i8, dtype=int8)
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_nn_relu_cast_fixed_point_mult_18399029763786111876_", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [32, 16, 56, 56, 4], []),
             placeholder_2: Buffer(placeholder_6: handle, int32, [1, 16, 1, 1, 4], []),
             placeholder: Buffer(placeholder_7: handle, int8, [32, 16, 56, 56, 4], []),
             placeholder_1: Buffer(placeholder_8: handle, int8, [16, 16, 3, 3, 4, 4], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 32;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [32]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [200]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [576]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 1;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 49;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8 {
    for (oh.init: int32, 0, 8) "unroll" {
      for (oc_block.init: int32, 0, 4) "unroll" {
        compute[((oh.init*4) + oc_block.init)] = 0
      }
    }
    attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
    attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
    attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8;
    if (((threadIdx.y_1*8) + threadIdx.x_1) < 100) {
      if (threadIdx.y_1 < 13) {
        pad_data.shared[ramp(((threadIdx.y_1*32) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((1 <= ((floordiv(blockIdx.x, 7)*8) + floordiv(((threadIdx.y_1*8) + threadIdx.x_1), 10))) && (((floordiv(blockIdx.x, 7)*8) + floordiv(((threadIdx.y_1*8) + threadIdx.x_1), 10)) < 57)) && (1 <= ((floormod(blockIdx.x, 7)*8) + floormod(((threadIdx.y_1*8) + threadIdx.x_1), 10)))) && (((floormod(blockIdx.x, 7)*8) + floormod(((threadIdx.y_1*8) + threadIdx.x_1), 10)) < 57)), (int8x4*)placeholder_7[ramp(((((((blockIdx.z*200704) + (floordiv(blockIdx.x, 7)*1792)) + (floordiv(((threadIdx.y_1*8) + threadIdx.x_1), 10)*224)) + (floormod(blockIdx.x, 7)*32)) + (floormod(((threadIdx.y_1*8) + threadIdx.x_1), 10)*4)) - 228), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
      }
    }
    for (ic_chunk.outer.outer: int32, 0, 15) {
      attr [pad_data.shared] "double_buffer_write" = 1;
      attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
      attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8;
      if (((threadIdx.y_1*8) + threadIdx.x_1) < 100) {
        if (threadIdx.y_1 < 13) {
          pad_data.shared[ramp((((floormod((ic_chunk.outer.outer + 1), 2)*400) + (threadIdx.y_1*32)) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((1 <= ((floordiv(blockIdx.x, 7)*8) + floordiv(((threadIdx.y_1*8) + threadIdx.x_1), 10))) && (((floordiv(blockIdx.x, 7)*8) + floordiv(((threadIdx.y_1*8) + threadIdx.x_1), 10)) < 57)) && (1 <= ((floormod(blockIdx.x, 7)*8) + floormod(((threadIdx.y_1*8) + threadIdx.x_1), 10)))) && (((floormod(blockIdx.x, 7)*8) + floormod(((threadIdx.y_1*8) + threadIdx.x_1), 10)) < 57)), (int8x4*)placeholder_7[ramp((((((((blockIdx.z*200704) + (ic_chunk.outer.outer*12544)) + (floordiv(blockIdx.x, 7)*1792)) + (floordiv(((threadIdx.y_1*8) + threadIdx.x_1), 10)*224)) + (floormod(blockIdx.x, 7)*32)) + (floormod(((threadIdx.y_1*8) + threadIdx.x_1), 10)*4)) + 12316), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
        }
      }
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 5) "unroll" {
        attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.y_2*2)) + floordiv(threadIdx.x_2, 4)) < 144) {
          if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*128) + (threadIdx.y_2*8)) + threadIdx.x_2) < 576) {
            if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*16) + threadIdx.y_2) < 72) {
              placeholder.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*512) + (threadIdx.y_2*32)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp(((((floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.y_2*2)) + floordiv(threadIdx.x_2, 4)), 9)*2304) + (ic_chunk.outer.outer*144)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.y_2*2)) + floordiv(threadIdx.x_2, 4)), 9)*16)) + (floormod(threadIdx.x_2, 4)*4)), 1, 4)]
            }
          }
        }
      }
      for (kw.inner: int32, 0, 3) "unroll" {
        for (kh.inner: int32, 0, 3) "unroll" {
          for (oh: int32, 0, 8) "unroll" {
            for (oc_block: int32, 0, 4) "unroll" {
              compute[((oh*4) + oc_block)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*400) + (oh*40)) + (kh.inner*40)) + (threadIdx.x*4)) + (kw.inner*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*144) + (kh.inner*48)) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[((oh*4) + oc_block)], dtype=int32)
            }
          }
        }
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 5) "unroll" {
      attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
      attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8;
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.y_2*2)) + floordiv(threadIdx.x_2, 4)) < 144) {
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*128) + (threadIdx.y_2*8)) + threadIdx.x_2) < 576) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*16) + threadIdx.y_2) < 72) {
            placeholder.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*512) + (threadIdx.y_2*32)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp(((((floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.y_2*2)) + floordiv(threadIdx.x_2, 4)), 9)*2304) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.y_2*2)) + floordiv(threadIdx.x_2, 4)), 9)*16)) + (floormod(threadIdx.x_2, 4)*4)) + 2160), 1, 4)]
          }
        }
      }
    }
    for (kw.inner_1: int32, 0, 3) "unroll" {
      for (kh.inner_1: int32, 0, 3) "unroll" {
        for (oh_1: int32, 0, 8) "unroll" {
          for (oc_block_1: int32, 0, 4) "unroll" {
            compute[((oh_1*4) + oc_block_1)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((oh_1*40) + (kh.inner_1*40)) + (threadIdx.x*4)) + (kw.inner_1*4)) + 400), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*144) + (kh.inner_1*48)) + (kw.inner_1*16)) + (oc_block_1*4)), 1, 4)], (int32*)compute[((oh_1*4) + oc_block_1)], dtype=int32)
          }
        }
      }
    }
    for (ax2.inner.inner.inner: int32, 0, 8) "unroll" {
      for (ax4: int32, 0, 4) "unroll" {
        T_cast_2[(((((((blockIdx.z*200704) + (threadIdx.y*12544)) + (floordiv(blockIdx.x, 7)*1792)) + (ax2.inner.inner.inner*224)) + (floormod(blockIdx.x, 7)*32)) + (threadIdx.x*4)) + ax4)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((int32*)compute[((ax2.inner.inner.inner*4) + ax4)], 1090324072, 31, 16, dtype=int32) + (int32*)placeholder_6[((threadIdx.y*4) + ax4)]), 0), 1346499769, 31, -22, dtype=int32), 127), -128))
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op right_shift
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_add_right_shift_clip_cast", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [32, 16, 56, 56, 4], []),
             placeholder: Buffer(placeholder_2: handle, int32, [32, 16, 56, 56, 4], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer: int32, 0, 25) {
    if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*65536) + (blockIdx.x*256)) + floordiv(threadIdx.x, 4)) < 1605632) {
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x) < 6422528) {
        T_cast_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = cast(int8, min(@tir.shift_right(((int32*)placeholder_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] + 8388608), 24, dtype=int32), 127))
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_nn_relu_cast_fixed_point_mult_18399029763786111876__1", "tir.noalias": True}
  buffers = {placeholder_2: Buffer(placeholder_6: handle, int32, [1, 16, 1, 1, 4], []),
             T_cast: Buffer(T_cast_2: handle, int8, [32, 16, 56, 56, 4], []),
             placeholder: Buffer(placeholder_7: handle, int8, [32, 16, 56, 56, 4], []),
             placeholder_1: Buffer(placeholder_8: handle, int8, [16, 16, 3, 3, 4, 4], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 32;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [32]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [200]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [576]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 1;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 49;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8 {
    for (oh.init: int32, 0, 8) "unroll" {
      for (oc_block.init: int32, 0, 4) "unroll" {
        compute[((oh.init*4) + oc_block.init)] = 0
      }
    }
    attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
    attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
    attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8;
    if (((threadIdx.y_1*8) + threadIdx.x_1) < 100) {
      if (threadIdx.y_1 < 13) {
        pad_data.shared[ramp(((threadIdx.y_1*32) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((1 <= ((floordiv(blockIdx.x, 7)*8) + floordiv(((threadIdx.y_1*8) + threadIdx.x_1), 10))) && (((floordiv(blockIdx.x, 7)*8) + floordiv(((threadIdx.y_1*8) + threadIdx.x_1), 10)) < 57)) && (1 <= ((floormod(blockIdx.x, 7)*8) + floormod(((threadIdx.y_1*8) + threadIdx.x_1), 10)))) && (((floormod(blockIdx.x, 7)*8) + floormod(((threadIdx.y_1*8) + threadIdx.x_1), 10)) < 57)), (int8x4*)placeholder_7[ramp(((((((blockIdx.z*200704) + (floordiv(blockIdx.x, 7)*1792)) + (floordiv(((threadIdx.y_1*8) + threadIdx.x_1), 10)*224)) + (floormod(blockIdx.x, 7)*32)) + (floormod(((threadIdx.y_1*8) + threadIdx.x_1), 10)*4)) - 228), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
      }
    }
    for (ic_chunk.outer.outer: int32, 0, 15) {
      attr [pad_data.shared] "double_buffer_write" = 1;
      attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
      attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8;
      if (((threadIdx.y_1*8) + threadIdx.x_1) < 100) {
        if (threadIdx.y_1 < 13) {
          pad_data.shared[ramp((((floormod((ic_chunk.outer.outer + 1), 2)*400) + (threadIdx.y_1*32)) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((1 <= ((floordiv(blockIdx.x, 7)*8) + floordiv(((threadIdx.y_1*8) + threadIdx.x_1), 10))) && (((floordiv(blockIdx.x, 7)*8) + floordiv(((threadIdx.y_1*8) + threadIdx.x_1), 10)) < 57)) && (1 <= ((floormod(blockIdx.x, 7)*8) + floormod(((threadIdx.y_1*8) + threadIdx.x_1), 10)))) && (((floormod(blockIdx.x, 7)*8) + floormod(((threadIdx.y_1*8) + threadIdx.x_1), 10)) < 57)), (int8x4*)placeholder_7[ramp((((((((blockIdx.z*200704) + (ic_chunk.outer.outer*12544)) + (floordiv(blockIdx.x, 7)*1792)) + (floordiv(((threadIdx.y_1*8) + threadIdx.x_1), 10)*224)) + (floormod(blockIdx.x, 7)*32)) + (floormod(((threadIdx.y_1*8) + threadIdx.x_1), 10)*4)) + 12316), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
        }
      }
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 5) "unroll" {
        attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.y_2*2)) + floordiv(threadIdx.x_2, 4)) < 144) {
          if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*128) + (threadIdx.y_2*8)) + threadIdx.x_2) < 576) {
            if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*16) + threadIdx.y_2) < 72) {
              placeholder.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*512) + (threadIdx.y_2*32)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp(((((floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.y_2*2)) + floordiv(threadIdx.x_2, 4)), 9)*2304) + (ic_chunk.outer.outer*144)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.y_2*2)) + floordiv(threadIdx.x_2, 4)), 9)*16)) + (floormod(threadIdx.x_2, 4)*4)), 1, 4)]
            }
          }
        }
      }
      for (kw.inner: int32, 0, 3) "unroll" {
        for (kh.inner: int32, 0, 3) "unroll" {
          for (oh: int32, 0, 8) "unroll" {
            for (oc_block: int32, 0, 4) "unroll" {
              compute[((oh*4) + oc_block)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*400) + (oh*40)) + (kh.inner*40)) + (threadIdx.x*4)) + (kw.inner*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*144) + (kh.inner*48)) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[((oh*4) + oc_block)], dtype=int32)
            }
          }
        }
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 5) "unroll" {
      attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
      attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 8;
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.y_2*2)) + floordiv(threadIdx.x_2, 4)) < 144) {
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*128) + (threadIdx.y_2*8)) + threadIdx.x_2) < 576) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*16) + threadIdx.y_2) < 72) {
            placeholder.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*512) + (threadIdx.y_2*32)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp(((((floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.y_2*2)) + floordiv(threadIdx.x_2, 4)), 9)*2304) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.y_2*2)) + floordiv(threadIdx.x_2, 4)), 9)*16)) + (floormod(threadIdx.x_2, 4)*4)) + 2160), 1, 4)]
          }
        }
      }
    }
    for (kw.inner_1: int32, 0, 3) "unroll" {
      for (kh.inner_1: int32, 0, 3) "unroll" {
        for (oh_1: int32, 0, 8) "unroll" {
          for (oc_block_1: int32, 0, 4) "unroll" {
            compute[((oh_1*4) + oc_block_1)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((oh_1*40) + (kh.inner_1*40)) + (threadIdx.x*4)) + (kw.inner_1*4)) + 400), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*144) + (kh.inner_1*48)) + (kw.inner_1*16)) + (oc_block_1*4)), 1, 4)], (int32*)compute[((oh_1*4) + oc_block_1)], dtype=int32)
          }
        }
      }
    }
    for (ax2.inner.inner.inner: int32, 0, 8) "unroll" {
      for (ax4: int32, 0, 4) "unroll" {
        T_cast_2[(((((((blockIdx.z*200704) + (threadIdx.y*12544)) + (floordiv(blockIdx.x, 7)*1792)) + (ax2.inner.inner.inner*224)) + (floormod(blockIdx.x, 7)*32)) + (threadIdx.x*4)) + ax4)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((int32*)compute[((ax2.inner.inner.inner*4) + ax4)], 1194331400, 31, 16, dtype=int32) + (int32*)placeholder_6[((threadIdx.y*4) + ax4)]), 0), 2092595616, 31, -23, dtype=int32), 127), -128))
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_fixed_point_multiply_clip_cast_3", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [32, 16, 56, 56, 4], []),
             placeholder: Buffer(placeholder_2: handle, int32, [32, 16, 56, 56, 4], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer: int32, 0, 25) {
    if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*65536) + (blockIdx.x*256)) + floordiv(threadIdx.x, 4)) < 1605632) {
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x) < 6422528) {
        T_cast_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = cast(int8, max(min(@tir.q_multiply_shift((int32*)placeholder_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)], 1972011630, 31, -23, dtype=int32), 127), -128))
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_fixed_point_multiply", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [32, 32, 28, 28, 4], []),
             placeholder_2: Buffer(placeholder_6: handle, int32, [1, 32, 1, 1, 4], []),
             placeholder: Buffer(placeholder_7: handle, int8, [32, 32, 28, 28, 4], []),
             placeholder_1: Buffer(placeholder_8: handle, int8, [32, 32, 3, 3, 4, 4], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, compute_1: compute} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 32;
  attr [compute_3: handle] "storage_scope" = "local";
  allocate(compute_3, int32, [56]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [96]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [288]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 4;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 14;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 4;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 2;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4 {
    for (oc_chunk.init: int32, 0, 2) "unroll" {
      for (oh.init: int32, 0, 7) "unroll" {
        for (oc_block.init: int32, 0, 4) "unroll" {
          compute_3[(((oc_chunk.init*28) + (oh.init*4)) + oc_block.init)] = 0
        }
      }
    }
    for (ic_chunk.outer: int32, 0, 32) {
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 3) "unroll" {
        attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 4;
        attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 2;
        attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
        pad_data.shared[ramp(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*32)) + (threadIdx.y_1*16)) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((1 <= ((floordiv(blockIdx.x, 7)*14) + floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*32) + (threadIdx.z_1*8)) + (threadIdx.y_1*4)) + threadIdx.x_1), 6))) && (((floordiv(blockIdx.x, 7)*14) + floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*32) + (threadIdx.z_1*8)) + (threadIdx.y_1*4)) + threadIdx.x_1), 6)) < 29)) && (1 <= ((floormod(blockIdx.x, 7)*4) + floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*32) + (threadIdx.z_1*8)) + (threadIdx.y_1*4)) + threadIdx.x_1), 6)))) && (((floormod(blockIdx.x, 7)*4) + floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*32) + (threadIdx.z_1*8)) + (threadIdx.y_1*4)) + threadIdx.x_1), 6)) < 29)), (int8x4*)placeholder_7[ramp((((((((blockIdx.z*100352) + (ic_chunk.outer*3136)) + (floordiv(blockIdx.x, 7)*1568)) + (floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*32) + (threadIdx.z_1*8)) + (threadIdx.y_1*4)) + threadIdx.x_1), 6)*112)) + (floormod(blockIdx.x, 7)*16)) + (floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*32) + (threadIdx.z_1*8)) + (threadIdx.y_1*4)) + threadIdx.x_1), 6)*4)) - 116), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
      }
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 9) "unroll" {
        attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 4;
        attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 2;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
        placeholder.shared[ramp(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*128) + (threadIdx.z_2*32)) + (threadIdx.y_2*16)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp((((((blockIdx.y*36864) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*8) + (threadIdx.z_2*2)) + threadIdx.y_2), 9)*4608)) + (ic_chunk.outer*144)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*8) + (threadIdx.z_2*2)) + threadIdx.y_2), 9)*16)) + (threadIdx.x_2*4)), 1, 4)]
      }
      for (kw.inner: int32, 0, 3) "unroll" {
        for (kh.inner: int32, 0, 3) "unroll" {
          for (oc_chunk: int32, 0, 2) "unroll" {
            for (oh: int32, 0, 7) "unroll" {
              for (oc_block: int32, 0, 4) "unroll" {
                compute_3[(((oc_chunk*28) + (oh*4)) + oc_block)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((threadIdx.y*168) + (oh*24)) + (kh.inner*24)) + (threadIdx.x*4)) + (kw.inner*4)), 1, 4)], (int8x4*)placeholder.shared[ramp((((((threadIdx.z*288) + (oc_chunk*144)) + (kh.inner*48)) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute_3[(((oc_chunk*28) + (oh*4)) + oc_block)], dtype=int32)
              }
            }
          }
        }
      }
    }
    for (i1.inner.inner.inner: int32, 0, 2) "unroll" {
      for (i2.inner.inner.inner: int32, 0, 7) "unroll" {
        for (i4: int32, 0, 4) "unroll" {
          compute_2[((((((((((blockIdx.z*100352) + (blockIdx.y*25088)) + (threadIdx.z*6272)) + (i1.inner.inner.inner*3136)) + (floordiv(blockIdx.x, 7)*1568)) + (threadIdx.y*784)) + (i2.inner.inner.inner*112)) + (floormod(blockIdx.x, 7)*16)) + (threadIdx.x*4)) + i4)] = @tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute_3[(((i1.inner.inner.inner*28) + (i2.inner.inner.inner*4)) + i4)], 2051410042, 31, 16, dtype=int32) + (int32*)placeholder_6[((((blockIdx.y*32) + (threadIdx.z*8)) + (i1.inner.inner.inner*4)) + i4)]), 1127693289, 31, 1, dtype=int32)
        }
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_nn_relu_cast_fixed_point_mult_18399029763786111876__2", "tir.noalias": True}
  buffers = {placeholder_2: Buffer(placeholder_6: handle, int32, [1, 32, 1, 1, 4], []),
             placeholder: Buffer(placeholder_7: handle, int8, [32, 16, 56, 56, 4], []),
             T_cast: Buffer(T_cast_2: handle, int8, [32, 32, 28, 28, 4], []),
             placeholder_1: Buffer(placeholder_8: handle, int8, [32, 16, 3, 3, 4, 4], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 16;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [32]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [580]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [2304]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 1;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 28;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 14 {
    for (n.init: int32, 0, 2) "unroll" {
      for (oc_chunk.init: int32, 0, 2) "unroll" {
        for (oh.init: int32, 0, 2) "unroll" {
          for (oc_block.init: int32, 0, 4) "unroll" {
            compute[((((n.init*16) + (oc_chunk.init*8)) + (oh.init*4)) + oc_block.init)] = 0
          }
        }
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 2) "unroll" {
      attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 14;
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*224) + (threadIdx.y_1*14)) + threadIdx.x_1) < 290) {
        if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*16) + threadIdx.y_1) < 21) {
          pad_data.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*896) + (threadIdx.y_1*56)) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((1 <= ((floordiv(blockIdx.x, 2)*4) + floordiv(floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*224) + (threadIdx.y_1*14)) + threadIdx.x_1), 145), 29))) && (1 <= ((floormod(blockIdx.x, 2)*28) + floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*224) + (threadIdx.y_1*14)) + threadIdx.x_1), 29)))), (int8x4*)placeholder_7[ramp((((((((blockIdx.z*401408) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*224) + (threadIdx.y_1*14)) + threadIdx.x_1), 145)*200704)) + (floordiv(blockIdx.x, 2)*896)) + (floordiv(floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*224) + (threadIdx.y_1*14)) + threadIdx.x_1), 145), 29)*224)) + (floormod(blockIdx.x, 2)*112)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*224) + (threadIdx.y_1*14)) + threadIdx.x_1), 29)*4)) - 228), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
        }
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 6) "unroll" {
      attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
      attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 14;
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*224) + (threadIdx.y_2*14)) + threadIdx.x_2) < 1152) {
        if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*16) + threadIdx.y_2) < 83) {
          placeholder.shared[ramp((((floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*224) + (threadIdx.y_2*14)) + threadIdx.x_2), 12)*48) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + floordiv(((threadIdx.y_2*14) + threadIdx.x_2), 4)), 3)*16)) + (floormod(((threadIdx.y_2*14) + threadIdx.x_2), 4)*4)), 1, 4)] = (int8x4*)placeholder_8[ramp(((((floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*224) + (threadIdx.y_2*14)) + threadIdx.x_2), 36)*2304) + (floordiv(floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*224) + (threadIdx.y_2*14)) + threadIdx.x_2), 36), 12)*48)) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + floordiv(((threadIdx.y_2*14) + threadIdx.x_2), 4)), 3)*16)) + (floormod(((threadIdx.y_2*14) + threadIdx.x_2), 4)*4)), 1, 4)]
        }
      }
    }
    for (ic_chunk.outer.outer: int32, 0, 15) {
      attr [pad_data.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1: int32, 0, 2) "unroll" {
        attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
        attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 14;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*224) + (threadIdx.y_1*14)) + threadIdx.x_1) < 290) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*16) + threadIdx.y_1) < 21) {
            pad_data.shared[ramp(((((floormod((ic_chunk.outer.outer + 1), 2)*1160) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*896)) + (threadIdx.y_1*56)) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((1 <= ((floordiv(blockIdx.x, 2)*4) + floordiv(floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*224) + (threadIdx.y_1*14)) + threadIdx.x_1), 145), 29))) && (1 <= ((floormod(blockIdx.x, 2)*28) + floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*224) + (threadIdx.y_1*14)) + threadIdx.x_1), 29)))), (int8x4*)placeholder_7[ramp(((((((((blockIdx.z*401408) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*224) + (threadIdx.y_1*14)) + threadIdx.x_1), 145)*200704)) + (ic_chunk.outer.outer*12544)) + (floordiv(blockIdx.x, 2)*896)) + (floordiv(floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*224) + (threadIdx.y_1*14)) + threadIdx.x_1), 145), 29)*224)) + (floormod(blockIdx.x, 2)*112)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*224) + (threadIdx.y_1*14)) + threadIdx.x_1), 29)*4)) + 12316), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
          }
        }
      }
      attr [placeholder.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 6) "unroll" {
        attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
        attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
        attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 14;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*224) + (threadIdx.y_2*14)) + threadIdx.x_2) < 1152) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*16) + threadIdx.y_2) < 83) {
            placeholder.shared[ramp(((((floormod((ic_chunk.outer.outer + 1), 2)*4608) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*224) + (threadIdx.y_2*14)) + threadIdx.x_2), 12)*48)) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + floordiv(((threadIdx.y_2*14) + threadIdx.x_2), 4)), 3)*16)) + (floormod(((threadIdx.y_2*14) + threadIdx.x_2), 4)*4)), 1, 4)] = (int8x4*)placeholder_8[ramp(((((((floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*224) + (threadIdx.y_2*14)) + threadIdx.x_2), 36)*2304) + (ic_chunk.outer.outer*144)) + (floordiv(floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*224) + (threadIdx.y_2*14)) + threadIdx.x_2), 36), 12)*48)) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + floordiv(((threadIdx.y_2*14) + threadIdx.x_2), 4)), 3)*16)) + (floormod(((threadIdx.y_2*14) + threadIdx.x_2), 4)*4)) + 144), 1, 4)]
          }
        }
      }
      for (kw.inner: int32, 0, 3) "unroll" {
        for (kh.inner: int32, 0, 3) "unroll" {
          for (n: int32, 0, 2) "unroll" {
            for (oc_chunk: int32, 0, 2) "unroll" {
              for (oh: int32, 0, 2) "unroll" {
                for (oc_block: int32, 0, 4) "unroll" {
                  compute[((((n*16) + (oc_chunk*8)) + (oh*4)) + oc_block)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((((floormod(ic_chunk.outer.outer, 2)*1160) + (n*580)) + (oh*232)) + (kh.inner*116)) + (threadIdx.x*8)) + (kw.inner*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((((floormod(ic_chunk.outer.outer, 2)*4608) + (threadIdx.y*288)) + (oc_chunk*144)) + (kh.inner*48)) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[((((n*16) + (oc_chunk*8)) + (oh*4)) + oc_block)], dtype=int32)
                }
              }
            }
          }
        }
      }
    }
    for (kw.inner_1: int32, 0, 3) "unroll" {
      for (kh.inner_1: int32, 0, 3) "unroll" {
        for (n_1: int32, 0, 2) "unroll" {
          for (oc_chunk_1: int32, 0, 2) "unroll" {
            for (oh_1: int32, 0, 2) "unroll" {
              for (oc_block_1: int32, 0, 4) "unroll" {
                compute[((((n_1*16) + (oc_chunk_1*8)) + (oh_1*4)) + oc_block_1)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((((n_1*580) + (oh_1*232)) + (kh.inner_1*116)) + (threadIdx.x*8)) + (kw.inner_1*4)) + 1160), 1, 4)], (int8x4*)placeholder.shared[ramp(((((((threadIdx.y*288) + (oc_chunk_1*144)) + (kh.inner_1*48)) + (kw.inner_1*16)) + (oc_block_1*4)) + 4608), 1, 4)], (int32*)compute[((((n_1*16) + (oc_chunk_1*8)) + (oh_1*4)) + oc_block_1)], dtype=int32)
              }
            }
          }
        }
      }
    }
    for (ax0.inner.inner.inner.inner: int32, 0, 2) "unroll" {
      for (ax1.inner.inner.inner: int32, 0, 2) "unroll" {
        for (ax2.inner.inner.inner: int32, 0, 2) "unroll" {
          for (ax4: int32, 0, 4) "unroll" {
            T_cast_2[(((((((((blockIdx.z*200704) + (ax0.inner.inner.inner.inner*100352)) + (threadIdx.y*6272)) + (ax1.inner.inner.inner*3136)) + (floordiv(blockIdx.x, 2)*224)) + (ax2.inner.inner.inner*112)) + (floormod(blockIdx.x, 2)*56)) + (threadIdx.x*4)) + ax4)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((int32*)compute[((((ax0.inner.inner.inner.inner*16) + (ax1.inner.inner.inner*8)) + (ax2.inner.inner.inner*4)) + ax4)], 1636774251, 31, 16, dtype=int32) + (int32*)placeholder_6[(((threadIdx.y*8) + (ax1.inner.inner.inner*4)) + ax4)]), 0), 1223412314, 31, -23, dtype=int32), 127), -128))
          }
        }
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_nn_relu_cast_fixed_point_mult_18399029763786111876__3", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [32, 32, 28, 28, 4], []),
             placeholder_2: Buffer(placeholder_6: handle, int32, [1, 32, 1, 1, 4], []),
             placeholder: Buffer(placeholder_7: handle, int8, [32, 32, 28, 28, 4], []),
             placeholder_1: Buffer(placeholder_8: handle, int8, [32, 32, 3, 3, 4, 4], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 32;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [56]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [96]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [288]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 4;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 14;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 4;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 2;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4 {
    for (oc_chunk.init: int32, 0, 2) "unroll" {
      for (oh.init: int32, 0, 7) "unroll" {
        for (oc_block.init: int32, 0, 4) "unroll" {
          compute[(((oc_chunk.init*28) + (oh.init*4)) + oc_block.init)] = 0
        }
      }
    }
    for (ic_chunk.outer: int32, 0, 32) {
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 3) "unroll" {
        attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 4;
        attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 2;
        attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
        pad_data.shared[ramp(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*128) + (threadIdx.z_1*32)) + (threadIdx.y_1*16)) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((1 <= ((floordiv(blockIdx.x, 7)*14) + floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*32) + (threadIdx.z_1*8)) + (threadIdx.y_1*4)) + threadIdx.x_1), 6))) && (((floordiv(blockIdx.x, 7)*14) + floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*32) + (threadIdx.z_1*8)) + (threadIdx.y_1*4)) + threadIdx.x_1), 6)) < 29)) && (1 <= ((floormod(blockIdx.x, 7)*4) + floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*32) + (threadIdx.z_1*8)) + (threadIdx.y_1*4)) + threadIdx.x_1), 6)))) && (((floormod(blockIdx.x, 7)*4) + floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*32) + (threadIdx.z_1*8)) + (threadIdx.y_1*4)) + threadIdx.x_1), 6)) < 29)), (int8x4*)placeholder_7[ramp((((((((blockIdx.z*100352) + (ic_chunk.outer*3136)) + (floordiv(blockIdx.x, 7)*1568)) + (floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*32) + (threadIdx.z_1*8)) + (threadIdx.y_1*4)) + threadIdx.x_1), 6)*112)) + (floormod(blockIdx.x, 7)*16)) + (floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*32) + (threadIdx.z_1*8)) + (threadIdx.y_1*4)) + threadIdx.x_1), 6)*4)) - 116), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
      }
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 9) "unroll" {
        attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 4;
        attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 2;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
        placeholder.shared[ramp(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*128) + (threadIdx.z_2*32)) + (threadIdx.y_2*16)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp((((((blockIdx.y*36864) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*8) + (threadIdx.z_2*2)) + threadIdx.y_2), 9)*4608)) + (ic_chunk.outer*144)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*8) + (threadIdx.z_2*2)) + threadIdx.y_2), 9)*16)) + (threadIdx.x_2*4)), 1, 4)]
      }
      for (kw.inner: int32, 0, 3) "unroll" {
        for (kh.inner: int32, 0, 3) "unroll" {
          for (oc_chunk: int32, 0, 2) "unroll" {
            for (oh: int32, 0, 7) "unroll" {
              for (oc_block: int32, 0, 4) "unroll" {
                compute[(((oc_chunk*28) + (oh*4)) + oc_block)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((threadIdx.y*168) + (oh*24)) + (kh.inner*24)) + (threadIdx.x*4)) + (kw.inner*4)), 1, 4)], (int8x4*)placeholder.shared[ramp((((((threadIdx.z*288) + (oc_chunk*144)) + (kh.inner*48)) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(((oc_chunk*28) + (oh*4)) + oc_block)], dtype=int32)
              }
            }
          }
        }
      }
    }
    for (ax1.inner.inner.inner: int32, 0, 2) "unroll" {
      for (ax2.inner.inner.inner: int32, 0, 7) "unroll" {
        for (ax4: int32, 0, 4) "unroll" {
          T_cast_2[((((((((((blockIdx.z*100352) + (blockIdx.y*25088)) + (threadIdx.z*6272)) + (ax1.inner.inner.inner*3136)) + (floordiv(blockIdx.x, 7)*1568)) + (threadIdx.y*784)) + (ax2.inner.inner.inner*112)) + (floormod(blockIdx.x, 7)*16)) + (threadIdx.x*4)) + ax4)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((int32*)compute[(((ax1.inner.inner.inner*28) + (ax2.inner.inner.inner*4)) + ax4)], 1425803333, 31, 17, dtype=int32) + (int32*)placeholder_6[((((blockIdx.y*32) + (threadIdx.z*8)) + (ax1.inner.inner.inner*4)) + ax4)]), 0), 1102733142, 31, -23, dtype=int32), 127), -128))
        }
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_fixed_point_multiply_clip_cast_4", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [32, 32, 28, 28, 4], []),
             placeholder: Buffer(placeholder_2: handle, int32, [32, 32, 28, 28, 4], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer: int32, 0, 13) {
    if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*65536) + (blockIdx.x*256)) + floordiv(threadIdx.x, 4)) < 802816) {
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x) < 3211264) {
        T_cast_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = cast(int8, max(min(@tir.q_multiply_shift((int32*)placeholder_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)], 2014218145, 31, -24, dtype=int32), 127), -128))
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_fixed_point_multiply_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [32, 64, 14, 14, 4], []),
             placeholder_2: Buffer(placeholder_6: handle, int32, [1, 64, 1, 1, 4], []),
             placeholder: Buffer(placeholder_7: handle, int8, [32, 64, 14, 14, 4], []),
             placeholder_1: Buffer(placeholder_8: handle, int8, [64, 64, 3, 3, 4, 4], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, compute_1: compute} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 8;
  attr [compute_3: handle] "storage_scope" = "local";
  allocate(compute_3, int32, [28]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [1024]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [1152]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 8;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 7;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 4;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4 {
    for (oh.init: int32, 0, 7) "unroll" {
      for (oc_block.init: int32, 0, 4) "unroll" {
        compute_3[((oh.init*4) + oc_block.init)] = 0
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 4) "unroll" {
      attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 4;
      attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
      pad_data.shared[ramp(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*512) + (threadIdx.z_1*128)) + (threadIdx.y_1*16)) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((1 <= floormod(((threadIdx.z_1*8) + threadIdx.y_1), 16)) && (floormod(((threadIdx.z_1*8) + threadIdx.y_1), 16) < 15)) && (1 <= ((blockIdx.x*2) + threadIdx.x_1))) && (((blockIdx.x*2) + threadIdx.x_1) < 15)), (int8x4*)placeholder_7[ramp((((((((blockIdx.z*200704) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*50176)) + (floordiv(((threadIdx.z_1*8) + threadIdx.y_1), 16)*784)) + (floormod(((threadIdx.z_1*8) + threadIdx.y_1), 16)*56)) + (blockIdx.x*8)) + (threadIdx.x_1*4)) - 60), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 5) "unroll" {
      attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 4;
      attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
      attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.z_2*8)) + threadIdx.y_2) < 144) {
        if (((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*128) + (threadIdx.z_2*32)) + (threadIdx.y_2*4)) + threadIdx.x_2) < 576) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*4) + threadIdx.z_2) < 18) {
            placeholder.shared[ramp(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*512) + (threadIdx.z_2*128)) + (threadIdx.y_2*16)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp(((((blockIdx.y*73728) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.z_2*8)) + threadIdx.y_2), 18)*9216)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.z_2*8)) + threadIdx.y_2), 18)*16)) + (threadIdx.x_2*4)), 1, 4)]
          }
        }
      }
    }
    for (ic_chunk.outer.outer: int32, 0, 31) {
      attr [pad_data.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1: int32, 0, 4) "unroll" {
        attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 4;
        attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
        attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
        pad_data.shared[ramp((((((floormod((ic_chunk.outer.outer + 1), 2)*2048) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*512)) + (threadIdx.z_1*128)) + (threadIdx.y_1*16)) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((1 <= floormod(((threadIdx.z_1*8) + threadIdx.y_1), 16)) && (floormod(((threadIdx.z_1*8) + threadIdx.y_1), 16) < 15)) && (1 <= ((blockIdx.x*2) + threadIdx.x_1))) && (((blockIdx.x*2) + threadIdx.x_1) < 15)), (int8x4*)placeholder_7[ramp(((((((((blockIdx.z*200704) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*50176)) + (ic_chunk.outer.outer*1568)) + (floordiv(((threadIdx.z_1*8) + threadIdx.y_1), 16)*784)) + (floormod(((threadIdx.z_1*8) + threadIdx.y_1), 16)*56)) + (blockIdx.x*8)) + (threadIdx.x_1*4)) + 1508), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
      }
      attr [placeholder.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 5) "unroll" {
        attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 4;
        attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
        attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.z_2*8)) + threadIdx.y_2) < 144) {
          if (((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_2*32)) + (threadIdx.y_2*4)) + threadIdx.x_2) < 576) {
            if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*4) + threadIdx.z_2) < 18) {
              placeholder.shared[ramp((((((floormod((ic_chunk.outer.outer + 1), 2)*2304) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*512)) + (threadIdx.z_2*128)) + (threadIdx.y_2*16)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp(((((((blockIdx.y*73728) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.z_2*8)) + threadIdx.y_2), 18)*9216)) + (ic_chunk.outer.outer*288)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.z_2*8)) + threadIdx.y_2), 18)*16)) + (threadIdx.x_2*4)) + 288), 1, 4)]
            }
          }
        }
      }
      for (ic_chunk.inner: int32, 0, 2) "unroll" {
        for (kw.inner: int32, 0, 3) "unroll" {
          for (kh.inner: int32, 0, 3) "unroll" {
            for (oh: int32, 0, 7) "unroll" {
              for (oc_block: int32, 0, 4) "unroll" {
                compute_3[((oh*4) + oc_block)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((((((floormod(ic_chunk.outer.outer, 2)*2048) + (threadIdx.z*512)) + (ic_chunk.inner*256)) + (floordiv(threadIdx.x, 2)*112)) + (oh*16)) + (kh.inner*16)) + (kw.inner*4)) + (floormod(threadIdx.x, 2)*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((((floormod(ic_chunk.outer.outer, 2)*2304) + (threadIdx.y*288)) + (ic_chunk.inner*144)) + (kh.inner*48)) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute_3[((oh*4) + oc_block)], dtype=int32)
              }
            }
          }
        }
      }
    }
    for (ic_chunk.inner_1: int32, 0, 2) "unroll" {
      for (kw.inner_1: int32, 0, 3) "unroll" {
        for (kh.inner_1: int32, 0, 3) "unroll" {
          for (oh_1: int32, 0, 7) "unroll" {
            for (oc_block_1: int32, 0, 4) "unroll" {
              compute_3[((oh_1*4) + oc_block_1)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((((((threadIdx.z*512) + (ic_chunk.inner_1*256)) + (floordiv(threadIdx.x, 2)*112)) + (oh_1*16)) + (kh.inner_1*16)) + (kw.inner_1*4)) + (floormod(threadIdx.x, 2)*4)) + 2048), 1, 4)], (int8x4*)placeholder.shared[ramp(((((((threadIdx.y*288) + (ic_chunk.inner_1*144)) + (kh.inner_1*48)) + (kw.inner_1*16)) + (oc_block_1*4)) + 2304), 1, 4)], (int32*)compute_3[((oh_1*4) + oc_block_1)], dtype=int32)
            }
          }
        }
      }
    }
    for (i2.inner.inner.inner: int32, 0, 7) "unroll" {
      for (i4: int32, 0, 4) "unroll" {
        compute_2[(((((((((blockIdx.z*200704) + (threadIdx.z*50176)) + (blockIdx.y*6272)) + (threadIdx.y*784)) + (floordiv(threadIdx.x, 2)*392)) + (i2.inner.inner.inner*56)) + (blockIdx.x*8)) + (floormod(threadIdx.x, 2)*4)) + i4)] = @tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute_3[((i2.inner.inner.inner*4) + i4)], 1968217277, 31, 16, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*32) + (threadIdx.y*4)) + i4)]), 2088981575, 31, 0, dtype=int32)
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_nn_relu_cast_fixed_point_mult_18399029763786111876__4", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [32, 64, 14, 14, 4], []),
             placeholder_2: Buffer(placeholder_6: handle, int32, [1, 64, 1, 1, 4], []),
             placeholder: Buffer(placeholder_7: handle, int8, [32, 32, 28, 28, 4], []),
             placeholder_1: Buffer(placeholder_8: handle, int8, [64, 32, 3, 3, 4, 4], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 8;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [32]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [116]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [384]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 2;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 14;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 16;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 1;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 14 {
    for (n.init: int32, 0, 4) "unroll" {
      for (oc_chunk.init: int32, 0, 2) "unroll" {
        for (oc_block.init: int32, 0, 4) "unroll" {
          compute[(((n.init*8) + (oc_chunk.init*4)) + oc_block.init)] = 0
        }
      }
    }
    for (ic_chunk.outer: int32, 0, 32) {
      for (kh.outer: int32, 0, 3) "unroll" {
        attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 16;
        attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 1;
        attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 14;
        if (((threadIdx.z_1*14) + threadIdx.x_1) < 116) {
          if (threadIdx.z_1 < 9) {
            pad_data.shared[ramp(((threadIdx.z_1*56) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((1 <= ((blockIdx.x*2) + kh.outer)) && (1 <= floormod(((threadIdx.z_1*14) + threadIdx.x_1), 29))), (int8x4*)placeholder_7[ramp((((((((blockIdx.z*401408) + (floordiv(((threadIdx.z_1*14) + threadIdx.x_1), 29)*100352)) + (ic_chunk.outer*3136)) + (blockIdx.x*224)) + (kh.outer*112)) + (floormod(((threadIdx.z_1*14) + threadIdx.x_1), 29)*4)) - 116), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
          }
        }
        for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 2) "unroll" {
          attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 16;
          attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 1;
          attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 14;
          if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*224) + (threadIdx.z_2*14)) + threadIdx.x_2) < 384) {
            if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*16) + threadIdx.z_2) < 28) {
              placeholder.shared[ramp((((floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*224) + (threadIdx.z_2*14)) + threadIdx.x_2), 12)*48) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + floordiv(((threadIdx.z_2*14) + threadIdx.x_2), 4)), 3)*16)) + (floormod(((threadIdx.z_2*14) + threadIdx.x_2), 4)*4)), 1, 4)] = (int8x4*)placeholder_8[ramp(((((((blockIdx.y*147456) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*224) + (threadIdx.z_2*14)) + threadIdx.x_2), 12)*4608)) + (ic_chunk.outer*144)) + (kh.outer*48)) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + floordiv(((threadIdx.z_2*14) + threadIdx.x_2), 4)), 3)*16)) + (floormod(((threadIdx.z_2*14) + threadIdx.x_2), 4)*4)), 1, 4)]
            }
          }
        }
        for (kw.inner: int32, 0, 3) "unroll" {
          for (n: int32, 0, 4) "unroll" {
            for (oc_chunk: int32, 0, 2) "unroll" {
              for (oc_block: int32, 0, 4) "unroll" {
                compute[(((n*8) + (oc_chunk*4)) + oc_block)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((n*116) + (threadIdx.x*8)) + (kw.inner*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.z*96) + (oc_chunk*48)) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(((n*8) + (oc_chunk*4)) + oc_block)], dtype=int32)
              }
            }
          }
        }
      }
    }
    for (ax0.inner.inner.inner.inner: int32, 0, 4) "unroll" {
      for (ax1.inner.inner.inner: int32, 0, 2) "unroll" {
        for (ax4: int32, 0, 4) "unroll" {
          T_cast_2[((((((((blockIdx.z*200704) + (ax0.inner.inner.inner.inner*50176)) + (blockIdx.y*25088)) + (threadIdx.z*1568)) + (ax1.inner.inner.inner*784)) + (blockIdx.x*56)) + (threadIdx.x*4)) + ax4)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((int32*)compute[(((ax0.inner.inner.inner.inner*8) + (ax1.inner.inner.inner*4)) + ax4)], 1529653425, 31, 16, dtype=int32) + (int32*)placeholder_6[((((blockIdx.y*128) + (threadIdx.z*8)) + (ax1.inner.inner.inner*4)) + ax4)]), 0), 1252240138, 31, -23, dtype=int32), 127), -128))
        }
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_nn_relu_cast_fixed_point_mult_18399029763786111876__5", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [32, 64, 14, 14, 4], []),
             placeholder_2: Buffer(placeholder_6: handle, int32, [1, 64, 1, 1, 4], []),
             placeholder: Buffer(placeholder_7: handle, int8, [32, 64, 14, 14, 4], []),
             placeholder_1: Buffer(placeholder_8: handle, int8, [64, 64, 3, 3, 4, 4], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 8;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [28]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [1024]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [1152]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 8;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 7;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 4;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4 {
    for (oh.init: int32, 0, 7) "unroll" {
      for (oc_block.init: int32, 0, 4) "unroll" {
        compute[((oh.init*4) + oc_block.init)] = 0
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 4) "unroll" {
      attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 4;
      attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
      pad_data.shared[ramp(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*512) + (threadIdx.z_1*128)) + (threadIdx.y_1*16)) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((1 <= floormod(((threadIdx.z_1*8) + threadIdx.y_1), 16)) && (floormod(((threadIdx.z_1*8) + threadIdx.y_1), 16) < 15)) && (1 <= ((blockIdx.x*2) + threadIdx.x_1))) && (((blockIdx.x*2) + threadIdx.x_1) < 15)), (int8x4*)placeholder_7[ramp((((((((blockIdx.z*200704) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*50176)) + (floordiv(((threadIdx.z_1*8) + threadIdx.y_1), 16)*784)) + (floormod(((threadIdx.z_1*8) + threadIdx.y_1), 16)*56)) + (blockIdx.x*8)) + (threadIdx.x_1*4)) - 60), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 5) "unroll" {
      attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 4;
      attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
      attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.z_2*8)) + threadIdx.y_2) < 144) {
        if (((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*128) + (threadIdx.z_2*32)) + (threadIdx.y_2*4)) + threadIdx.x_2) < 576) {
          if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*4) + threadIdx.z_2) < 18) {
            placeholder.shared[ramp(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*512) + (threadIdx.z_2*128)) + (threadIdx.y_2*16)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp(((((blockIdx.y*73728) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.z_2*8)) + threadIdx.y_2), 18)*9216)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.z_2*8)) + threadIdx.y_2), 18)*16)) + (threadIdx.x_2*4)), 1, 4)]
          }
        }
      }
    }
    for (ic_chunk.outer.outer: int32, 0, 31) {
      attr [pad_data.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1: int32, 0, 4) "unroll" {
        attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 4;
        attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
        attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
        pad_data.shared[ramp((((((floormod((ic_chunk.outer.outer + 1), 2)*2048) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*512)) + (threadIdx.z_1*128)) + (threadIdx.y_1*16)) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((((1 <= floormod(((threadIdx.z_1*8) + threadIdx.y_1), 16)) && (floormod(((threadIdx.z_1*8) + threadIdx.y_1), 16) < 15)) && (1 <= ((blockIdx.x*2) + threadIdx.x_1))) && (((blockIdx.x*2) + threadIdx.x_1) < 15)), (int8x4*)placeholder_7[ramp(((((((((blockIdx.z*200704) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer_1*50176)) + (ic_chunk.outer.outer*1568)) + (floordiv(((threadIdx.z_1*8) + threadIdx.y_1), 16)*784)) + (floormod(((threadIdx.z_1*8) + threadIdx.y_1), 16)*56)) + (blockIdx.x*8)) + (threadIdx.x_1*4)) + 1508), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
      }
      attr [placeholder.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 5) "unroll" {
        attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 4;
        attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
        attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 4;
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.z_2*8)) + threadIdx.y_2) < 144) {
          if (((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*128) + (threadIdx.z_2*32)) + (threadIdx.y_2*4)) + threadIdx.x_2) < 576) {
            if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*4) + threadIdx.z_2) < 18) {
              placeholder.shared[ramp((((((floormod((ic_chunk.outer.outer + 1), 2)*2304) + (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*512)) + (threadIdx.z_2*128)) + (threadIdx.y_2*16)) + (threadIdx.x_2*4)), 1, 4)] = (int8x4*)placeholder_8[ramp(((((((blockIdx.y*73728) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.z_2*8)) + threadIdx.y_2), 18)*9216)) + (ic_chunk.outer.outer*288)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.z_2*8)) + threadIdx.y_2), 18)*16)) + (threadIdx.x_2*4)) + 288), 1, 4)]
            }
          }
        }
      }
      for (ic_chunk.inner: int32, 0, 2) "unroll" {
        for (kw.inner: int32, 0, 3) "unroll" {
          for (kh.inner: int32, 0, 3) "unroll" {
            for (oh: int32, 0, 7) "unroll" {
              for (oc_block: int32, 0, 4) "unroll" {
                compute[((oh*4) + oc_block)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((((((floormod(ic_chunk.outer.outer, 2)*2048) + (threadIdx.z*512)) + (ic_chunk.inner*256)) + (floordiv(threadIdx.x, 2)*112)) + (oh*16)) + (kh.inner*16)) + (kw.inner*4)) + (floormod(threadIdx.x, 2)*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((((floormod(ic_chunk.outer.outer, 2)*2304) + (threadIdx.y*288)) + (ic_chunk.inner*144)) + (kh.inner*48)) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[((oh*4) + oc_block)], dtype=int32)
              }
            }
          }
        }
      }
    }
    for (ic_chunk.inner_1: int32, 0, 2) "unroll" {
      for (kw.inner_1: int32, 0, 3) "unroll" {
        for (kh.inner_1: int32, 0, 3) "unroll" {
          for (oh_1: int32, 0, 7) "unroll" {
            for (oc_block_1: int32, 0, 4) "unroll" {
              compute[((oh_1*4) + oc_block_1)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((((((threadIdx.z*512) + (ic_chunk.inner_1*256)) + (floordiv(threadIdx.x, 2)*112)) + (oh_1*16)) + (kh.inner_1*16)) + (kw.inner_1*4)) + (floormod(threadIdx.x, 2)*4)) + 2048), 1, 4)], (int8x4*)placeholder.shared[ramp(((((((threadIdx.y*288) + (ic_chunk.inner_1*144)) + (kh.inner_1*48)) + (kw.inner_1*16)) + (oc_block_1*4)) + 2304), 1, 4)], (int32*)compute[((oh_1*4) + oc_block_1)], dtype=int32)
            }
          }
        }
      }
    }
    for (ax2.inner.inner.inner: int32, 0, 7) "unroll" {
      for (ax4: int32, 0, 4) "unroll" {
        T_cast_2[(((((((((blockIdx.z*200704) + (threadIdx.z*50176)) + (blockIdx.y*6272)) + (threadIdx.y*784)) + (floordiv(threadIdx.x, 2)*392)) + (ax2.inner.inner.inner*56)) + (blockIdx.x*8)) + (floormod(threadIdx.x, 2)*4)) + ax4)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((int32*)compute[((ax2.inner.inner.inner*4) + ax4)], 1954738632, 31, 16, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*32) + (threadIdx.y*4)) + ax4)]), 0), 1275273255, 31, -23, dtype=int32), 127), -128))
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_fixed_point_multiply_clip_cast_5", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [32, 64, 14, 14, 4], []),
             placeholder: Buffer(placeholder_2: handle, int32, [32, 64, 14, 14, 4], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer: int32, 0, 7) {
    if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*65536) + (blockIdx.x*256)) + floordiv(threadIdx.x, 4)) < 401408) {
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x) < 1605632) {
        T_cast_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = cast(int8, max(min(@tir.q_multiply_shift((int32*)placeholder_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)], 1984087727, 31, -24, dtype=int32), 127), -128))
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_fixed_point_multiply_2", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: handle, int32, [32, 128, 7, 7, 4], []),
             placeholder_2: Buffer(placeholder_6: handle, int32, [1, 128, 1, 1, 4], []),
             placeholder: Buffer(placeholder_7: handle, int8, [32, 128, 7, 7, 4], []),
             placeholder_1: Buffer(placeholder_8: handle, int8, [128, 128, 3, 3, 4, 4], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, compute_1: compute} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 16;
  attr [compute_3: handle] "storage_scope" = "local";
  allocate(compute_3, int32, [28]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [1152]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [162]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 8;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7 {
    for (oh.init: int32, 0, 7) "unroll" {
      for (oc_block.init: int32, 0, 4) "unroll" {
        compute_3[((oh.init*4) + oc_block.init)] = 0
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 3) "unroll" {
      attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
      attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
      if (((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*224) + (threadIdx.z_1*112)) + (threadIdx.y_1*7)) + threadIdx.x_1) < 576) {
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.z_1*16)) + threadIdx.y_1) < 83) {
          placeholder.shared[ramp((((floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*224) + (threadIdx.z_1*112)) + (threadIdx.y_1*7)) + threadIdx.x_1), 12)*48) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.z_1*28)) + floordiv(((threadIdx.y_1*7) + threadIdx.x_1), 4)), 3)*16)) + (floormod(((threadIdx.y_1*7) + threadIdx.x_1), 4)*4)), 1, 4)] = (int8x4*)placeholder_8[ramp((((((blockIdx.y*294912) + (floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*224) + (threadIdx.z_1*112)) + (threadIdx.y_1*7)) + threadIdx.x_1), 36)*18432)) + (floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*224) + (threadIdx.z_1*112)) + (threadIdx.y_1*7)) + threadIdx.x_1), 36), 12)*48)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.z_1*28)) + floordiv(((threadIdx.y_1*7) + threadIdx.x_1), 4)), 3)*16)) + (floormod(((threadIdx.y_1*7) + threadIdx.x_1), 4)*4)), 1, 4)]
        }
      }
    }
    for (ic_chunk.outer.outer: int32, 0, 127) {
      attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
      attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
      attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
      if ((((threadIdx.z_2*112) + (threadIdx.y_2*7)) + threadIdx.x_2) < 162) {
        if (((threadIdx.z_2*16) + threadIdx.y_2) < 24) {
          pad_data.shared[ramp((((threadIdx.z_2*448) + (threadIdx.y_2*28)) + (threadIdx.x_2*4)), 1, 4)] = @tir.if_then_else(((((9 <= floormod((((threadIdx.z_2*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 81)) && (floormod((((threadIdx.z_2*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 81) < 72)) && (1 <= floormod((((threadIdx.z_2*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 9))) && (floormod((((threadIdx.z_2*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 9) < 8)), (int8x4*)placeholder_7[ramp(((((((blockIdx.z*50176) + (floordiv((((threadIdx.z_2*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 81)*25088)) + (ic_chunk.outer.outer*196)) + (floordiv(floormod((((threadIdx.z_2*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 81), 9)*28)) + (floormod((((threadIdx.z_2*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 9)*4)) - 32), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
        }
      }
      attr [placeholder.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 3) "unroll" {
        attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
        attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
        attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
        if (((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*224) + (threadIdx.z_1*112)) + (threadIdx.y_1*7)) + threadIdx.x_1) < 576) {
          if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.z_1*16)) + threadIdx.y_1) < 83) {
            placeholder.shared[ramp(((((floormod((ic_chunk.outer.outer + 1), 2)*2304) + (floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*224) + (threadIdx.z_1*112)) + (threadIdx.y_1*7)) + threadIdx.x_1), 12)*48)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.z_1*28)) + floordiv(((threadIdx.y_1*7) + threadIdx.x_1), 4)), 3)*16)) + (floormod(((threadIdx.y_1*7) + threadIdx.x_1), 4)*4)), 1, 4)] = (int8x4*)placeholder_8[ramp((((((((blockIdx.y*294912) + (floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*224) + (threadIdx.z_1*112)) + (threadIdx.y_1*7)) + threadIdx.x_1), 36)*18432)) + (ic_chunk.outer.outer*144)) + (floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*224) + (threadIdx.z_1*112)) + (threadIdx.y_1*7)) + threadIdx.x_1), 36), 12)*48)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.z_1*28)) + floordiv(((threadIdx.y_1*7) + threadIdx.x_1), 4)), 3)*16)) + (floormod(((threadIdx.y_1*7) + threadIdx.x_1), 4)*4)) + 144), 1, 4)]
          }
        }
      }
      for (kw.inner: int32, 0, 3) "unroll" {
        for (kh.inner: int32, 0, 3) "unroll" {
          for (oh: int32, 0, 7) "unroll" {
            for (oc_block: int32, 0, 4) "unroll" {
              compute_3[((oh*4) + oc_block)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((threadIdx.z*324) + (oh*36)) + (kh.inner*36)) + (threadIdx.x*4)) + (kw.inner*4)), 1, 4)], (int8x4*)placeholder.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*2304) + (threadIdx.y*144)) + (kh.inner*48)) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute_3[((oh*4) + oc_block)], dtype=int32)
            }
          }
        }
      }
    }
    attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
    attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
    attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
    if ((((threadIdx.z_2*112) + (threadIdx.y_2*7)) + threadIdx.x_2) < 162) {
      if (((threadIdx.z_2*16) + threadIdx.y_2) < 24) {
        pad_data.shared[ramp((((threadIdx.z_2*448) + (threadIdx.y_2*28)) + (threadIdx.x_2*4)), 1, 4)] = @tir.if_then_else(((((9 <= floormod((((threadIdx.z_2*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 81)) && (floormod((((threadIdx.z_2*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 81) < 72)) && (1 <= floormod((((threadIdx.z_2*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 9))) && (floormod((((threadIdx.z_2*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 9) < 8)), (int8x4*)placeholder_7[ramp((((((blockIdx.z*50176) + (floordiv((((threadIdx.z_2*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 81)*25088)) + (floordiv(floormod((((threadIdx.z_2*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 81), 9)*28)) + (floormod((((threadIdx.z_2*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 9)*4)) + 24860), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
      }
    }
    for (kw.inner_1: int32, 0, 3) "unroll" {
      for (kh.inner_1: int32, 0, 3) "unroll" {
        for (oh_1: int32, 0, 7) "unroll" {
          for (oc_block_1: int32, 0, 4) "unroll" {
            compute_3[((oh_1*4) + oc_block_1)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((threadIdx.z*324) + (oh_1*36)) + (kh.inner_1*36)) + (threadIdx.x*4)) + (kw.inner_1*4)), 1, 4)], (int8x4*)placeholder.shared[ramp((((((threadIdx.y*144) + (kh.inner_1*48)) + (kw.inner_1*16)) + (oc_block_1*4)) + 2304), 1, 4)], (int32*)compute_3[((oh_1*4) + oc_block_1)], dtype=int32)
          }
        }
      }
    }
    for (i2.inner.inner.inner: int32, 0, 7) "unroll" {
      for (i4: int32, 0, 4) "unroll" {
        compute_2[(((((((blockIdx.z*50176) + (threadIdx.z*25088)) + (blockIdx.y*3136)) + (threadIdx.y*196)) + (i2.inner.inner.inner*28)) + (threadIdx.x*4)) + i4)] = @tir.q_multiply_shift((@tir.q_multiply_shift((int32*)compute_3[((i2.inner.inner.inner*4) + i4)], 1839999616, 31, 17, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*64) + (threadIdx.y*4)) + i4)]), 2068073536, 31, 0, dtype=int32)
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_nn_relu_cast_fixed_point_mult_18399029763786111876__6", "tir.noalias": True}
  buffers = {placeholder_2: Buffer(placeholder_6: handle, int32, [1, 128, 1, 1, 4], []),
             placeholder: Buffer(placeholder_7: handle, int8, [32, 64, 14, 14, 4], []),
             T_cast: Buffer(T_cast_2: handle, int8, [32, 128, 7, 7, 4], []),
             placeholder_1: Buffer(placeholder_8: handle, int8, [128, 64, 3, 3, 4, 4], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 8;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [32]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [120]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [384]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 8;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 7;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7 {
    for (n.init: int32, 0, 2) "unroll" {
      for (oc_block.init: int32, 0, 4) "unroll" {
        compute[((n.init*4) + oc_block.init)] = 0
        compute[(((n.init*4) + oc_block.init) + 16)] = 0
        compute[(((n.init*4) + oc_block.init) + 8)] = 0
        compute[(((n.init*4) + oc_block.init) + 24)] = 0
      }
    }
    for (kh.outer: int32, 0, 3) {
      for (ic_chunk.outer: int32, 0, 32) {
        for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer: int32, 0, 3) "unroll" {
          attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
          attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
          attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
          if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*56) + (threadIdx.y_1*7)) + threadIdx.x_1) < 120) {
            if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*8) + threadIdx.y_1) < 18) {
              pad_data.shared[ramp((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*224) + (threadIdx.y_1*28)) + (threadIdx.x_1*4)), 1, 4)] = @tir.if_then_else(((1 <= ((blockIdx.x*2) + kh.outer)) && (1 <= floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*56) + (threadIdx.y_1*7)) + threadIdx.x_1), 15))), (int8x4*)placeholder_7[ramp(((((((((blockIdx.z*200704) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*56) + (threadIdx.y_1*7)) + threadIdx.x_1), 30)*50176)) + (ic_chunk.outer*1568)) + (floordiv(floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*56) + (threadIdx.y_1*7)) + threadIdx.x_1), 30), 15)*784)) + (blockIdx.x*112)) + (kh.outer*56)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.outer.fused.outer.outer.outer*56) + (threadIdx.y_1*7)) + threadIdx.x_1), 15)*4)) - 60), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
            }
          }
        }
        for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 7) "unroll" {
          attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
          attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 8;
          attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
          if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.y_2*7)) + threadIdx.x_2) < 384) {
            if (((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*8) + threadIdx.y_2) < 55) {
              placeholder.shared[ramp((((floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.y_2*7)) + threadIdx.x_2), 12)*48) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*14) + floordiv(((threadIdx.y_2*7) + threadIdx.x_2), 4)), 3)*16)) + (floormod(((threadIdx.y_2*7) + threadIdx.x_2), 4)*4)), 1, 4)] = (int8x4*)placeholder_8[ramp((((((((blockIdx.y*147456) + (floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.y_2*7)) + threadIdx.x_2), 24)*9216)) + (ic_chunk.outer*288)) + (floordiv(floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.y_2*7)) + threadIdx.x_2), 24), 12)*144)) + (kh.outer*48)) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*14) + floordiv(((threadIdx.y_2*7) + threadIdx.x_2), 4)), 3)*16)) + (floormod(((threadIdx.y_2*7) + threadIdx.x_2), 4)*4)), 1, 4)]
            }
          }
        }
        for (ic_chunk.inner: int32, 0, 2) "unroll" {
          for (kw.inner: int32, 0, 3) "unroll" {
            for (n: int32, 0, 2) "unroll" {
              for (oc_block: int32, 0, 4) "unroll" {
                compute[((n*4) + oc_block)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((n*120) + (ic_chunk.inner*60)) + (threadIdx.x*8)) + (kw.inner*4)), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*96) + (ic_chunk.inner*48)) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[((n*4) + oc_block)], dtype=int32)
                compute[(((n*4) + oc_block) + 16)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((n*120) + (ic_chunk.inner*60)) + (threadIdx.x*8)) + (kw.inner*4)) + 240), 1, 4)], (int8x4*)placeholder.shared[ramp(((((threadIdx.y*96) + (ic_chunk.inner*48)) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[(((n*4) + oc_block) + 16)], dtype=int32)
                compute[(((n*4) + oc_block) + 8)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp(((((n*120) + (ic_chunk.inner*60)) + (threadIdx.x*8)) + (kw.inner*4)), 1, 4)], (int8x4*)placeholder.shared[ramp((((((threadIdx.y*96) + (ic_chunk.inner*48)) + (kw.inner*16)) + (oc_block*4)) + 768), 1, 4)], (int32*)compute[(((n*4) + oc_block) + 8)], dtype=int32)
                compute[(((n*4) + oc_block) + 24)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((n*120) + (ic_chunk.inner*60)) + (threadIdx.x*8)) + (kw.inner*4)) + 240), 1, 4)], (int8x4*)placeholder.shared[ramp((((((threadIdx.y*96) + (ic_chunk.inner*48)) + (kw.inner*16)) + (oc_block*4)) + 768), 1, 4)], (int32*)compute[(((n*4) + oc_block) + 24)], dtype=int32)
              }
            }
          }
        }
      }
    }
    for (ax0.inner.inner.inner.inner: int32, 0, 2) "unroll" {
      for (ax4: int32, 0, 4) "unroll" {
        T_cast_2[(((((((blockIdx.z*100352) + (ax0.inner.inner.inner.inner*25088)) + (blockIdx.y*3136)) + (threadIdx.y*196)) + (blockIdx.x*28)) + (threadIdx.x*4)) + ax4)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((int32*)compute[((ax0.inner.inner.inner.inner*4) + ax4)], 1345670983, 31, 17, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 0), 1104268508, 31, -23, dtype=int32), 127), -128))
        T_cast_2[((((((((blockIdx.z*100352) + (ax0.inner.inner.inner.inner*25088)) + (blockIdx.y*3136)) + (threadIdx.y*196)) + (blockIdx.x*28)) + (threadIdx.x*4)) + ax4) + 50176)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((int32*)compute[(((ax0.inner.inner.inner.inner*4) + ax4) + 16)], 1345670983, 31, 17, dtype=int32) + (int32*)placeholder_6[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 0), 1104268508, 31, -23, dtype=int32), 127), -128))
        T_cast_2[((((((((blockIdx.z*100352) + (ax0.inner.inner.inner.inner*25088)) + (blockIdx.y*3136)) + (threadIdx.y*196)) + (blockIdx.x*28)) + (threadIdx.x*4)) + ax4) + 1568)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((int32*)compute[(((ax0.inner.inner.inner.inner*4) + ax4) + 8)], 1345670983, 31, 17, dtype=int32) + (int32*)placeholder_6[((((blockIdx.y*64) + (threadIdx.y*4)) + ax4) + 32)]), 0), 1104268508, 31, -23, dtype=int32), 127), -128))
        T_cast_2[((((((((blockIdx.z*100352) + (ax0.inner.inner.inner.inner*25088)) + (blockIdx.y*3136)) + (threadIdx.y*196)) + (blockIdx.x*28)) + (threadIdx.x*4)) + ax4) + 51744)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((int32*)compute[(((ax0.inner.inner.inner.inner*4) + ax4) + 24)], 1345670983, 31, 17, dtype=int32) + (int32*)placeholder_6[((((blockIdx.y*64) + (threadIdx.y*4)) + ax4) + 32)]), 0), 1104268508, 31, -23, dtype=int32), 127), -128))
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation conv2d_NCHWc_int8.cuda for op nn.conv2d
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op add
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op nn.relu
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_conv2d_cast_fixed_point_multiply_add_cast_nn_relu_cast_fixed_point_mult_18399029763786111876__7", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [32, 128, 7, 7, 4], []),
             placeholder: Buffer(placeholder_6: handle, int8, [32, 128, 7, 7, 4], []),
             placeholder_2: Buffer(placeholder_7: handle, int32, [1, 128, 1, 1, 4], []),
             placeholder_1: Buffer(placeholder_8: handle, int8, [128, 128, 3, 3, 4, 4], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 16;
  attr [compute: handle] "storage_scope" = "local";
  allocate(compute, int32, [28]);
  attr [placeholder.shared: handle] "storage_scope" = "shared";
  allocate(placeholder.shared, int8x4, [1152]);
  attr [pad_data.shared: handle] "storage_scope" = "shared";
  allocate(pad_data.shared, int8x4, [162]);
  attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 8;
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1;
  attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
  attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7 {
    for (oh.init: int32, 0, 7) "unroll" {
      for (oc_block.init: int32, 0, 4) "unroll" {
        compute[((oh.init*4) + oc_block.init)] = 0
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer: int32, 0, 3) "unroll" {
      attr [IterVar(threadIdx.z_1: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
      attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
      if (((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*224) + (threadIdx.z_1*112)) + (threadIdx.y_1*7)) + threadIdx.x_1) < 576) {
        if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*32) + (threadIdx.z_1*16)) + threadIdx.y_1) < 83) {
          placeholder.shared[ramp((((floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*224) + (threadIdx.z_1*112)) + (threadIdx.y_1*7)) + threadIdx.x_1), 12)*48) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.z_1*28)) + floordiv(((threadIdx.y_1*7) + threadIdx.x_1), 4)), 3)*16)) + (floormod(((threadIdx.y_1*7) + threadIdx.x_1), 4)*4)), 1, 4)] = (int8x4*)placeholder_8[ramp((((((blockIdx.y*294912) + (floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*224) + (threadIdx.z_1*112)) + (threadIdx.y_1*7)) + threadIdx.x_1), 36)*18432)) + (floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*224) + (threadIdx.z_1*112)) + (threadIdx.y_1*7)) + threadIdx.x_1), 36), 12)*48)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer*56) + (threadIdx.z_1*28)) + floordiv(((threadIdx.y_1*7) + threadIdx.x_1), 4)), 3)*16)) + (floormod(((threadIdx.y_1*7) + threadIdx.x_1), 4)*4)), 1, 4)]
        }
      }
    }
    for (ic_chunk.outer.outer: int32, 0, 127) {
      attr [IterVar(threadIdx.z_2: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
      attr [IterVar(threadIdx.y_2: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
      attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
      if ((((threadIdx.z_2*112) + (threadIdx.y_2*7)) + threadIdx.x_2) < 162) {
        if (((threadIdx.z_2*16) + threadIdx.y_2) < 24) {
          pad_data.shared[ramp((((threadIdx.z_2*448) + (threadIdx.y_2*28)) + (threadIdx.x_2*4)), 1, 4)] = @tir.if_then_else(((((9 <= floormod((((threadIdx.z_2*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 81)) && (floormod((((threadIdx.z_2*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 81) < 72)) && (1 <= floormod((((threadIdx.z_2*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 9))) && (floormod((((threadIdx.z_2*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 9) < 8)), (int8x4*)placeholder_6[ramp(((((((blockIdx.z*50176) + (floordiv((((threadIdx.z_2*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 81)*25088)) + (ic_chunk.outer.outer*196)) + (floordiv(floormod((((threadIdx.z_2*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 81), 9)*28)) + (floormod((((threadIdx.z_2*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 9)*4)) - 32), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
        }
      }
      attr [placeholder.shared] "double_buffer_write" = 1;
      for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1: int32, 0, 3) "unroll" {
        attr [IterVar(threadIdx.z_1, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
        attr [IterVar(threadIdx.y_1, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
        attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
        if (((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*224) + (threadIdx.z_1*112)) + (threadIdx.y_1*7)) + threadIdx.x_1) < 576) {
          if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*32) + (threadIdx.z_1*16)) + threadIdx.y_1) < 83) {
            placeholder.shared[ramp(((((floormod((ic_chunk.outer.outer + 1), 2)*2304) + (floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*224) + (threadIdx.z_1*112)) + (threadIdx.y_1*7)) + threadIdx.x_1), 12)*48)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.z_1*28)) + floordiv(((threadIdx.y_1*7) + threadIdx.x_1), 4)), 3)*16)) + (floormod(((threadIdx.y_1*7) + threadIdx.x_1), 4)*4)), 1, 4)] = (int8x4*)placeholder_8[ramp((((((((blockIdx.y*294912) + (floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*224) + (threadIdx.z_1*112)) + (threadIdx.y_1*7)) + threadIdx.x_1), 36)*18432)) + (ic_chunk.outer.outer*144)) + (floordiv(floormod(((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*224) + (threadIdx.z_1*112)) + (threadIdx.y_1*7)) + threadIdx.x_1), 36), 12)*48)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.ax5.outer.fused.outer.outer.outer_1*56) + (threadIdx.z_1*28)) + floordiv(((threadIdx.y_1*7) + threadIdx.x_1), 4)), 3)*16)) + (floormod(((threadIdx.y_1*7) + threadIdx.x_1), 4)*4)) + 144), 1, 4)]
          }
        }
      }
      for (kw.inner: int32, 0, 3) "unroll" {
        for (kh.inner: int32, 0, 3) "unroll" {
          for (oh: int32, 0, 7) "unroll" {
            for (oc_block: int32, 0, 4) "unroll" {
              compute[((oh*4) + oc_block)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((threadIdx.z*324) + (oh*36)) + (kh.inner*36)) + (threadIdx.x*4)) + (kw.inner*4)), 1, 4)], (int8x4*)placeholder.shared[ramp((((((floormod(ic_chunk.outer.outer, 2)*2304) + (threadIdx.y*144)) + (kh.inner*48)) + (kw.inner*16)) + (oc_block*4)), 1, 4)], (int32*)compute[((oh*4) + oc_block)], dtype=int32)
            }
          }
        }
      }
    }
    attr [IterVar(threadIdx.z_2, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 2;
    attr [IterVar(threadIdx.y_2, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 16;
    attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 7;
    if ((((threadIdx.z_2*112) + (threadIdx.y_2*7)) + threadIdx.x_2) < 162) {
      if (((threadIdx.z_2*16) + threadIdx.y_2) < 24) {
        pad_data.shared[ramp((((threadIdx.z_2*448) + (threadIdx.y_2*28)) + (threadIdx.x_2*4)), 1, 4)] = @tir.if_then_else(((((9 <= floormod((((threadIdx.z_2*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 81)) && (floormod((((threadIdx.z_2*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 81) < 72)) && (1 <= floormod((((threadIdx.z_2*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 9))) && (floormod((((threadIdx.z_2*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 9) < 8)), (int8x4*)placeholder_6[ramp((((((blockIdx.z*50176) + (floordiv((((threadIdx.z_2*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 81)*25088)) + (floordiv(floormod((((threadIdx.z_2*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 81), 9)*28)) + (floormod((((threadIdx.z_2*112) + (threadIdx.y_2*7)) + threadIdx.x_2), 9)*4)) + 24860), 1, 4)], broadcast(0i8, 4), dtype=int8x4)
      }
    }
    for (kw.inner_1: int32, 0, 3) "unroll" {
      for (kh.inner_1: int32, 0, 3) "unroll" {
        for (oh_1: int32, 0, 7) "unroll" {
          for (oc_block_1: int32, 0, 4) "unroll" {
            compute[((oh_1*4) + oc_block_1)] = @tir.call_pure_extern("__dp4a", (int8x4*)pad_data.shared[ramp((((((threadIdx.z*324) + (oh_1*36)) + (kh.inner_1*36)) + (threadIdx.x*4)) + (kw.inner_1*4)), 1, 4)], (int8x4*)placeholder.shared[ramp((((((threadIdx.y*144) + (kh.inner_1*48)) + (kw.inner_1*16)) + (oc_block_1*4)) + 2304), 1, 4)], (int32*)compute[((oh_1*4) + oc_block_1)], dtype=int32)
          }
        }
      }
    }
    for (ax2.inner.inner.inner: int32, 0, 7) "unroll" {
      for (ax4: int32, 0, 4) "unroll" {
        T_cast_2[(((((((blockIdx.z*50176) + (threadIdx.z*25088)) + (blockIdx.y*3136)) + (threadIdx.y*196)) + (ax2.inner.inner.inner*28)) + (threadIdx.x*4)) + ax4)] = cast(int8, max(min(@tir.q_multiply_shift(max((@tir.q_multiply_shift((int32*)compute[((ax2.inner.inner.inner*4) + ax4)], 1933257701, 31, 16, dtype=int32) + (int32*)placeholder_7[(((blockIdx.y*64) + (threadIdx.y*4)) + ax4)]), 0), 1649746970, 31, -23, dtype=int32), 127), -128))
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data
INFO:compile_engine:Use implementation injective.cuda for op cast
INFO:compile_engine:Use implementation injective.cuda for op fixed_point_multiply
INFO:compile_engine:Use implementation injective.cuda for op clip
INFO:compile_engine:Use implementation injective.cuda for op cast
primfn(placeholder_1: handle, T_cast_1: handle) -> ()
  attr = {"global_symbol": "fused_cast_fixed_point_multiply_clip_cast_6", "tir.noalias": True}
  buffers = {T_cast: Buffer(T_cast_2: handle, int8, [32, 128, 7, 7, 4], []),
             placeholder: Buffer(placeholder_2: handle, int32, [32, 128, 7, 7, 4], [])}
  buffer_map = {placeholder_1: placeholder, T_cast_1: T_cast} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer: int32, 0, 4) {
    if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*65536) + (blockIdx.x*256)) + floordiv(threadIdx.x, 4)) < 200704) {
      if ((((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x) < 802816) {
        T_cast_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = cast(int8, max(min(@tir.q_multiply_shift((int32*)placeholder_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.ax4.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)], 1773341876, 31, -24, dtype=int32), 127), -128))
      }
    }
  }
}

// meta data omitted. you can use show_meta_data=True to include meta data

